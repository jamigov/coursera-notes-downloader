<!DOCTYPE html>
<html xmlns:fb="http://ogp.me/ns/fb#" itemtype="http://schema.org" dir="ltr" class="supports-svg" lang="en"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><style class="vjs-styles-defaults">
      .video-js {
        width: 300px;
        height: 150px;
      }

      .vjs-fluid {
        padding-top: 56.25%
      }
    </style><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=IE7"><meta charset="utf-8"><meta property="og:site_name" content="Coursera"><meta property="fb:admins" content="727836538,4807654"><meta property="fb:app_id" content="823425307723964"><meta name="twitter:site" content="Coursera"><meta name="twitter:app:name:iphone" content="Coursera"><meta name="twitter:app:name:ipad" content="Coursera"><meta name="twitter:app:name:googleplay" content="Coursera"><meta name="twitter:app:id:iphone" content="id736535961"><meta name="twitter:app:id:ipad" content="id736535961"><meta name="twitter:app:id:googleplay" content="org.coursera.android"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="apple-touch-icon" sizes="57x57" href="https://d3njjcbhbojbot.cloudfront.net/web/images/favicons/apple-touch-icon-v2-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="https://d3njjcbhbojbot.cloudfront.net/web/images/favicons/apple-touch-icon-v2-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="https://d3njjcbhbojbot.cloudfront.net/web/images/favicons/apple-touch-icon-v2-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="https://d3njjcbhbojbot.cloudfront.net/web/images/favicons/apple-touch-icon-v2-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="https://d3njjcbhbojbot.cloudfront.net/web/images/favicons/apple-touch-icon-v2-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="https://d3njjcbhbojbot.cloudfront.net/web/images/favicons/apple-touch-icon-v2-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="https://d3njjcbhbojbot.cloudfront.net/web/images/favicons/apple-touch-icon-v2-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="https://d3njjcbhbojbot.cloudfront.net/web/images/favicons/apple-touch-icon-v2-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="https://d3njjcbhbojbot.cloudfront.net/web/images/favicons/apple-touch-icon-v2-180x180.png"><link rel="icon" type="image/png" href="https://d3njjcbhbojbot.cloudfront.net/web/images/favicons/favicon-v2-194x194.png" sizes="194x194"><link rel="icon" type="image/png" href="https://d3njjcbhbojbot.cloudfront.net/web/images/favicons/android-chrome-v2-192x192.png" sizes="192x192"><link rel="icon" type="image/png" href="https://d3njjcbhbojbot.cloudfront.net/web/images/favicons/favicon-v2-96x96.png" sizes="96x96"><link rel="icon" type="image/png" href="https://d3njjcbhbojbot.cloudfront.net/web/images/favicons/favicon-v2-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://d3njjcbhbojbot.cloudfront.net/web/images/favicons/favicon-v2-32x32.png" sizes="32x32"><meta name="msapplication-TileColor" content="#2d89ef"><meta name="msapplication-TileImage" content="https://d3njjcbhbojbot.cloudfront.net/web/images/favicons/mstile-v2-144x144.png"><meta name="theme-color" content="#4689c6"><meta property="qc:admins" content="366737676376375235216727"><!-- Verification for Yandex--><meta property="yandex-verification" content="4970cfdb825622c7"><style>@font-face {
  font-family: 'coursera-iconfont';
  src: url("https://d3njjcbhbojbot.cloudfront.net/web/bundles/styleguide/icons/fonts/coursera.v26.eot");
  src: url("https://d3njjcbhbojbot.cloudfront.net/web/bundles/styleguide/icons/fonts/coursera.v26.eot?#iefix") format('embedded-opentype'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/bundles/styleguide/icons/fonts/coursera.v26.woff") format('woff'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/bundles/styleguide/icons/fonts/coursera.v26.ttf") format('truetype'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/bundles/styleguide/icons/fonts/coursera.v26.svg") format('svg');
}

@font-face {
  font-family: 'OpenSans-Light';
  src: url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans/OpenSans-Light.eot");
  src: url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans/OpenSans-Light.eot?#iefix") format('embedded-opentype'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans-v17-latin-latinext-cyrillic/opensans-300.woff2") format('woff2'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans-v17-latin-latinext-cyrillic/opensans-300.woff") format('woff'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans/OpenSans-Light.ttf") format('truetype'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans/OpenSans-Light.svg#OpenSans-Light") format('svg');
  font-weight: normal;
  font-style: normal;
}
@font-face {
  font-family: 'OpenSans';
  src: url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans/OpenSans-Regular.eot");
  src: url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans/OpenSans-Regular.eot?#iefix") format('embedded-opentype'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans-v17-latin-latinext-cyrillic/opensans-regular.woff2") format('woff2'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans-v17-latin-latinext-cyrillic/opensans-regular.woff") format('woff'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans/OpenSans-Regular.ttf") format('truetype'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans/OpenSans-Regular.svg#OpenSans-Regular") format('svg');
  font-weight: normal;
  font-style: normal;
}
@font-face {
  font-family: 'OpenSans-Semibold';
  src: url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans/OpenSans-Semibold.eot");
  src: url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans/OpenSans-Semibold.eot?#iefix") format('embedded-opentype'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans-v17-latin-latinext-cyrillic/opensans-600.woff2") format('woff2'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans-v17-latin-latinext-cyrillic/opensans-600.woff") format('woff'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans/OpenSans-Semibold.ttf") format('truetype'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans/OpenSans-Semibold.svg#OpenSans-Semibold") format('svg');
  font-weight: normal;
  font-style: normal;
}
@font-face {
  font-family: 'OpenSans';
  src: url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans/OpenSans-Bold.eot");
  src: url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans/OpenSans-Bold.eot?#iefix") format('embedded-opentype'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans-v17-latin-latinext-cyrillic/opensans-700.woff2") format('woff2'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans-v17-latin-latinext-cyrillic/opensans-700.woff") format('woff'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans/OpenSans-Bold.ttf") format('truetype'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/opensans/OpenSans-Bold.svg#OpenSans-Bold") format('svg');
  font-weight: bold;
  font-style: normal;
}
@font-face {
  font-family: 'Merriweather';
  src: url("https://d3njjcbhbojbot.cloudfront.net/web/type/merriweather/Merriweather-Regular.eot");
  src: url("https://d3njjcbhbojbot.cloudfront.net/web/type/merriweather/Merriweather-Regular.eot?#iefix") format('embedded-opentype'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/merriweather/Merriweather-Regular.woff2") format('woff2'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/merriweather/Merriweather-Regular.woff") format('woff'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/merriweather/Merriweather-Regular.ttf") format('truetype'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/merriweather/Merriweather-Regular.svg#Merriweather-Regular") format('svg');
  font-weight: normal;
  font-style: normal;
}
@font-face {
  font-family: 'Merriweather-Light';
  src: url("https://d3njjcbhbojbot.cloudfront.net/web/type/merriweather/Merriweather-Light.eot");
  src: url("https://d3njjcbhbojbot.cloudfront.net/web/type/merriweather/Merriweather-Light.eot?#iefix") format('embedded-opentype'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/merriweather/Merriweather-Light.woff2") format('woff2'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/merriweather/Merriweather-Light.woff") format('woff'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/merriweather/Merriweather-Light.ttf") format('truetype'),
       url("https://d3njjcbhbojbot.cloudfront.net/web/type/merriweather/Merriweather-Regular.svg#Merriweather-Light") format('svg');
  font-weight: normal;
  font-style: normal;
}
@font-face {
  font-family: 'Source Sans Pro';
  font-style: normal;
  font-weight: 300;
  src: url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-300.eot'); /* IE9 Compat Modes */
  src: url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-300.eot?#iefix')
      format('embedded-opentype'),
      url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-300.woff2')
      format('woff2'),
      url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-300.woff')
      format('woff'),
      url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-300.ttf')
      format('truetype'),
      url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-300.svg#SourceSansPro')
      format('svg');
}
@font-face {
  font-family: 'Source Sans Pro';
  font-style: normal;
  font-weight: 400;
  src: url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-regular.eot'); /* IE9 Compat Modes */
  src: url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-regular.eot?#iefix')
      format('embedded-opentype'),
      url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-regular.woff2')
      format('woff2'),
      url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-regular.woff')
      format('woff'),
      url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-regular.ttf')
      format('truetype'),
      url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-regular.svg#SourceSansPro')
      format('svg');
}
@font-face {
  font-family: 'Source Sans Pro';
  font-style: normal;
  font-weight: 600;
  src: url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-600.eot'); /* IE9 Compat Modes */
  src: url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-600.eot?#iefix')
      format('embedded-opentype'),
      url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-600.woff2')
      format('woff2'),
      url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-600.woff')
      format('woff'),
      url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-600.ttf')
      format('truetype'),
      url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-600.svg#SourceSansPro')
      format('svg');
}
@font-face {
  font-family: 'Source Sans Pro';
  font-style: normal;
  font-weight: bold;
  src: url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-700.eot');
  src: url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-700.eot?#iefix')
      format('embedded-opentype'),
      url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-700.woff2')
      format('woff2'),
      url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-700.woff')
      format('woff'),
      url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-700.ttf')
      format('truetype'),
      url('https://d3njjcbhbojbot.cloudfront.net/web/type/source-sans-pro-v14-latin/source-sans-pro-v14-latin-700.svg#SourceSansPro')
      format('svg');
}</style><script>// NOTE: This file gets included in Jade pre-transformed so it must be ES5-safe.

(function (global, factory) {
  global.errorTracker = factory();
})(this, function () {
  var lastError = {};

  function errorEquals(left, right) {
    return ['message', 'url', 'line', 'column'].every(function (field) {
      return left[field] == right[field];
    });
  }

  return function (tracker, options) {
    options = options || {};

    var logger = options.logger || (window && window.console) || { error: function () {} };
    var version = options.version || '';
    var versionTimestamp = options.versionTimestamp || '';

    var stringifyError = function (error) {
      var plainObject = {};
      if (error && typeof error == 'object') {
        Object.getOwnPropertyNames(error).forEach(function (key) {
          plainObject[key] = error[key];
        });
      }
      return JSON.stringify(plainObject);
    };

    var logClientSideError = function (message, url, line, column, error) {
      // errors without line numbers, urls or columns aren't helpful, chuck them
      if (!url || !column || !line) return;

      if (message.target && message.type) {
        message = message.type;
      }

      if (error && error.stack) {
        var findStackUrlRegExp = /\(([^)\s]+?):\d+:\d+\)/gm;
        var findLastStackUrlRegExp = /\s*(https?:\/\/[^:\s]+?):\d+:\d+\s*$/gm;
        var match;
        var local = true;

        // test for parens enclosed URLs in stack trace
        while ((match = findStackUrlRegExp.exec(error.stack))) {
          if (match && !options.scriptFilter.test(match[1])) {
            local = false;
            break;
          }
        }

        // test for last URL in stack trace
        if (local) {
          while ((match = findLastStackUrlRegExp.exec(error.stack))) {
            if (match && !options.scriptFilter.test(match[1])) {
              local = false;
              break;
            }
          }
        }

        // if stack trace shows us external scripts are buggy, don't log
        if (!local) return;
      }

      var errorStr = stringifyError(error);
      var errorDescrip = {
        message: message,
        script: url,
        line: line,
        url: window && window.document ? window.document.URL : url,
        column: column,
        error: errorStr,
        version: version,
        versionTimestamp: versionTimestamp,
        appName: window.appName || 'unknown',
      };

      logger.error(errorStr);

      var trackableUrl = url && (!options.scriptFilter || options.scriptFilter.test(url));

      if (trackableUrl) {
        var isNewError = !errorEquals(errorDescrip, lastError);

        // don't track the same error over and over again
        if (isNewError) {
          lastError = errorDescrip;
          tracker(errorDescrip);
        }
      }
    };

    if (typeof window !== 'undefined') {
      window.onerror = logClientSideError;
      if (window.errorTracker) {
        delete window.errorTracker;
      }
    } else {
      return logClientSideError;
    }
  };
});
</script><script>window._204 = [];
window._400 = [];
if(window.errorTracker) {
  window.errorTracker(
    function(error) {
      window._400.push({key:'page.error.javascript', value:error});
    },
    {
      scriptFilter: new RegExp('^/|^' + location.protocol + '//' + location.host),
      version: "681cc59bc2e6194c5883db9380c5f8d8bcb44a25",
      versionTimestamp: "1611353947628"
    });
}</script><script>window.publicPathOverride = "" !== "" ?
  "" : null;</script><link href="Applied%20Machine%20Learning%20in%20Python%20-%20Notes%20|%20Coursera_files/allStyles.css" data-href="https://d3njjcbhbojbot.cloudfront.net/webapps/r2-builds/ondemand/allStyles.8713d60a3674b46e46a8.css" rel="stylesheet"><title>Applied Machine Learning in Python - Notes | Coursera</title>
<meta data-react-helmet="true" property="og:url" content="https://www.coursera.org/learn/python-machine-learning/exam/PUZ55/module-2-quiz/attempt"><meta data-react-helmet="true" property="og:locale" content="en_US"><meta data-react-helmet="true" property="og:type" content="website"><meta data-react-helmet="true" property="twitter:card" content="summary"><meta data-react-helmet="true" name="robots" content="noindex, nofollow">
<link data-react-helmet="true" rel="canonical" href="https://www.coursera.org/learn/python-machine-learning/exam/PUZ55/module-2-quiz/attempt">


<style data-emotion="css"></style>
<style data-aphrodite="_473mf9o _e296pg keyframe_1mfzdnn _1hwtb43">._473mf9o{-webkit-box-direction:normal;-webkit-box-orient:vertical;-webkit-box-align:center;-ms-flex-align:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-align-items:center;align-items:center;display:-webkit-box;display:-moz-box;display:-ms-flexbox;display:-webkit-flex;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}._e296pg{position:relative;}@keyframes keyframe_1mfzdnn{0%{-webkit-transform:scale(.1);-ms-transform:scale(.1);transform:scale(.1);opacity:0;}40%{opacity:1;}100%{-webkit-transform:scale(1);-ms-transform:scale(1);transform:scale(1);opacity:0;}}._1hwtb43{text-indent:-9999em;border-style:solid;margin:1.125rem 0 0 1.125rem;opacity:0;position:absolute;top:-1.125rem;left:-1.125rem;-webkit-animation-name:keyframe_1mfzdnn;animation-name:keyframe_1mfzdnn;-webkit-animation-duration:1s;animation-duration:1s;-webkit-animation-iteration-count:infinite;animation-iteration-count:infinite;}</style>
<script data-ssr="true">window.ssr = true</script><script>!function(e){function webpackJsonpCallback(a){for(var c=a[0],d=a[1],r=a[2],t,o,u=0,i=[];u<c.length;u++)o=c[u],Object.prototype.hasOwnProperty.call(f,o)&&f[o]&&i.push(f[o][0]),f[o]=0;for(t in d)Object.prototype.hasOwnProperty.call(d,t)&&(e[t]=d[t]);for(n&&n(a);i.length;)i.shift()();return b.push.apply(b,r||[]),checkDeferredModules()}function checkDeferredModules(){for(var e,a=0;a<b.length;a++){for(var c=b[a],d=!0,r=1;r<c.length;r++){var t=c[r];0!==f[t]&&(d=!1)}d&&(b.splice(a--,1),e=__webpack_require__(__webpack_require__.s=c[0]))}return e}var a={},c={manifest:0},f={manifest:0},b=[];function jsonpScriptSrc(e){var a=function(e){var a;return{"9":true,"10":true,"12":true,"13":true,"20":true,"22":true,"23":true,"24":true,"26":true,"29":true,"30":true,"32":true,"33":true,"34":true,"35":true,"38":true,"39":true,"40":true,"41":true,"42":true,"44":true,"45":true,"47":true,"49":true,"50":true,"51":true,"52":true,"53":true,"54":true,"56":true,"58":true,"59":true,"63":true,"64":true,"66":true,"68":true,"70":true,"71":true,"72":true,"74":true,"79":true,"81":true,"86":true,"87":true,"90":true,"92":true,"93":true,"94":true,"95":true,"107":true,"111":true,"app":true,"asyncCommonJS":true,"manifest":true}[e]?"en."+e:e};return __webpack_require__.p+""+a(e)+"."+{0:"fc2d4f153195e41d2ecf",1:"a283899c042ec73ac266",2:"f65399bf3e0b898cce66",3:"4b975b70fbeb06fd6ac2",4:"818c2dee6a6a9ea61f1c",5:"525135deb58a09edf17d",6:"ba42c2e8fccd6a874865",7:"cdbf81c64d2cfb26a16c",8:"f4b122a8dae83c3188e0",9:"9fcc06d8a8589f85d9bc",10:"d2ab6bf5be40b587901f",11:"7a68b150625b8ad6e766",12:"e4b5cfc9a511a69f73dd",13:"2568647a48fbad429f62",14:"acf644575deefc7a9a8e",15:"9abdc18a87f5ba238d4e",16:"4a0a1d1cbdfba35811aa",17:"5f6926b7f850eb0eed07",18:"dd8f0b8672726a393404",19:"30961a06ac9881e3ede4",20:"9e4e34d677821e2dcecf",21:"578accedc00676c2ef85",22:"dc0a106658231e595ca6",23:"b841978a7debbb728b2d",24:"077d16a789d98440f67f",25:"0f92e61001bd4dfa927e",26:"ca03398c7fe0627f683a",27:"ab4849850524dd39c517",28:"f356f6e0fa68f8cef4be",29:"440c81a01f3a18239bc5",30:"958425f3ce93ef0386ce",31:"73bfe3435598bed6a04a",32:"17fa79b2ae57710d4a0a",33:"7caee64b1b07332f27f1",34:"57c35046b8249846db41",35:"f403602ed7572a3a5f09",36:"ece6a6ae8aa83310e0b7",37:"13946e00cba088d22527",38:"2692feea587ca2ca08a3",39:"40eabe77835b032fb994",40:"e7513b001f87b00fc3f6",41:"50e34ef9f3744960e280",42:"32ba0880fa4435db9d92",43:"578454af0273390aa136",44:"a98ae9ac82e9f2476cc6",45:"a67a76c43e191789ff65",46:"fc2a9a9e9a5999c2035b",47:"5d3bfcc44deffc3335f6",48:"74f5272315101eecf097",49:"73947735095fefff02ee",50:"3e560f8378e629057bd2",51:"a3ba9754bca969568863",52:"fe953e555b547c835708",53:"16fac150fd9ad9f186e3",54:"4c9961b30c2b2f82bed0",55:"5f18c61407f9534e3852",56:"11a14c3704e00e3e6de8",57:"5a83862008a105dab85c",58:"d2e316371949483271f2",59:"0beb4f5b38e4c1b52796",60:"7b11978dfc018879ca2e",61:"a0ac9c9cd38c2709f626",62:"980162fbd9de42d61eb0",63:"6a79fc1f034ecf35da8d",64:"0013fae2750db7d55b5d",65:"a2f2a76ed305820108ac",66:"69b9249f610da01799e5",67:"29f966f2d2e801f857fe",68:"bf62a578f1122a9cf911",69:"339bc145b3562171ac44",70:"de3010d7c955c0be0dba",71:"f3375e4ca157ff525df6",72:"c1f9ba407dcb0d0da57e",73:"b2738e44a6952b1d993a",74:"ac8a0d349496f7a5088d",75:"865bbae76b22e82121e9",76:"594631cad1fab06c233b",77:"bd7df0bf58a5b830cc0b",78:"9943aec1aa1f5ef94f39",79:"3d882949f3858c20be5c",80:"b5d88e22537e98e20bb3",81:"adbf6a36d3ba5388ad23",82:"d945e0e4f5b4c380b5ac",83:"6a3e5269e064f0b356d6",84:"d1eccbcb9a5d11a03b10",85:"792e01660745162a80f6",86:"8424b75558d0bce65fb5",87:"b712fbff5b1b7ecf8931",88:"3959a9cdb963f4c8bf24",89:"2c9cd62fd6cfb96d4cb0",90:"dbd6220c2bf451e39f5b",91:"ae524302679150f5b1e6",92:"e9c787fea6b018b33419",93:"ff795106c799114ff503",94:"6f7b82f7d9644af82477",95:"fadbbbd37113173441b1",96:"1b8cb297c1c70ebe970d",97:"a9473b65bb0614bfc539",98:"1ddeab8f9b1b0a3e4153",99:"72271c4b903ef4aaf2e8",100:"0fcd47bae7c696b122ad",101:"372df8a60c7b3fb89e9d",102:"b7cb49903f8dc332f4e8",103:"539d712829abdf196f09",104:"610fdb5bd1ea2c9fa0f2",105:"39ad5f030b9638fa2d56",106:"221774dfa34be29b5cdc",107:"5898511d30f5c39d8fa7",108:"497880cf693b8a5cac17",109:"12282dec9fd9bb32f8fd",110:"d6015d4976d2ed94b2ab",111:"1ed3f850cfd9130275b5",112:"f11e90a60f39c318193f",113:"716b8d4c810e3a19dedf",114:"006a895ebef3592e5042",115:"bcbc3e7ad4290add98ba",116:"015254856fc0d66d958f",117:"672ba5f970eb50b958a0",118:"f08794409d3da31b2f2a",119:"ec973696032ab8144e97",120:"e66a71c3f39e8458f0ea",121:"53ffc233927e569cee44",122:"6aa3da4a2fd7a9765d28",123:"22a2c24c33b657a0c857",124:"4abba1c82c6d3a6271dd",125:"eee1d6c6da0138bb6e4a",126:"53c2fcd06ad36983dd45",127:"d98c8f5f316284ecd0d6",128:"6b14c1e9acb9228579b3",129:"405a78a91f13c8f1b1c4",130:"389e3b96429cdf3d7bcd",131:"b9b00917305b000a6aef",132:"ee711a5b89741a4e0c1e",133:"5bbd66f5177f62deb82b",134:"d26fa738cfe8d598e031",135:"18a77a8b7abbf20deeed",136:"7950e8042f66bdfb478e",137:"266344872355c6294515",138:"aac4a5b8fb6a404090fc",139:"ddc3c986295d25d02254",140:"095c27bd62dc09f536dc",141:"f3c7ea6147a5c68f559a",142:"3493a65ed9b7f28eb725",143:"a5ab8742598f21339df8",144:"63328c23b9d301c13853",145:"bc38c550bf3136230c0e",146:"d5cf6fc97a016a33c366",147:"3d2b3aa32ac878ab8bff",148:"9752adf70286e73493d9",149:"5d865429d6ee8bda0730",150:"44065edb0f001ae70726",151:"5dcdd219040f6affa636",152:"e543f5659f18c079bd50",153:"bc8af53025c1c8709ce6",154:"e96e18e48758ad3dd026",155:"3aca0bb2570638c6208d",156:"aa61be32dd32d0e22ad7",157:"541c6088cb77e64503a6",158:"889030f188acaee5ea30",159:"77b81a889651734a2c69",160:"395a79f8ccde8ce9ce82",161:"cc3dc1e845c1bc58bb1b",162:"fc0d58b0be6c27bd482e",163:"9b0dd102bd15719f793e",164:"05d09b873d7f31a12a68",165:"2f49c0bec7dfc7cc21fe",166:"a2d6cf1fc7ed05854888",167:"6dad3a327ac6667da083",168:"c785a3ee774308d026b1",169:"2a87264ae338b3ac4d38",170:"b6a6f641012e9fb6cb65",171:"e2a6d6f962943dcffc44",172:"e4cd2f60ef21d1dbd803",173:"aa0782a07075faa774e6",174:"2d83ae95d93367336285",175:"40d7a4fc69b369bf28d5",176:"3433da9ae84f058c0bff",177:"2af7fd4eb85530042d83",178:"ed725a8aeb8c307737d8",179:"c1287e10e9a3ecb59a9f",180:"17fc5ed64673c2af0146",181:"26b4e6ee08eff2265d6c",182:"e4b19c22e709d4c3be11",allStyles:"8713d60a3674b46e46a8",asyncCommonJS:"e47b2245d7c3c3947479"}[e]+".js"}function __webpack_require__(c){if(a[c])return a[c].exports;var module=a[c]={i:c,l:!1,exports:{}};return e[c].call(module.exports,module,module.exports,__webpack_require__),module.l=!0,module.exports}__webpack_require__.e=function requireEnsure(e){var a=[],b={allStyles:1};c[e]?a.push(c[e]):0!==c[e]&&b[e]&&a.push(c[e]=new Promise(function(a,c){for(var f=({allStyles:"allStyles",asyncCommonJS:"asyncCommonJS"}[e]||e)+"."+{0:"fc2d4f153195e41d2ecf",1:"a283899c042ec73ac266",2:"f65399bf3e0b898cce66",3:"4b975b70fbeb06fd6ac2",4:"818c2dee6a6a9ea61f1c",5:"525135deb58a09edf17d",6:"ba42c2e8fccd6a874865",7:"cdbf81c64d2cfb26a16c",8:"f4b122a8dae83c3188e0",9:"9fcc06d8a8589f85d9bc",10:"d2ab6bf5be40b587901f",11:"7a68b150625b8ad6e766",12:"e4b5cfc9a511a69f73dd",13:"2568647a48fbad429f62",14:"acf644575deefc7a9a8e",15:"9abdc18a87f5ba238d4e",16:"4a0a1d1cbdfba35811aa",17:"5f6926b7f850eb0eed07",18:"dd8f0b8672726a393404",19:"30961a06ac9881e3ede4",20:"9e4e34d677821e2dcecf",21:"578accedc00676c2ef85",22:"dc0a106658231e595ca6",23:"b841978a7debbb728b2d",24:"077d16a789d98440f67f",25:"0f92e61001bd4dfa927e",26:"ca03398c7fe0627f683a",27:"ab4849850524dd39c517",28:"f356f6e0fa68f8cef4be",29:"440c81a01f3a18239bc5",30:"958425f3ce93ef0386ce",31:"73bfe3435598bed6a04a",32:"17fa79b2ae57710d4a0a",33:"7caee64b1b07332f27f1",34:"57c35046b8249846db41",35:"f403602ed7572a3a5f09",36:"ece6a6ae8aa83310e0b7",37:"13946e00cba088d22527",38:"2692feea587ca2ca08a3",39:"40eabe77835b032fb994",40:"e7513b001f87b00fc3f6",41:"50e34ef9f3744960e280",42:"32ba0880fa4435db9d92",43:"578454af0273390aa136",44:"a98ae9ac82e9f2476cc6",45:"a67a76c43e191789ff65",46:"fc2a9a9e9a5999c2035b",47:"5d3bfcc44deffc3335f6",48:"74f5272315101eecf097",49:"73947735095fefff02ee",50:"3e560f8378e629057bd2",51:"a3ba9754bca969568863",52:"fe953e555b547c835708",53:"16fac150fd9ad9f186e3",54:"4c9961b30c2b2f82bed0",55:"5f18c61407f9534e3852",56:"11a14c3704e00e3e6de8",57:"5a83862008a105dab85c",58:"d2e316371949483271f2",59:"0beb4f5b38e4c1b52796",60:"7b11978dfc018879ca2e",61:"a0ac9c9cd38c2709f626",62:"980162fbd9de42d61eb0",63:"6a79fc1f034ecf35da8d",64:"0013fae2750db7d55b5d",65:"a2f2a76ed305820108ac",66:"69b9249f610da01799e5",67:"29f966f2d2e801f857fe",68:"bf62a578f1122a9cf911",69:"339bc145b3562171ac44",70:"de3010d7c955c0be0dba",71:"f3375e4ca157ff525df6",72:"c1f9ba407dcb0d0da57e",73:"b2738e44a6952b1d993a",74:"ac8a0d349496f7a5088d",75:"865bbae76b22e82121e9",76:"594631cad1fab06c233b",77:"bd7df0bf58a5b830cc0b",78:"9943aec1aa1f5ef94f39",79:"3d882949f3858c20be5c",80:"b5d88e22537e98e20bb3",81:"adbf6a36d3ba5388ad23",82:"d945e0e4f5b4c380b5ac",83:"6a3e5269e064f0b356d6",84:"d1eccbcb9a5d11a03b10",85:"792e01660745162a80f6",86:"8424b75558d0bce65fb5",87:"b712fbff5b1b7ecf8931",88:"3959a9cdb963f4c8bf24",89:"2c9cd62fd6cfb96d4cb0",90:"dbd6220c2bf451e39f5b",91:"ae524302679150f5b1e6",92:"e9c787fea6b018b33419",93:"ff795106c799114ff503",94:"6f7b82f7d9644af82477",95:"fadbbbd37113173441b1",96:"1b8cb297c1c70ebe970d",97:"a9473b65bb0614bfc539",98:"1ddeab8f9b1b0a3e4153",99:"72271c4b903ef4aaf2e8",100:"0fcd47bae7c696b122ad",101:"372df8a60c7b3fb89e9d",102:"b7cb49903f8dc332f4e8",103:"539d712829abdf196f09",104:"610fdb5bd1ea2c9fa0f2",105:"39ad5f030b9638fa2d56",106:"221774dfa34be29b5cdc",107:"5898511d30f5c39d8fa7",108:"497880cf693b8a5cac17",109:"12282dec9fd9bb32f8fd",110:"d6015d4976d2ed94b2ab",111:"1ed3f850cfd9130275b5",112:"f11e90a60f39c318193f",113:"716b8d4c810e3a19dedf",114:"006a895ebef3592e5042",115:"bcbc3e7ad4290add98ba",116:"015254856fc0d66d958f",117:"672ba5f970eb50b958a0",118:"f08794409d3da31b2f2a",119:"ec973696032ab8144e97",120:"e66a71c3f39e8458f0ea",121:"53ffc233927e569cee44",122:"6aa3da4a2fd7a9765d28",123:"22a2c24c33b657a0c857",124:"4abba1c82c6d3a6271dd",125:"eee1d6c6da0138bb6e4a",126:"53c2fcd06ad36983dd45",127:"d98c8f5f316284ecd0d6",128:"6b14c1e9acb9228579b3",129:"405a78a91f13c8f1b1c4",130:"389e3b96429cdf3d7bcd",131:"b9b00917305b000a6aef",132:"ee711a5b89741a4e0c1e",133:"5bbd66f5177f62deb82b",134:"d26fa738cfe8d598e031",135:"18a77a8b7abbf20deeed",136:"7950e8042f66bdfb478e",137:"266344872355c6294515",138:"aac4a5b8fb6a404090fc",139:"ddc3c986295d25d02254",140:"095c27bd62dc09f536dc",141:"f3c7ea6147a5c68f559a",142:"3493a65ed9b7f28eb725",143:"a5ab8742598f21339df8",144:"63328c23b9d301c13853",145:"bc38c550bf3136230c0e",146:"d5cf6fc97a016a33c366",147:"3d2b3aa32ac878ab8bff",148:"9752adf70286e73493d9",149:"5d865429d6ee8bda0730",150:"44065edb0f001ae70726",151:"5dcdd219040f6affa636",152:"e543f5659f18c079bd50",153:"bc8af53025c1c8709ce6",154:"e96e18e48758ad3dd026",155:"3aca0bb2570638c6208d",156:"aa61be32dd32d0e22ad7",157:"541c6088cb77e64503a6",158:"889030f188acaee5ea30",159:"77b81a889651734a2c69",160:"395a79f8ccde8ce9ce82",161:"cc3dc1e845c1bc58bb1b",162:"fc0d58b0be6c27bd482e",163:"9b0dd102bd15719f793e",164:"05d09b873d7f31a12a68",165:"2f49c0bec7dfc7cc21fe",166:"a2d6cf1fc7ed05854888",167:"6dad3a327ac6667da083",168:"c785a3ee774308d026b1",169:"2a87264ae338b3ac4d38",170:"b6a6f641012e9fb6cb65",171:"e2a6d6f962943dcffc44",172:"e4cd2f60ef21d1dbd803",173:"aa0782a07075faa774e6",174:"2d83ae95d93367336285",175:"40d7a4fc69b369bf28d5",176:"3433da9ae84f058c0bff",177:"2af7fd4eb85530042d83",178:"ed725a8aeb8c307737d8",179:"c1287e10e9a3ecb59a9f",180:"17fc5ed64673c2af0146",181:"26b4e6ee08eff2265d6c",182:"e4b19c22e709d4c3be11",allStyles:"8713d60a3674b46e46a8",asyncCommonJS:"e47b2245d7c3c3947479"}[e]+".css",b=__webpack_require__.p+f,d=document.getElementsByTagName("link"),r=0;r<d.length;r++){var t,n=(t=d[r]).getAttribute("data-href")||t.getAttribute("href");if("stylesheet"===t.rel&&(n===f||n===b))return a()}for(var o=document.getElementsByTagName("style"),r=0;r<o.length;r++){var t,n;if((n=(t=o[r]).getAttribute("data-href"))===f||n===b)return a()}var u=document.createElement("link"),i;u.rel="stylesheet",u.type="text/css",u.onload=a,u.onerror=function(a){var f=a&&a.target&&a.target.src||b,d=new Error("Loading CSS chunk "+e+" failed.\n("+f+")");d.request=f,c(d)},u.href=b,document.getElementsByTagName("head")[0].appendChild(u)}).then(function(){c[e]=0}));var d=f[e];if(0!==d)if(d)a.push(d[2]);else{var r=new Promise(function(a,c){d=f[e]=[a,c]});a.push(d[2]=r);var t=document.createElement("script"),n;t.charset="utf-8",t.timeout=120,__webpack_require__.nc&&t.setAttribute("nonce",__webpack_require__.nc),t.src=jsonpScriptSrc(e);var o=new Error;n=function(a){t.onerror=t.onload=null,clearTimeout(u);var c=f[e];if(0!==c){if(c){var b=a&&("load"===a.type?"missing":a.type),d=a&&a.target&&a.target.src;o.message="Loading chunk "+e+" failed.\n("+b+": "+d+")",o.name="ChunkLoadError",o.type=b,o.request=d,c[1](o)}f[e]=void 0}};var u=setTimeout(function(){n({type:"timeout",target:t})},12e4);t.onerror=t.onload=n,document.head.appendChild(t)}return Promise.all(a)},__webpack_require__.m=e,__webpack_require__.c=a,__webpack_require__.d=function(exports,e,a){__webpack_require__.o(exports,e)||Object.defineProperty(exports,e,{enumerable:!0,get:a})},__webpack_require__.r=function(exports){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(exports,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(exports,"__esModule",{value:!0})},__webpack_require__.t=function(e,a){if(1&a&&(e=__webpack_require__(e)),8&a)return e;if(4&a&&"object"==typeof e&&e&&e.__esModule)return e;var c=Object.create(null);if(__webpack_require__.r(c),Object.defineProperty(c,"default",{enumerable:!0,value:e}),2&a&&"string"!=typeof e)for(var f in e)__webpack_require__.d(c,f,function(a){return e[a]}.bind(null,f));return c},__webpack_require__.n=function(module){var e=module&&module.__esModule?function getDefault(){return module.default}:function getModuleExports(){return module};return __webpack_require__.d(e,"a",e),e},__webpack_require__.o=function(e,a){return Object.prototype.hasOwnProperty.call(e,a)},__webpack_require__.p="https://d3njjcbhbojbot.cloudfront.net/webapps/r2-builds/ondemand/",__webpack_require__.oe=function(e){throw console.error(e),e};var d=window.webpackJsonp=window.webpackJsonp||[],r=d.push.bind(d);d.push=webpackJsonpCallback,d=d.slice();for(var t=0;t<d.length;t++)webpackJsonpCallback(d[t]);var n=r;checkDeferredModules()}([]);</script><script type="text/javascript" src="Applied%20Machine%20Learning%20in%20Python%20-%20Notes%20|%20Coursera_files/allStyles.js" defer="defer" crossorigin="anonymous"></script><script>/* Polyfill Injector */
(function(main) {
    if(/* Intl */!('Intl' in this)) {
        var js = document.createElement('script');
        js.src = "https://d3njjcbhbojbot.cloudfront.net/web/bundles/vendor/Intl.js.v0-1-4/Intl.en-US.js?features=Intl";
        js.onload = main;
        js.onerror = function() {
            console.error('Could not load polyfills script!');
            main();
        };
        document.head.appendChild(js);
    } else {
        main();
    }
})(function() {
});
//# sourceMappingURL=polyfill.7261bd210e8c516552b6.js.map</script><script>/* Polyfill Injector */
(function(main) {
    if(/* Intl */!('Intl' in this)) {
        var js = document.createElement('script');
        js.src = "https://d3njjcbhbojbot.cloudfront.net/web/bundles/vendor/Intl.js.v0-1-4/Intl.en-US.js?features=Intl";
        js.onload = main;
        js.onerror = function() {
            console.error('Could not load polyfills script!');
            main();
        };
        document.head.appendChild(js);
    } else {
        main();
    }
})(function() {
});
/*# sourceURL=ace/css/ace_editor.css */</style><style id="ace-tm">.ace-tm .ace_gutter {background: #f0f0f0;color: #333;}.ace-tm .ace_print-margin {width: 1px;background: #e8e8e8;}.ace-tm .ace_fold {background-color: #6B72E6;}.ace-tm {background-color: #FFFFFF;color: black;}.ace-tm .ace_cursor {color: black;}.ace-tm .ace_invisible {color: rgb(191, 191, 191);}.ace-tm .ace_storage,.ace-tm .ace_keyword {color: blue;}.ace-tm .ace_constant {color: rgb(197, 6, 11);}.ace-tm .ace_constant.ace_buildin {color: rgb(88, 72, 246);}.ace-tm .ace_constant.ace_language {color: rgb(88, 92, 246);}.ace-tm .ace_constant.ace_library {color: rgb(6, 150, 14);}.ace-tm .ace_invalid {background-color: rgba(255, 0, 0, 0.1);color: red;}.ace-tm .ace_support.ace_function {color: rgb(60, 76, 114);}.ace-tm .ace_support.ace_constant {color: rgb(6, 150, 14);}.ace-tm .ace_support.ace_type,.ace-tm .ace_support.ace_class {color: rgb(109, 121, 222);}.ace-tm .ace_keyword.ace_operator {color: rgb(104, 118, 135);}.ace-tm .ace_string {color: rgb(3, 106, 7);}.ace-tm .ace_comment {color: rgb(76, 136, 107);}.ace-tm .ace_comment.ace_doc {color: rgb(0, 102, 255);}.ace-tm .ace_comment.ace_doc.ace_tag {color: rgb(128, 159, 191);}.ace-tm .ace_constant.ace_numeric {color: rgb(0, 0, 205);}.ace-tm .ace_variable {color: rgb(49, 132, 149);}.ace-tm .ace_xml-pe {color: rgb(104, 104, 91);}.ace-tm .ace_entity.ace_name.ace_function {color: #0000A2;}.ace-tm .ace_heading {color: rgb(12, 7, 255);}.ace-tm .ace_list {color:rgb(185, 6, 144);}.ace-tm .ace_meta.ace_tag {color:rgb(0, 22, 142);}.ace-tm .ace_string.ace_regex {color: rgb(255, 0, 0)}.ace-tm .ace_marker-layer .ace_selection {background: rgb(181, 213, 255);}.ace-tm.ace_multiselect .ace_selection.ace_start {box-shadow: 0 0 3px 0px white;}.ace-tm .ace_marker-layer .ace_step {background: rgb(252, 255, 0);}.ace-tm .ace_marker-layer .ace_stack {background: rgb(164, 229, 101);}.ace-tm .ace_marker-layer .ace_bracket {margin: -1px 0 0 -1px;border: 1px solid rgb(192, 192, 192);}.ace-tm .ace_marker-layer .ace_active-line {background: rgba(0, 0, 0, 0.07);}.ace-tm .ace_gutter-active-line {background-color : #dcdcdc;}.ace-tm .ace_marker-layer .ace_selected-word {background: rgb(250, 250, 255);border: 1px solid rgb(200, 200, 250);}.ace-tm .ace_indent-guide {background: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAACCAYAAACZgbYnAAAAE0lEQVQImWP4////f4bLly//BwAmVgd1/w11/gAAAABJRU5ErkJggg==") right repeat-y;}
 with regression, what we do is instead of taking a majority vote, we 
don't have class values here as targets, we have continuous values.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Now with regression, what we do is instead of taking a majority vote, we don't have class values here as targets, we have continuous values." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit481766f6-bb84-46a1-fc48-f23ae3985dc3 Edit481766f6-bb84-46a1-fc48-f23ae3985dc3Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit481766f6-bb84-46a1-fc48-f23ae3985dc3">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Now with regression, what we do is instead of taking a majority vote, we don't have class values here as targets, we have continuous values." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleteeeb67f58-bd04-4d82-fe31-ffae9cb94d01 Deleteeeb67f58-bd04-4d82-fe31-ffae9cb94d01Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deleteeeb67f58-bd04-4d82-fe31-ffae9cb94d01">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video687f485e-ba45-4051-bbf8-8b5d4f371aab Video687f485e-ba45-4051-bbf8-8b5d4f371aabDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video687f485e-ba45-4051-bbf8-8b5d4f371aab">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/I1cfu?t=309&quot;,&quot;itemId&quot;:&quot;I1cfu&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/I1cfu?t=309" href="https://www.coursera.org/learn/python-machine-learning/lecture/I1cfu?t=309" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">K-Nearest Neighbors: Classification and Regression</div></a><div class="video-details" aria-label="Duration">5:09 - 5:52</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">In
 the k = 1 case, the training score is a perfect 1.0. But the test score
 is only 0.80. As k increases to 3, the training score drops to 0.88 but
 the test score rises slightly 2.88, indicating the model is 
generalizing better to new data. When k = 11, the training score drops a
 bit further to 0.81, but the test score even better at 0.92, indicating
 that this simple model is much more effective at ignoring minor 
variations in training data. And instead capturing the more important 
global trend in where the classes tend to be located with the best 
overall generalization performance as a result.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: In the k = 1 case, the training score is a perfect 1.0. But the test score is only 0.80. As k increases to 3, the training score drops to 0.88 but the test score rises slightly 2.88, indicating the model is generalizing better to new data. When k = 11, the training score drops a bit further to 0.81, but the test score even better at 0.92, indicating that this simple model is much more effective at ignoring minor variations in training data. And instead capturing the more important global trend in where the classes tend to be located with the best overall generalization performance as a result." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit7a306e6f-2432-4aae-927c-4c3b90a2b367 Edit7a306e6f-2432-4aae-927c-4c3b90a2b367Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit7a306e6f-2432-4aae-927c-4c3b90a2b367">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: In the k = 1 case, the training score is a perfect 1.0. But the test score is only 0.80. As k increases to 3, the training score drops to 0.88 but the test score rises slightly 2.88, indicating the model is generalizing better to new data. When k = 11, the training score drops a bit further to 0.81, but the test score even better at 0.92, indicating that this simple model is much more effective at ignoring minor variations in training data. And instead capturing the more important global trend in where the classes tend to be located with the best overall generalization performance as a result." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleteaa8be6ba-19e7-48b0-b171-d9311e6e00de Deleteaa8be6ba-19e7-48b0-b171-d9311e6e00deDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deleteaa8be6ba-19e7-48b0-b171-d9311e6e00de">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoaf546c53-f351-4f18-b05d-07549b938248 Videoaf546c53-f351-4f18-b05d-07549b938248Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoaf546c53-f351-4f18-b05d-07549b938248">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/I1cfu?t=607&quot;,&quot;itemId&quot;:&quot;I1cfu&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/I1cfu?t=607" href="https://www.coursera.org/learn/python-machine-learning/lecture/I1cfu?t=607" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">K-Nearest Neighbors: Classification and Regression</div></a><div class="video-details" aria-label="Duration">10:07 - 10:14</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">A
 value of 0 corresponds to a model that makes a constant value 
prediction that's always just a mean value of all the training target 
values.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: A value of 0 corresponds to a model that makes a constant value prediction that's always just a mean value of all the training target values." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit80b10203-e46e-43a8-b690-84a702536a0c Edit80b10203-e46e-43a8-b690-84a702536a0cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit80b10203-e46e-43a8-b690-84a702536a0c">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: A value of 0 corresponds to a model that makes a constant value prediction that's always just a mean value of all the training target values." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete979e1b3d-fd03-4891-9e2c-ef19f63ca7fb Delete979e1b3d-fd03-4891-9e2c-ef19f63ca7fbDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete979e1b3d-fd03-4891-9e2c-ef19f63ca7fb">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video641c917d-c68f-48d4-de6a-f8dc650571ec Video641c917d-c68f-48d4-de6a-f8dc650571ecDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video641c917d-c68f-48d4-de6a-f8dc650571ec">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/I1cfu?t=767&quot;,&quot;itemId&quot;:&quot;I1cfu&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/I1cfu?t=767" href="https://www.coursera.org/learn/python-machine-learning/lecture/I1cfu?t=767" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">K-Nearest Neighbors: Classification and Regression</div></a><div class="video-details" aria-label="Duration">12:47 - 13:04</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">So
 to sum up, and as a review of what we saw in week one. The two key 
parameters for both regression and classification in nearest neighbors 
models are naturally n-neighbors which controls the value of the number 
of neighbors to consider and thus the model complexity, as we saw.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: So to sum up, and as a review of what we saw in week one. The two key parameters for both regression and classification in nearest neighbors models are naturally n-neighbors which controls the value of the number of neighbors to consider and thus the model complexity, as we saw." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit85cab7b6-c701-4c65-83ae-502212001314 Edit85cab7b6-c701-4c65-83ae-502212001314Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit85cab7b6-c701-4c65-83ae-502212001314">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: So to sum up, and as a review of what we saw in week one. The two key parameters for both regression and classification in nearest neighbors models are naturally n-neighbors which controls the value of the number of neighbors to consider and thus the model complexity, as we saw." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleteec676bb4-6af2-471e-d81e-667ce56daad2 Deleteec676bb4-6af2-471e-d81e-667ce56daad2Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deleteec676bb4-6af2-471e-d81e-667ce56daad2">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video95b945f2-5ca5-4878-9fed-1ba940b5adf9 Video95b945f2-5ca5-4878-9fed-1ba940b5adf9Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video95b945f2-5ca5-4878-9fed-1ba940b5adf9">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/I1cfu?t=576&quot;,&quot;itemId&quot;:&quot;I1cfu&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/I1cfu?t=576" href="https://www.coursera.org/learn/python-machine-learning/lecture/I1cfu?t=576" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">K-Nearest Neighbors: Classification and Regression</div></a><div class="video-details" aria-label="Duration">9:36 - 9:52</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Because
 the target values in a regression problem are continuous as compared to
 the discrete values that we see for classifier target labels. To assess
 how well a regression model fits the data, we use a regression score 
called r-squared that's between 0 and 1</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Because the target values in a regression problem are continuous as compared to the discrete values that we see for classifier target labels. To assess how well a regression model fits the data, we use a regression score called r-squared that's between 0 and 1" tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit47213f44-2c57-4661-d3ec-61c6c96707de Edit47213f44-2c57-4661-d3ec-61c6c96707deDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit47213f44-2c57-4661-d3ec-61c6c96707de">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Because the target values in a regression problem are continuous as compared to the discrete values that we see for classifier target labels. To assess how well a regression model fits the data, we use a regression score called r-squared that's between 0 and 1" tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletee962d96f-f8bc-45d7-d419-ee449b9ecaec Deletee962d96f-f8bc-45d7-d419-ee449b9ecaecDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletee962d96f-f8bc-45d7-d419-ee449b9ecaec">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video34fc0af6-e819-4c36-d54e-0ecb8b7a7392 Video34fc0af6-e819-4c36-d54e-0ecb8b7a7392Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video34fc0af6-e819-4c36-d54e-0ecb8b7a7392">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/I1cfu?t=744&quot;,&quot;itemId&quot;:&quot;I1cfu&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/I1cfu?t=744" href="https://www.coursera.org/learn/python-machine-learning/lecture/I1cfu?t=744" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">K-Nearest Neighbors: Classification and Regression</div></a><div class="video-details" aria-label="Duration">12:24 - 12:44</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">When
 the training data has many instances, or each instance has lots of 
features, this can really slow down the performance of a k-nearest 
neighbors model. So in general, if your data set has hundreds or 
thousands of features, you should consider alternatives to k-nearest 
neighbors models, especially if your data is sparse. Meaning that each 
instance has lots of features, but most of them are zero.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: When the training data has many instances, or each instance has lots of features, this can really slow down the performance of a k-nearest neighbors model. So in general, if your data set has hundreds or thousands of features, you should consider alternatives to k-nearest neighbors models, especially if your data is sparse. Meaning that each instance has lots of features, but most of them are zero." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit61aab30e-0ea2-430b-e964-c81922249a0a Edit61aab30e-0ea2-430b-e964-c81922249a0aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit61aab30e-0ea2-430b-e964-c81922249a0a">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: When the training data has many instances, or each instance has lots of features, this can really slow down the performance of a k-nearest neighbors model. So in general, if your data set has hundreds or thousands of features, you should consider alternatives to k-nearest neighbors models, especially if your data is sparse. Meaning that each instance has lots of features, but most of them are zero." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletee69a7c83-4730-4720-8b4a-debf1d1333bb Deletee69a7c83-4730-4720-8b4a-debf1d1333bbDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletee69a7c83-4730-4720-8b4a-debf1d1333bb">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video84fc6336-42fe-4a76-f436-4f4e61b3934c Video84fc6336-42fe-4a76-f436-4f4e61b3934cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video84fc6336-42fe-4a76-f436-4f4e61b3934c">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/I1cfu?t=263&quot;,&quot;itemId&quot;:&quot;I1cfu&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/I1cfu?t=263" href="https://www.coursera.org/learn/python-machine-learning/lecture/I1cfu?t=263" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">K-Nearest Neighbors: Classification and Regression</div></a><div class="video-details" aria-label="Duration">4:23 - 4:36</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">if
 we increased k even higher to be the total number of points in the 
training set, the result would be a single decision region where all 
predictions would be the most frequent class in the training data.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: if we increased k even higher to be the total number of points in the training set, the result would be a single decision region where all predictions would be the most frequent class in the training data." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editf3795ecf-c0e2-42e4-90d4-b6916a61b232 Editf3795ecf-c0e2-42e4-90d4-b6916a61b232Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editf3795ecf-c0e2-42e4-90d4-b6916a61b232">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: if we increased k even higher to be the total number of points in the training set, the result would be a single decision region where all predictions would be the most frequent class in the training data." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletec12007ba-de67-4694-c06b-4efa905aa2e3 Deletec12007ba-de67-4694-c06b-4efa905aa2e3Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletec12007ba-de67-4694-c06b-4efa905aa2e3">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video0c4565be-7d01-488f-d7e2-60d90e6a0970 Video0c4565be-7d01-488f-d7e2-60d90e6a0970Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video0c4565be-7d01-488f-d7e2-60d90e6a0970">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/I1cfu?t=785&quot;,&quot;itemId&quot;:&quot;I1cfu&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/I1cfu?t=785" href="https://www.coursera.org/learn/python-machine-learning/lecture/I1cfu?t=785" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">K-Nearest Neighbors: Classification and Regression</div></a><div class="video-details" aria-label="Duration">13:05 - 13:15</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">And
 the metric parameter which controls the distance function between 
points and thus which points are considered as nearest in finding 
neighbors.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: And the metric parameter which controls the distance function between points and thus which points are considered as nearest in finding neighbors." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit7a7ec5c7-0a96-41d8-b1cd-bba990214640 Edit7a7ec5c7-0a96-41d8-b1cd-bba990214640Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit7a7ec5c7-0a96-41d8-b1cd-bba990214640">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: And the metric parameter which controls the distance function between points and thus which points are considered as nearest in finding neighbors." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete7c9c658b-c438-466f-ed67-8695b4a22f24 Delete7c9c658b-c438-466f-ed67-8695b4a22f24Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete7c9c658b-c438-466f-ed67-8695b4a22f24">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoee598d85-d5a5-46ea-9416-23978f7f78ff Videoee598d85-d5a5-46ea-9416-23978f7f78ffDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videoee598d85-d5a5-46ea-9416-23978f7f78ff">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/I1cfu?t=597&quot;,&quot;itemId&quot;:&quot;I1cfu&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/I1cfu?t=597" href="https://www.coursera.org/learn/python-machine-learning/lecture/I1cfu?t=597" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">K-Nearest Neighbors: Classification and Regression</div></a><div class="video-details" aria-label="Duration">9:57 - 10:06</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">For the r-squared value, a value of 1 corresponds to the best possible performance. A model that makes perfect predictions.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: For the r-squared value, a value of 1 corresponds to the best possible performance. A model that makes perfect predictions." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit06b986ac-614f-49c5-a3e3-deff3b18fc38 Edit06b986ac-614f-49c5-a3e3-deff3b18fc38Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit06b986ac-614f-49c5-a3e3-deff3b18fc38">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: For the r-squared value, a value of 1 corresponds to the best possible performance. A model that makes perfect predictions." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete12cfa616-9e2b-4ff8-fafd-997d8d4dec58 Delete12cfa616-9e2b-4ff8-fafd-997d8d4dec58Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete12cfa616-9e2b-4ff8-fafd-997d8d4dec58">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoccdac159-ea86-4683-8a5a-82592d53d798 Videoccdac159-ea86-4683-8a5a-82592d53d798Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoccdac159-ea86-4683-8a5a-82592d53d798">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/I1cfu?t=519&quot;,&quot;itemId&quot;:&quot;I1cfu&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/I1cfu?t=519" href="https://www.coursera.org/learn/python-machine-learning/lecture/I1cfu?t=519" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">K-Nearest Neighbors: Classification and Regression</div></a><div class="video-details" aria-label="Duration">8:39 - 8:55</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">So
 we can average these three target values. And if we do that, we find 
that the output, when the query point is this X-value, is going to be 
the average of the y-values of the three nearest training points</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: So we can average these three target values. And if we do that, we find that the output, when the query point is this X-value, is going to be the average of the y-values of the three nearest training points" tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit1f8d7bd7-d58d-45c7-d82a-108d52f78dcb Edit1f8d7bd7-d58d-45c7-d82a-108d52f78dcbDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit1f8d7bd7-d58d-45c7-d82a-108d52f78dcb">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: So we can average these three target values. And if we do that, we find that the output, when the query point is this X-value, is going to be the average of the y-values of the three nearest training points" tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete55908472-0d60-4079-d402-2937e60ac208 Delete55908472-0d60-4079-d402-2937e60ac208Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete55908472-0d60-4079-d402-2937e60ac208">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video3b918cf5-ab28-4de0-feab-caf865545d04 Video3b918cf5-ab28-4de0-feab-caf865545d04Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video3b918cf5-ab28-4de0-feab-caf865545d04">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/I1cfu?t=649&quot;,&quot;itemId&quot;:&quot;I1cfu&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/I1cfu?t=649" href="https://www.coursera.org/learn/python-machine-learning/lecture/I1cfu?t=649" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">K-Nearest Neighbors: Classification and Regression</div></a><div class="video-details" aria-label="Duration">10:49 - 11:04</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">We
 can see the same pattern in model complexity for k and N regression 
that we saw for k and N classification. Namely, that small values of k 
give models with higher complexity. And large values of k result in 
simpler models with lower complexity.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: We can see the same pattern in model complexity for k and N regression that we saw for k and N classification. Namely, that small values of k give models with higher complexity. And large values of k result in simpler models with lower complexity." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editeed8f5b8-4a6c-47ce-a899-531b43dbe6cb Editeed8f5b8-4a6c-47ce-a899-531b43dbe6cbDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editeed8f5b8-4a6c-47ce-a899-531b43dbe6cb">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: We can see the same pattern in model complexity for k and N regression that we saw for k and N classification. Namely, that small values of k give models with higher complexity. And large values of k result in simpler models with lower complexity." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletef9b86a20-4e40-4e7a-c77d-c27a091c4bde Deletef9b86a20-4e40-4e7a-c77d-c27a091c4bdeDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletef9b86a20-4e40-4e7a-c77d-c27a091c4bde">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video35969532-a98b-4c72-d71a-92e1c05c18f0 Video35969532-a98b-4c72-d71a-92e1c05c18f0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video35969532-a98b-4c72-d71a-92e1c05c18f0">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/I1cfu?t=616&quot;,&quot;itemId&quot;:&quot;I1cfu&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/I1cfu?t=616" href="https://www.coursera.org/learn/python-machine-learning/lecture/I1cfu?t=616" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">K-Nearest Neighbors: Classification and Regression</div></a><div class="video-details" aria-label="Duration">10:16 - 10:20</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">The r-squared value is sometimes known as the coefficient of determination.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: The r-squared value is sometimes known as the coefficient of determination." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit2431d624-de95-4235-da30-48da33e2ffc3 Edit2431d624-de95-4235-da30-48da33e2ffc3Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit2431d624-de95-4235-da30-48da33e2ffc3">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: The r-squared value is sometimes known as the coefficient of determination." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete06dc6487-3b13-4a02-d90c-e1d2adbd6bf1 Delete06dc6487-3b13-4a02-d90c-e1d2adbd6bf1Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete06dc6487-3b13-4a02-d90c-e1d2adbd6bf1">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videobe1890c2-b029-4cc2-a196-8d712fbe5ab5 Videobe1890c2-b029-4cc2-a196-8d712fbe5ab5Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videobe1890c2-b029-4cc2-a196-8d712fbe5ab5">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/I1cfu?t=354&quot;,&quot;itemId&quot;:&quot;I1cfu&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/I1cfu?t=354" href="https://www.coursera.org/learn/python-machine-learning/lecture/I1cfu?t=354" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">K-Nearest Neighbors: Classification and Regression</div></a><div class="video-details" aria-label="Duration">5:54 - 5:59</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">The nearest neighbors approach isn't useful just for classification. You can use it for regression too.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: The nearest neighbors approach isn't useful just for classification. You can use it for regression too." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editccf4df82-c85b-4463-c1db-469fa8a88beb Editccf4df82-c85b-4463-c1db-469fa8a88bebDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editccf4df82-c85b-4463-c1db-469fa8a88beb">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: The nearest neighbors approach isn't useful just for classification. You can use it for regression too." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete56e5c912-4bde-4188-f195-47daf51e02f0 Delete56e5c912-4bde-4188-f195-47daf51e02f0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete56e5c912-4bde-4188-f195-47daf51e02f0">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video68067f66-adfb-48e9-bc70-df9abc8d2bfe Video68067f66-adfb-48e9-bc70-df9abc8d2bfeDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video68067f66-adfb-48e9-bc70-df9abc8d2bfe">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/EiQjD?t=634&quot;,&quot;itemId&quot;:&quot;EiQjD&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/EiQjD?t=634" href="https://www.coursera.org/learn/python-machine-learning/lecture/EiQjD?t=634" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Least-Squares</div></a><div class="video-details" aria-label="Duration">10:34 - 10:43</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Linear
 models may seem simplistic, but for data with many features linear 
models can be very effective and generalize well to new data beyond the 
training set.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Linear models may seem simplistic, but for data with many features linear models can be very effective and generalize well to new data beyond the training set." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit81863fc0-bf44-4cc1-8c50-2a0081ff033e Edit81863fc0-bf44-4cc1-8c50-2a0081ff033eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit81863fc0-bf44-4cc1-8c50-2a0081ff033e">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Linear models may seem simplistic, but for data with many features linear models can be very effective and generalize well to new data beyond the training set." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletef88ff909-8b79-4945-b59b-e4eea9c37e6c Deletef88ff909-8b79-4945-b59b-e4eea9c37e6cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletef88ff909-8b79-4945-b59b-e4eea9c37e6c">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoccaf8390-e25e-49d6-e031-33612424c7f0 Videoccaf8390-e25e-49d6-e031-33612424c7f0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoccaf8390-e25e-49d6-e031-33612424c7f0">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/EiQjD?t=163&quot;,&quot;itemId&quot;:&quot;EiQjD&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/EiQjD?t=163" href="https://www.coursera.org/learn/python-machine-learning/lecture/EiQjD?t=163" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Least-Squares</div></a><div class="video-details" aria-label="Duration">2:43 - 2:46</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">The predicted output, which we denote y hat,</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: The predicted output, which we denote y hat," tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editff6b11bb-511c-4f19-c786-f816153ef2f3 Editff6b11bb-511c-4f19-c786-f816153ef2f3Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editff6b11bb-511c-4f19-c786-f816153ef2f3">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: The predicted output, which we denote y hat," tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete0838297e-fb91-4101-fc28-994eb8841573 Delete0838297e-fb91-4101-fc28-994eb8841573Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete0838297e-fb91-4101-fc28-994eb8841573">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videodf6ea116-c20b-4884-e011-caa324439dd0 Videodf6ea116-c20b-4884-e011-caa324439dd0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videodf6ea116-c20b-4884-e011-caa324439dd0">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/EiQjD?t=416&quot;,&quot;itemId&quot;:&quot;EiQjD&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/EiQjD?t=416" href="https://www.coursera.org/learn/python-machine-learning/lecture/EiQjD?t=416" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Least-Squares</div></a><div class="video-details" aria-label="Duration">6:56 - 7:27</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">So
 widely used method for estimating w and b for linear aggression 
problems is called least-squares linear regression, also known as 
ordinary least-squares. Least-squares linear regression finds the line 
through this cloud of points that minimizes what is called the means 
squared error of the model. The mean squared error of the model is 
essentially the sum of the squared differences between the predicted 
target value and the actual target value for all the points in the 
training set.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: So widely used method for estimating w and b for linear aggression problems is called least-squares linear regression, also known as ordinary least-squares. Least-squares linear regression finds the line through this cloud of points that minimizes what is called the means squared error of the model. The mean squared error of the model is essentially the sum of the squared differences between the predicted target value and the actual target value for all the points in the training set." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit13dce997-3e85-469b-8d43-239471f14ae5 Edit13dce997-3e85-469b-8d43-239471f14ae5Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit13dce997-3e85-469b-8d43-239471f14ae5">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: So widely used method for estimating w and b for linear aggression problems is called least-squares linear regression, also known as ordinary least-squares. Least-squares linear regression finds the line through this cloud of points that minimizes what is called the means squared error of the model. The mean squared error of the model is essentially the sum of the squared differences between the predicted target value and the actual target value for all the points in the training set." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete01aeb10b-0385-474a-9a2d-c289efb911aa Delete01aeb10b-0385-474a-9a2d-c289efb911aaDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete01aeb10b-0385-474a-9a2d-c289efb911aa">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video8c326c40-d56b-4a98-c7bf-85dd0a393f57 Video8c326c40-d56b-4a98-c7bf-85dd0a393f57Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video8c326c40-d56b-4a98-c7bf-85dd0a393f57">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/EiQjD?t=802&quot;,&quot;itemId&quot;:&quot;EiQjD&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/EiQjD?t=802" href="https://www.coursera.org/learn/python-machine-learning/lecture/EiQjD?t=802" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Least-Squares</div></a><div class="video-details" aria-label="Duration">13:22 - 13:31</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Here,
 there are no parameters to control model complexity. The linear model 
always uses all of the input variables and always is represented by a 
straight line.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Here, there are no parameters to control model complexity. The linear model always uses all of the input variables and always is represented by a straight line." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editbfd60ab4-fd3e-420a-f40e-74c88a395e9d Editbfd60ab4-fd3e-420a-f40e-74c88a395e9dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editbfd60ab4-fd3e-420a-f40e-74c88a395e9d">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Here, there are no parameters to control model complexity. The linear model always uses all of the input variables and always is represented by a straight line." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletee1af9e81-5675-4b46-ddc3-f2d9374fa9cb Deletee1af9e81-5675-4b46-ddc3-f2d9374fa9cbDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletee1af9e81-5675-4b46-ddc3-f2d9374fa9cb">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video28ee0363-05c1-440c-951a-263a53b4fcc7 Video28ee0363-05c1-440c-951a-263a53b4fcc7Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video28ee0363-05c1-440c-951a-263a53b4fcc7">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/EiQjD?t=148&quot;,&quot;itemId&quot;:&quot;EiQjD&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/EiQjD?t=148" href="https://www.coursera.org/learn/python-machine-learning/lecture/EiQjD?t=148" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Least-Squares</div></a><div class="video-details" aria-label="Duration">2:28 - 2:36</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">More
 generally, in a linear regression model, there may be multiple input 
variables, or features, which we'll denote x0, x1, etc.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: More generally, in a linear regression model, there may be multiple input variables, or features, which we'll denote x0, x1, etc." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editb0b3f830-f54b-4c21-acd9-0f78cb80150d Editb0b3f830-f54b-4c21-acd9-0f78cb80150dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editb0b3f830-f54b-4c21-acd9-0f78cb80150d">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: More generally, in a linear regression model, there may be multiple input variables, or features, which we'll denote x0, x1, etc." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletecb17e4da-2df2-40fe-a684-175aed030f24 Deletecb17e4da-2df2-40fe-a684-175aed030f24Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletecb17e4da-2df2-40fe-a684-175aed030f24">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoe8fc24d8-70e2-4b8f-ba8f-cf64f5e567a8 Videoe8fc24d8-70e2-4b8f-ba8f-cf64f5e567a8Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoe8fc24d8-70e2-4b8f-ba8f-cf64f5e567a8">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/EiQjD?t=594&quot;,&quot;itemId&quot;:&quot;EiQjD&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/EiQjD?t=594" href="https://www.coursera.org/learn/python-machine-learning/lecture/EiQjD?t=594" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Least-Squares</div></a><div class="video-details" aria-label="Duration">9:54 - 10:01</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">One thing to note about this linear regression model is that there are no parameters to control the model complexity.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: One thing to note about this linear regression model is that there are no parameters to control the model complexity." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit87f0b811-e403-4015-db3e-c31337efe174 Edit87f0b811-e403-4015-db3e-c31337efe174Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit87f0b811-e403-4015-db3e-c31337efe174">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: One thing to note about this linear regression model is that there are no parameters to control the model complexity." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete8ae0ed2a-8d21-4e58-d9a0-99ffdaa9b6ac Delete8ae0ed2a-8d21-4e58-d9a0-99ffdaa9b6acDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete8ae0ed2a-8d21-4e58-d9a0-99ffdaa9b6ac">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videof3fb4062-13f3-4389-a8d0-09ee94c4f493 Videof3fb4062-13f3-4389-a8d0-09ee94c4f493Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videof3fb4062-13f3-4389-a8d0-09ee94c4f493">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/EiQjD?t=837&quot;,&quot;itemId&quot;:&quot;EiQjD&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/EiQjD?t=837" href="https://www.coursera.org/learn/python-machine-learning/lecture/EiQjD?t=837" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Least-Squares</div></a><div class="video-details" aria-label="Duration">13:57 - 14:04</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Linear regression in Scikit-Learn is implemented by the linear regression class in the sklearn.linear_model module.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Linear regression in Scikit-Learn is implemented by the linear regression class in the sklearn.linear_model module." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edite73e0038-56b8-4821-b29a-eafc7b12e142 Edite73e0038-56b8-4821-b29a-eafc7b12e142Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edite73e0038-56b8-4821-b29a-eafc7b12e142">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Linear regression in Scikit-Learn is implemented by the linear regression class in the sklearn.linear_model module." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletea9b5f922-7595-47ac-81b8-e27ee4974cbc Deletea9b5f922-7595-47ac-81b8-e27ee4974cbcDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletea9b5f922-7595-47ac-81b8-e27ee4974cbc">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video6634bbd0-d63f-4524-9040-d3272a4e14ad Video6634bbd0-d63f-4524-9040-d3272a4e14adDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video6634bbd0-d63f-4524-9040-d3272a4e14ad">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/EiQjD?t=603&quot;,&quot;itemId&quot;:&quot;EiQjD&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/EiQjD?t=603" href="https://www.coursera.org/learn/python-machine-learning/lecture/EiQjD?t=603" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Least-Squares</div></a><div class="video-details" aria-label="Duration">10:03 - 10:08</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">No matter what the value of w and b, the result is always going to be a straight line.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: No matter what the value of w and b, the result is always going to be a straight line." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edite92bd782-ad8c-445a-cd34-74af84c3b993 Edite92bd782-ad8c-445a-cd34-74af84c3b993Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edite92bd782-ad8c-445a-cd34-74af84c3b993">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: No matter what the value of w and b, the result is always going to be a straight line." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete7a4c86aa-9bf8-4439-c8b3-18ed18c13357 Delete7a4c86aa-9bf8-4439-c8b3-18ed18c13357Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete7a4c86aa-9bf8-4439-c8b3-18ed18c13357">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video5e291061-326d-4e1a-8c0d-8e9430a7b0e4 Video5e291061-326d-4e1a-8c0d-8e9430a7b0e4Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video5e291061-326d-4e1a-8c0d-8e9430a7b0e4">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/EiQjD?t=139&quot;,&quot;itemId&quot;:&quot;EiQjD&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/EiQjD?t=139" href="https://www.coursera.org/learn/python-machine-learning/lecture/EiQjD?t=139" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Least-Squares</div></a><div class="video-details" aria-label="Duration">2:19 - 2:27</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Predicting house price is an example of a regression task using a linear model called, not surprisingly, linear regression.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Predicting house price is an example of a regression task using a linear model called, not surprisingly, linear regression." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit7d55cf63-43b8-473e-8d99-415bfb58a3a0 Edit7d55cf63-43b8-473e-8d99-415bfb58a3a0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit7d55cf63-43b8-473e-8d99-415bfb58a3a0">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Predicting house price is an example of a regression task using a linear model called, not surprisingly, linear regression." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete5684e3f3-76ee-4f49-be9f-2845fb56241a Delete5684e3f3-76ee-4f49-be9f-2845fb56241aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete5684e3f3-76ee-4f49-be9f-2845fb56241a">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video0fdafe5a-57ea-44b0-e2cb-b30da9e30f75 Video0fdafe5a-57ea-44b0-e2cb-b30da9e30f75Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video0fdafe5a-57ea-44b0-e2cb-b30da9e30f75">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/EiQjD?t=556&quot;,&quot;itemId&quot;:&quot;EiQjD&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/EiQjD?t=556" href="https://www.coursera.org/learn/python-machine-learning/lecture/EiQjD?t=556" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Least-Squares</div></a><div class="video-details" aria-label="Duration">9:16 - 9:30</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">the
 square difference can be computed, and then if we add all these up, And
 divide by the number of training points, take the average, that will be
 the mean squared error of the model.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: the square difference can be computed, and then if we add all these up, And divide by the number of training points, take the average, that will be the mean squared error of the model." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit7560a780-5d96-4fdf-a409-ab1ed27ea58f Edit7560a780-5d96-4fdf-a409-ab1ed27ea58fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit7560a780-5d96-4fdf-a409-ab1ed27ea58f">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: the square difference can be computed, and then if we add all these up, And divide by the number of training points, take the average, that will be the mean squared error of the model." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletec1563d56-9aa3-4768-9f31-e78e0ebc32d9 Deletec1563d56-9aa3-4768-9f31-e78e0ebc32d9Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletec1563d56-9aa3-4768-9f31-e78e0ebc32d9">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video7f299966-2727-47af-e3f8-1efebade3c9f Video7f299966-2727-47af-e3f8-1efebade3c9fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video7f299966-2727-47af-e3f8-1efebade3c9f">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/EiQjD?t=815&quot;,&quot;itemId&quot;:&quot;EiQjD&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/EiQjD?t=815" href="https://www.coursera.org/learn/python-machine-learning/lecture/EiQjD?t=815" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Least-Squares</div></a><div class="video-details" aria-label="Duration">13:35 - 13:39</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Another name for this quantity is the residual sum of squares.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Another name for this quantity is the residual sum of squares." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit96564a47-2199-4cc0-afa1-f20ad8836a24 Edit96564a47-2199-4cc0-afa1-f20ad8836a24Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit96564a47-2199-4cc0-afa1-f20ad8836a24">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Another name for this quantity is the residual sum of squares." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete8100d0a5-2da9-4110-c6e3-94bfd13003cb Delete8100d0a5-2da9-4110-c6e3-94bfd13003cbDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete8100d0a5-2da9-4110-c6e3-94bfd13003cb">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video1c8f9983-4928-4256-e8b2-837997e948b1 Video1c8f9983-4928-4256-e8b2-837997e948b1Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video1c8f9983-4928-4256-e8b2-837997e948b1">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/EiQjD?t=792&quot;,&quot;itemId&quot;:&quot;EiQjD&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/EiQjD?t=792" href="https://www.coursera.org/learn/python-machine-learning/lecture/EiQjD?t=792" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Least-Squares</div></a><div class="video-details" aria-label="Duration">13:12 - 13:21</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Adding
 up all the squared values of these differences for all the training 
points gives the total squared error and this is what the least-square 
solution minimizes.</div><div class="video-note-text-box video-note-text" aria-label="User Note">xxxxx</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Adding up all the squared values of these differences for all the training points gives the total squared error and this is what the least-square solution minimizes." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edite0744631-0ffc-4eaf-dd41-e3782e45a573 Edite0744631-0ffc-4eaf-dd41-e3782e45a573Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edite0744631-0ffc-4eaf-dd41-e3782e45a573">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Adding up all the squared values of these differences for all the training points gives the total squared error and this is what the least-square solution minimizes." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete2a4d7dcc-d6e9-4987-dc5b-1c67b6559910 Delete2a4d7dcc-d6e9-4987-dc5b-1c67b6559910Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete2a4d7dcc-d6e9-4987-dc5b-1c67b6559910">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video099759ef-eb76-44b5-f5d1-208aa887a29a Video099759ef-eb76-44b5-f5d1-208aa887a29aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video099759ef-eb76-44b5-f5d1-208aa887a29a">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/EiQjD?t=157&quot;,&quot;itemId&quot;:&quot;EiQjD&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/EiQjD?t=157" href="https://www.coursera.org/learn/python-machine-learning/lecture/EiQjD?t=157" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Least-Squares</div></a><div class="video-details" aria-label="Duration">2:37 - 2:41</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Each feature, xi, has a corresponding weight, wi.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Each feature, xi, has a corresponding weight, wi." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editdc249a3b-a331-4c15-ed56-5f42b3b78a7a Editdc249a3b-a331-4c15-ed56-5f42b3b78a7aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editdc249a3b-a331-4c15-ed56-5f42b3b78a7a">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Each feature, xi, has a corresponding weight, wi." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleted6637424-f9c5-4513-bb22-9b59f3979fe1 Deleted6637424-f9c5-4513-bb22-9b59f3979fe1Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deleted6637424-f9c5-4513-bb22-9b59f3979fe1">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoee52e14a-e6c4-41f4-ec07-871facd1c63d Videoee52e14a-e6c4-41f4-ec07-871facd1c63dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videoee52e14a-e6c4-41f4-ec07-871facd1c63d">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/EiQjD?t=214&quot;,&quot;itemId&quot;:&quot;EiQjD&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/EiQjD?t=214" href="https://www.coursera.org/learn/python-machine-learning/lecture/EiQjD?t=214" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Least-Squares</div></a><div class="video-details" aria-label="Duration">3:34 - 3:43</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">We
 called these wi values model coefficients or sometimes future weights, 
and b hat is called the bias term or the intercept of the model.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: We called these wi values model coefficients or sometimes future weights, and b hat is called the bias term or the intercept of the model." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit0d308f85-9a83-4766-f7ea-edb66f560613 Edit0d308f85-9a83-4766-f7ea-edb66f560613Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit0d308f85-9a83-4766-f7ea-edb66f560613">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: We called these wi values model coefficients or sometimes future weights, and b hat is called the bias term or the intercept of the model." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete84682924-4be3-45c5-8a7d-27a156377209 Delete84682924-4be3-45c5-8a7d-27a156377209Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete84682924-4be3-45c5-8a7d-27a156377209">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoce1adad3-83a7-4b13-ede7-8b6d874194a7 Videoce1adad3-83a7-4b13-ede7-8b6d874194a7Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoce1adad3-83a7-4b13-ede7-8b6d874194a7">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/EiQjD?t=733&quot;,&quot;itemId&quot;:&quot;EiQjD&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/EiQjD?t=733" href="https://www.coursera.org/learn/python-machine-learning/lecture/EiQjD?t=733" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Least-Squares</div></a><div class="video-details" aria-label="Duration">12:13 - 12:42</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">The
 most popular way to estimate w and b parameters is using what's called 
least-squares linear regression or ordinary least-squares. Least-squares
 finds the values of w and b that minimize the total sum of squared 
differences between the predicted y value and the actual y value in the 
training set. Or equivalently it minimizes the mean squared error of the
 model. Least-squares is based on the squared loss function mentioned 
before.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: The most popular way to estimate w and b parameters is using what's called least-squares linear regression or ordinary least-squares. Least-squares finds the values of w and b that minimize the total sum of squared differences between the predicted y value and the actual y value in the training set. Or equivalently it minimizes the mean squared error of the model. Least-squares is based on the squared loss function mentioned before." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editcea50b07-e5ad-41b7-c926-99f6a51d3c20 Editcea50b07-e5ad-41b7-c926-99f6a51d3c20Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editcea50b07-e5ad-41b7-c926-99f6a51d3c20">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: The most popular way to estimate w and b parameters is using what's called least-squares linear regression or ordinary least-squares. Least-squares finds the values of w and b that minimize the total sum of squared differences between the predicted y value and the actual y value in the training set. Or equivalently it minimizes the mean squared error of the model. Least-squares is based on the squared loss function mentioned before." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletef2fe4256-9c28-4ab8-a4e9-b3b382e4399d Deletef2fe4256-9c28-4ab8-a4e9-b3b382e4399dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletef2fe4256-9c28-4ab8-a4e9-b3b382e4399d">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video38bc07f4-a641-4320-978c-6872b81b368d Video38bc07f4-a641-4320-978c-6872b81b368dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video38bc07f4-a641-4320-978c-6872b81b368d">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/EiQjD?t=167&quot;,&quot;itemId&quot;:&quot;EiQjD&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/EiQjD?t=167" href="https://www.coursera.org/learn/python-machine-learning/lecture/EiQjD?t=167" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Least-Squares</div></a><div class="video-details" aria-label="Duration">2:47 - 2:51</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">is a weighted sum of features plus a constant term b hat.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: is a weighted sum of features plus a constant term b hat." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit0f5e704d-532a-4c6b-a4d6-1fcfc802142e Edit0f5e704d-532a-4c6b-a4d6-1fcfc802142eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit0f5e704d-532a-4c6b-a4d6-1fcfc802142e">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: is a weighted sum of features plus a constant term b hat." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete83864719-abfd-4b23-ccac-59b9af23eb47 Delete83864719-abfd-4b23-ccac-59b9af23eb47Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete83864719-abfd-4b23-ccac-59b9af23eb47">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoe4fa01d5-7941-408f-d290-c9b5a952d3a5 Videoe4fa01d5-7941-408f-d290-c9b5a952d3a5Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoe4fa01d5-7941-408f-d290-c9b5a952d3a5">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=567&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=567" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=567" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">9:27 - 9:49</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">
 In general, regularisation works especially well when you have 
relatively small amounts of training data compared to the number of 
features in your model. Regularisation becomes less important as the 
amount of training data you have increases. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text:  In general, regularisation works especially well when you have relatively small amounts of training data compared to the number of features in your model. Regularisation becomes less important as the amount of training data you have increases. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit1373f912-8bcc-4f2b-9d81-e9cc966b537c Edit1373f912-8bcc-4f2b-9d81-e9cc966b537cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit1373f912-8bcc-4f2b-9d81-e9cc966b537c">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text:  In general, regularisation works especially well when you have relatively small amounts of training data compared to the number of features in your model. Regularisation becomes less important as the amount of training data you have increases. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletee6fc8da4-6dd0-46e3-a18d-96fdb7901ba3 Deletee6fc8da4-6dd0-46e3-a18d-96fdb7901ba3Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletee6fc8da4-6dd0-46e3-a18d-96fdb7901ba3">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video966c33ba-a494-4926-fd21-5a74b9f504ea Video966c33ba-a494-4926-fd21-5a74b9f504eaDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video966c33ba-a494-4926-fd21-5a74b9f504ea">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=275&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=275" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=275" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">4:35 - 4:53</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">So
 transforming the input features, so they're all on the same scale, 
means the ridge penalty is in some sense applied more fairly to all 
features without unduly weighting some more than others, just because of
 the difference in scales.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: So transforming the input features, so they're all on the same scale, means the ridge penalty is in some sense applied more fairly to all features without unduly weighting some more than others, just because of the difference in scales." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit8872c69c-c472-4d1e-9305-6c5a988bebfb Edit8872c69c-c472-4d1e-9305-6c5a988bebfbDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit8872c69c-c472-4d1e-9305-6c5a988bebfb">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: So transforming the input features, so they're all on the same scale, means the ridge penalty is in some sense applied more fairly to all features without unduly weighting some more than others, just because of the difference in scales." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete13b5b210-a096-4d5c-ff89-4344ec28a5fb Delete13b5b210-a096-4d5c-ff89-4344ec28a5fbDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete13b5b210-a096-4d5c-ff89-4344ec28a5fb">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video2c070d3d-4575-45a8-a1cf-e9513d41d2dc Video2c070d3d-4575-45a8-a1cf-e9513d41d2dcDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video2c070d3d-4575-45a8-a1cf-e9513d41d2dc">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=375&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=375" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=375" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">6:15 - 6:25</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">To apply minmax scaling, in scikit-learn, you import the minmax scalar object from sklearn.preprocessing.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: To apply minmax scaling, in scikit-learn, you import the minmax scalar object from sklearn.preprocessing." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit808a204c-f71e-4a32-8ba9-84d547c0520e Edit808a204c-f71e-4a32-8ba9-84d547c0520eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit808a204c-f71e-4a32-8ba9-84d547c0520e">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: To apply minmax scaling, in scikit-learn, you import the minmax scalar object from sklearn.preprocessing." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletee07d0224-f8a9-424f-a3d7-c4f4710c251c Deletee07d0224-f8a9-424f-a3d7-c4f4710c251cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletee07d0224-f8a9-424f-a3d7-c4f4710c251c">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video67aa5e26-61d3-4721-cd9f-18f7e1553a7f Video67aa5e26-61d3-4721-cd9f-18f7e1553a7fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video67aa5e26-61d3-4721-cd9f-18f7e1553a7f">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=108&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=108" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=108" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">1:48 - 2:13</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Because
 our goal is to minimize the overall objective function, the 
regularisation term acts as a penalty of models with lots of large 
feature weight values. In other words, all things being equal, if ridge 
regression finds two possible linear models that predict the training 
data values equally well, it will prefer the linear model that has a 
smaller overall sum of squared feature weights.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Because our goal is to minimize the overall objective function, the regularisation term acts as a penalty of models with lots of large feature weight values. In other words, all things being equal, if ridge regression finds two possible linear models that predict the training data values equally well, it will prefer the linear model that has a smaller overall sum of squared feature weights." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit18a666b7-cdb3-420a-f3de-2494cf747e27 Edit18a666b7-cdb3-420a-f3de-2494cf747e27Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit18a666b7-cdb3-420a-f3de-2494cf747e27">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Because our goal is to minimize the overall objective function, the regularisation term acts as a penalty of models with lots of large feature weight values. In other words, all things being equal, if ridge regression finds two possible linear models that predict the training data values equally well, it will prefer the linear model that has a smaller overall sum of squared feature weights." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletee9eab865-68e5-4af7-8fe9-24038b3e8cfa Deletee9eab865-68e5-4af7-8fe9-24038b3e8cfaDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletee9eab865-68e5-4af7-8fe9-24038b3e8cfa">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoeb63dd39-1f16-4a9d-b861-4fe34a9e9068 Videoeb63dd39-1f16-4a9d-b861-4fe34a9e9068Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoeb63dd39-1f16-4a9d-b861-4fe34a9e9068">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=187&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=187" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=187" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">3:07 - 3:31</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">In
 scikit learn, you use rich regression by importing the ridge class from
 sklearn.linear model. And then use that estimate or object just as you 
would for least-squares. The one difference is that you can specify the 
amount of the ridge regression regularisation penalty, which is called 
the L2 penalty, using the alpha parameter.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: In scikit learn, you use rich regression by importing the ridge class from sklearn.linear model. And then use that estimate or object just as you would for least-squares. The one difference is that you can specify the amount of the ridge regression regularisation penalty, which is called the L2 penalty, using the alpha parameter." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit858467b2-8f61-4139-907f-d469369e1904 Edit858467b2-8f61-4139-907f-d469369e1904Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit858467b2-8f61-4139-907f-d469369e1904">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: In scikit learn, you use rich regression by importing the ridge class from sklearn.linear model. And then use that estimate or object just as you would for least-squares. The one difference is that you can specify the amount of the ridge regression regularisation penalty, which is called the L2 penalty, using the alpha parameter." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete48baf819-8d53-4527-8c02-872ddce5f1f1 Delete48baf819-8d53-4527-8c02-872ddce5f1f1Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete48baf819-8d53-4527-8c02-872ddce5f1f1">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video820773d3-d5a3-46bd-9a1f-53933b1a64bc Video820773d3-d5a3-46bd-9a1f-53933b1a64bcDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video820773d3-d5a3-46bd-9a1f-53933b1a64bc">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=465&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=465" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=465" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">7:45 - 7:54</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">f
 you don't apply the same scaling to training and test sets, you'll end 
up with more or less random data skew, which will invalidate your 
results.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: f you don't apply the same scaling to training and test sets, you'll end up with more or less random data skew, which will invalidate your results." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit2cb76196-dfe2-46cd-fbf4-b493684ab249 Edit2cb76196-dfe2-46cd-fbf4-b493684ab249Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit2cb76196-dfe2-46cd-fbf4-b493684ab249">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: f you don't apply the same scaling to training and test sets, you'll end up with more or less random data skew, which will invalidate your results." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete68f53c0d-49a5-4b2a-cb4c-3a95f38db174 Delete68f53c0d-49a5-4b2a-cb4c-3a95f38db174Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete68f53c0d-49a5-4b2a-cb4c-3a95f38db174">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video519d9d4c-f582-4584-d142-6591970d7021 Video519d9d4c-f582-4584-d142-6591970d7021Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video519d9d4c-f582-4584-d142-6591970d7021">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=316&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=316" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=316" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">5:16 - 5:29</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">a
 widely used form of future normalization called MinMax Scaling, that 
will transform all the input variables, so they're all on the same scale
 between zero and one.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: a widely used form of future normalization called MinMax Scaling, that will transform all the input variables, so they're all on the same scale between zero and one." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit604a61d7-d3f3-4ad0-8792-df624e9c865d Edit604a61d7-d3f3-4ad0-8792-df624e9c865dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit604a61d7-d3f3-4ad0-8792-df624e9c865d">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: a widely used form of future normalization called MinMax Scaling, that will transform all the input variables, so they're all on the same scale between zero and one." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleted10d1834-9875-42b5-b675-3c70a737046f Deleted10d1834-9875-42b5-b675-3c70a737046fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deleted10d1834-9875-42b5-b675-3c70a737046f">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video2b19f38c-0a3a-46b1-8b86-302103fcd466 Video2b19f38c-0a3a-46b1-8b86-302103fcd466Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video2b19f38c-0a3a-46b1-8b86-302103fcd466">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=14&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=14" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=14" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">0:14 - 0:29</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Ridge
 regression uses the same least-squares criterion, but with one 
difference. During the training phase, it adds a penalty for feature 
weights, the WI values that are too large</div><div class="video-note-text-box video-note-text" aria-label="User Note">xxxxx</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Ridge regression uses the same least-squares criterion, but with one difference. During the training phase, it adds a penalty for feature weights, the WI values that are too large" tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit5d12d857-108e-4556-b32c-1056cc06d310 Edit5d12d857-108e-4556-b32c-1056cc06d310Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit5d12d857-108e-4556-b32c-1056cc06d310">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Ridge regression uses the same least-squares criterion, but with one difference. During the training phase, it adds a penalty for feature weights, the WI values that are too large" tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete6bb8122e-3f87-4654-97a7-d33d236862ca Delete6bb8122e-3f87-4654-97a7-d33d236862caDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete6bb8122e-3f87-4654-97a7-d33d236862ca">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video09c2be49-2f69-4df0-f4ab-539c0c03855f Video09c2be49-2f69-4df0-f4ab-539c0c03855fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video09c2be49-2f69-4df0-f4ab-539c0c03855f">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=720&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=720" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=720" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">12:00 - 12:21</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">
 In general, lasso regression is most helpful if you think there are 
only a few variables that have a medium or large effect on the output 
variable. Otherwise if there are lots of variables that contribute small
 or medium effects, ridge regression is typically the better choice.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text:  In general, lasso regression is most helpful if you think there are only a few variables that have a medium or large effect on the output variable. Otherwise if there are lots of variables that contribute small or medium effects, ridge regression is typically the better choice." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit76a3da48-fed3-4283-f8e4-d7cb70f1952e Edit76a3da48-fed3-4283-f8e4-d7cb70f1952eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit76a3da48-fed3-4283-f8e4-d7cb70f1952e">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text:  In general, lasso regression is most helpful if you think there are only a few variables that have a medium or large effect on the output variable. Otherwise if there are lots of variables that contribute small or medium effects, ridge regression is typically the better choice." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete64873a5a-2cfd-4b44-ef70-eced56d3b849 Delete64873a5a-2cfd-4b44-ef70-eced56d3b849Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete64873a5a-2cfd-4b44-ef70-eced56d3b849">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video09e19542-9936-4859-e055-1023f84cd6c2 Video09e19542-9936-4859-e055-1023f84cd6c2Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video09e19542-9936-4859-e055-1023f84cd6c2">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=224&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=224" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=224" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">3:44 - 3:58</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">However
 there is something we can do in applying ridge regression that will 
improve the results dramatically. So now is the time for a brief 
digression about the need for feature preprocessing and normalization.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: However there is something we can do in applying ridge regression that will improve the results dramatically. So now is the time for a brief digression about the need for feature preprocessing and normalization." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edite313e9a3-183b-4537-e86f-960dae921e7a Edite313e9a3-183b-4537-e86f-960dae921e7aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edite313e9a3-183b-4537-e86f-960dae921e7a">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: However there is something we can do in applying ridge regression that will improve the results dramatically. So now is the time for a brief digression about the need for feature preprocessing and normalization." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletefa4fd8f3-b892-4b95-9193-943d3ab40d97 Deletefa4fd8f3-b892-4b95-9193-943d3ab40d97Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletefa4fd8f3-b892-4b95-9193-943d3ab40d97">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video7ec56911-2afd-4800-88c1-d494b7d737ce Video7ec56911-2afd-4800-88c1-d494b7d737ceDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video7ec56911-2afd-4800-88c1-d494b7d737ce">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=91&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=91" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=91" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">1:31 - 1:48</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">how
 does this work with linear regression? The addition of the sum of 
squared parameter values that's shown in the box, to the least-squares 
objective means that models with larger feature weights (w) add more to 
the objective functions overall value.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: how does this work with linear regression? The addition of the sum of squared parameter values that's shown in the box, to the least-squares objective means that models with larger feature weights (w) add more to the objective functions overall value." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit76379502-a3c8-41e1-e330-60ff88bf2d0a Edit76379502-a3c8-41e1-e330-60ff88bf2d0aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit76379502-a3c8-41e1-e330-60ff88bf2d0a">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: how does this work with linear regression? The addition of the sum of squared parameter values that's shown in the box, to the least-squares objective means that models with larger feature weights (w) add more to the objective functions overall value." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete5d2ac410-141c-4da6-a517-957ff39b5d7c Delete5d2ac410-141c-4da6-a517-957ff39b5d7cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete5d2ac410-141c-4da6-a517-957ff39b5d7c">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video3db78a00-b3e5-451c-9caa-728d3bf10617 Video3db78a00-b3e5-451c-9caa-728d3bf10617Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video3db78a00-b3e5-451c-9caa-728d3bf10617">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=749&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=749" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=749" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">12:29 - 12:46</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">To
 use lasso regression, you import the lasso class from sklearn.linear 
model, and then just use it as you would use an estimator like ridge 
regression. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: To use lasso regression, you import the lasso class from sklearn.linear model, and then just use it as you would use an estimator like ridge regression. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit18baa3fc-2cb1-4842-b24d-9f4a4c210204 Edit18baa3fc-2cb1-4842-b24d-9f4a4c210204Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit18baa3fc-2cb1-4842-b24d-9f4a4c210204">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: To use lasso regression, you import the lasso class from sklearn.linear model, and then just use it as you would use an estimator like ridge regression. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletea0d595b0-23a9-4c18-d71a-50fc6354fe73 Deletea0d595b0-23a9-4c18-d71a-50fc6354fe73Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletea0d595b0-23a9-4c18-d71a-50fc6354fe73">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video45bbb262-c577-42b2-ebfc-8bbfbf6b7ce9 Video45bbb262-c577-42b2-ebfc-8bbfbf6b7ce9Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video45bbb262-c577-42b2-ebfc-8bbfbf6b7ce9">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=985&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=985" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=985" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">16:25 - 17:06</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">
 When we add these new polynomial features, we're essentially adding to 
the model's ability to capture interactions between the different 
variables by adding them as features to the linear model. For example, 
it may be that housing prices vary as a quadratic function of both the 
lat size that a house sits on, and the amount of taxes paid on the 
property as a theoretical example. A simple linear model could not 
capture this nonlinear relationship, but by adding nonlinear features 
like polynomials to the linear regression model, we can capture this 
nonlinearity.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text:  When we add these new polynomial features, we're essentially adding to the model's ability to capture interactions between the different variables by adding them as features to the linear model. For example, it may be that housing prices vary as a quadratic function of both the lat size that a house sits on, and the amount of taxes paid on the property as a theoretical example. A simple linear model could not capture this nonlinear relationship, but by adding nonlinear features like polynomials to the linear regression model, we can capture this nonlinearity." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit091c2e1b-3e58-47e0-dfd7-64cadbbdf61d Edit091c2e1b-3e58-47e0-dfd7-64cadbbdf61dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit091c2e1b-3e58-47e0-dfd7-64cadbbdf61d">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text:  When we add these new polynomial features, we're essentially adding to the model's ability to capture interactions between the different variables by adding them as features to the linear model. For example, it may be that housing prices vary as a quadratic function of both the lat size that a house sits on, and the amount of taxes paid on the property as a theoretical example. A simple linear model could not capture this nonlinear relationship, but by adding nonlinear features like polynomials to the linear regression model, we can capture this nonlinearity." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletef7165a4c-d0c2-414a-b717-1d8c45f4166d Deletef7165a4c-d0c2-414a-b717-1d8c45f4166dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletef7165a4c-d0c2-414a-b717-1d8c45f4166d">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video935927ce-7c06-40b8-89f4-428e15a77695 Video935927ce-7c06-40b8-89f4-428e15a77695Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video935927ce-7c06-40b8-89f4-428e15a77695">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=697&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=697" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=697" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">11:37 - 11:54</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Like
 ridge regression, the amount of regularisation for the lasso regression
 is controlled by the parameter alpha, which by default is zero. Also 
like ridge regression, the purpose of using lasso regression is to 
estimate the WNB model coefficients.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Like ridge regression, the amount of regularisation for the lasso regression is controlled by the parameter alpha, which by default is zero. Also like ridge regression, the purpose of using lasso regression is to estimate the WNB model coefficients." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editb01f1b2e-2b64-4e63-ac85-80ff2679f824 Editb01f1b2e-2b64-4e63-ac85-80ff2679f824Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editb01f1b2e-2b64-4e63-ac85-80ff2679f824">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Like ridge regression, the amount of regularisation for the lasso regression is controlled by the parameter alpha, which by default is zero. Also like ridge regression, the purpose of using lasso regression is to estimate the WNB model coefficients." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete9727eaa3-ed73-4321-f45b-f3cb51aa193b Delete9727eaa3-ed73-4321-f45b-f3cb51aa193bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete9727eaa3-ed73-4321-f45b-f3cb51aa193b">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video657c7b41-be7b-4070-9aa8-8ef782da2ebf Video657c7b41-be7b-4070-9aa8-8ef782da2ebfDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video657c7b41-be7b-4070-9aa8-8ef782da2ebf">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=944&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=944" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=944" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">15:44 - 16:18</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">this
 is called polynomial future transformation that we can use to transform
 a problem into a higher dimensional regression space. And in effect, 
adding these extra polynomial features allows us a much richer set of 
complex functions that we can use to fit to the data. So you can think 
of this intuitively as allowing polynomials to be fit to the training 
data instead of simply a straight line, but using the same least-squares
 criterion that minimizes mean squared error. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: this is called polynomial future transformation that we can use to transform a problem into a higher dimensional regression space. And in effect, adding these extra polynomial features allows us a much richer set of complex functions that we can use to fit to the data. So you can think of this intuitively as allowing polynomials to be fit to the training data instead of simply a straight line, but using the same least-squares criterion that minimizes mean squared error. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit65bdb383-92ad-4431-e6c6-c683a87e515c Edit65bdb383-92ad-4431-e6c6-c683a87e515cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit65bdb383-92ad-4431-e6c6-c683a87e515c">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: this is called polynomial future transformation that we can use to transform a problem into a higher dimensional regression space. And in effect, adding these extra polynomial features allows us a much richer set of complex functions that we can use to fit to the data. So you can think of this intuitively as allowing polynomials to be fit to the training data instead of simply a straight line, but using the same least-squares criterion that minimizes mean squared error. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleteaf9b4cf8-59e7-4031-c5c9-6bd9f9c1e9ce Deleteaf9b4cf8-59e7-4031-c5c9-6bd9f9c1e9ceDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deleteaf9b4cf8-59e7-4031-c5c9-6bd9f9c1e9ce">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoc4136fa1-ca22-4768-9939-4c9ba66a67fd Videoc4136fa1-ca22-4768-9939-4c9ba66a67fdDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videoc4136fa1-ca22-4768-9939-4c9ba66a67fd">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=644&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=644" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=644" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">10:44 - 10:55</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Lasso regression uses a slightly different regularisation term called an L1 penalty, instead of ridge regression's L2 penalty </div><div class="video-note-text-box video-note-text" aria-label="User Note">xxxxx</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Lasso regression uses a slightly different regularisation term called an L1 penalty, instead of ridge regression's L2 penalty " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit68848e77-5f55-4c79-a6d9-12aad3e3663c Edit68848e77-5f55-4c79-a6d9-12aad3e3663cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit68848e77-5f55-4c79-a6d9-12aad3e3663c">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Lasso regression uses a slightly different regularisation term called an L1 penalty, instead of ridge regression's L2 penalty " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete7cd30f6d-ab34-4cee-a328-816d840f7412 Delete7cd30f6d-ab34-4cee-a328-816d840f7412Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete7cd30f6d-ab34-4cee-a328-816d840f7412">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videob2d1ef07-9e5d-4fd0-c4c9-017ed4f9daca Videob2d1ef07-9e5d-4fd0-c4c9-017ed4f9dacaDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videob2d1ef07-9e5d-4fd0-c4c9-017ed4f9daca">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=518&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=518" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=518" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">8:38 - 8:47</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">the
 type of feature normalization that's best to apply, can depend on the 
data set, learning task and learning algorithm to be used.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: the type of feature normalization that's best to apply, can depend on the data set, learning task and learning algorithm to be used." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editabcfa661-80be-4b7d-bab6-d98100a8addc Editabcfa661-80be-4b7d-bab6-d98100a8addcDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editabcfa661-80be-4b7d-bab6-d98100a8addc">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: the type of feature normalization that's best to apply, can depend on the data set, learning task and learning algorithm to be used." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete528d9991-770b-46a2-9851-6d122fafd9b4 Delete528d9991-770b-46a2-9851-6d122fafd9b4Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete528d9991-770b-46a2-9851-6d122fafd9b4">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video6e7f12a3-fa98-4880-9967-80c11259deec Video6e7f12a3-fa98-4880-9967-80c11259deecDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video6e7f12a3-fa98-4880-9967-80c11259deec">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=912&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=912" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=912" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">15:12 - 15:41</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Now
 we can write a new regression problem that tries to predict the same 
output variable y-hat but using these five features instead of two. The 
critical insight here is that this is still a linear regression problem.
 The features are just numbers within a weighted sum. So we can use the 
same least-squares techniques to estimate the five model coefficients 
for these five features that we used in these simpler two-dimensional 
case.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Now we can write a new regression problem that tries to predict the same output variable y-hat but using these five features instead of two. The critical insight here is that this is still a linear regression problem. The features are just numbers within a weighted sum. So we can use the same least-squares techniques to estimate the five model coefficients for these five features that we used in these simpler two-dimensional case." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit4017a7bf-605d-4136-d1af-29c69d5bbe61 Edit4017a7bf-605d-4136-d1af-29c69d5bbe61Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit4017a7bf-605d-4136-d1af-29c69d5bbe61">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Now we can write a new regression problem that tries to predict the same output variable y-hat but using these five features instead of two. The critical insight here is that this is still a linear regression problem. The features are just numbers within a weighted sum. So we can use the same least-squares techniques to estimate the five model coefficients for these five features that we used in these simpler two-dimensional case." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete16fe036d-bbd0-4eed-b7a7-58beee24cb66 Delete16fe036d-bbd0-4eed-b7a7-58beee24cb66Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete16fe036d-bbd0-4eed-b7a7-58beee24cb66">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video1081ccf4-a4b3-46b8-a280-baabd08331f4 Video1081ccf4-a4b3-46b8-a280-baabd08331f4Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video1081ccf4-a4b3-46b8-a280-baabd08331f4">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=655&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=655" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=655" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">10:55 - 11:11</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">The
 L1 penalty looks kind of similar to the L2 penalty, in that it computes
 a sum over the coefficients but it's some of the absolute values of the
 W-coefficients instead of a sum of squares. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: The L1 penalty looks kind of similar to the L2 penalty, in that it computes a sum over the coefficients but it's some of the absolute values of the W-coefficients instead of a sum of squares. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit2d127a92-31a3-4692-f062-099890ff1d7a Edit2d127a92-31a3-4692-f062-099890ff1d7aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit2d127a92-31a3-4692-f062-099890ff1d7a">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: The L1 penalty looks kind of similar to the L2 penalty, in that it computes a sum over the coefficients but it's some of the absolute values of the W-coefficients instead of a sum of squares. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletee518e9d4-09db-4912-b94e-6f04ee804410 Deletee518e9d4-09db-4912-b94e-6f04ee804410Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletee518e9d4-09db-4912-b94e-6f04ee804410">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video739daa47-fbca-4976-e444-3196e607e840 Video739daa47-fbca-4976-e444-3196e607e840Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video739daa47-fbca-4976-e444-3196e607e840">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=449&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=449" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=449" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">7:29 - 7:37</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">irst, that we're applying the same scalar object to both the training and the testing. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: irst, that we're applying the same scalar object to both the training and the testing. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit2e532997-92f1-437c-88b5-0df41b9430f1 Edit2e532997-92f1-437c-88b5-0df41b9430f1Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit2e532997-92f1-437c-88b5-0df41b9430f1">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: irst, that we're applying the same scalar object to both the training and the testing. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletefc0ecb53-a650-4cb6-f927-ec482eb72298 Deletefc0ecb53-a650-4cb6-f927-ec482eb72298Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletefc0ecb53-a650-4cb6-f927-ec482eb72298">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video6e2f3ac5-d49d-419b-f38f-944aa5cc23ed Video6e2f3ac5-d49d-419b-f38f-944aa5cc23edDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video6e2f3ac5-d49d-419b-f38f-944aa5cc23ed">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=61&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=61" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=61" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">1:01 - 1:08</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">This addition of a penalty term to a learning algorithm's objective function is called Regularisation.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: This addition of a penalty term to a learning algorithm's objective function is called Regularisation." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit7d041ce9-0436-4cec-d1b3-56b1af467d94 Edit7d041ce9-0436-4cec-d1b3-56b1af467d94Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit7d041ce9-0436-4cec-d1b3-56b1af467d94">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: This addition of a penalty term to a learning algorithm's objective function is called Regularisation." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete5756e81d-d6f3-4fe3-bd36-1a81a6bd60b6 Delete5756e81d-d6f3-4fe3-bd36-1a81a6bd60b6Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete5756e81d-d6f3-4fe3-bd36-1a81a6bd60b6">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video7706d0d0-bcbc-4a8a-85b6-7267abe8d858 Video7706d0d0-bcbc-4a8a-85b6-7267abe8d858Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video7706d0d0-bcbc-4a8a-85b6-7267abe8d858">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=73&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=73" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=73" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">1:13 - 1:31</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">t's
 a way to prevent overfitting, and thus, improve the likely 
generalization performance of a model, by restricting the models 
possible parameter settings. Usually the effect of this restriction from
 regularisation, is to reduce the complexity of the final estimated 
model.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: t's a way to prevent overfitting, and thus, improve the likely generalization performance of a model, by restricting the models possible parameter settings. Usually the effect of this restriction from regularisation, is to reduce the complexity of the final estimated model." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editf84a640d-fac5-49af-e84e-800086909528 Editf84a640d-fac5-49af-e84e-800086909528Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editf84a640d-fac5-49af-e84e-800086909528">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: t's a way to prevent overfitting, and thus, improve the likely generalization performance of a model, by restricting the models possible parameter settings. Usually the effect of this restriction from regularisation, is to reduce the complexity of the final estimated model." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete05fef752-7110-4671-8b7b-04ec94aeaf79 Delete05fef752-7110-4671-8b7b-04ec94aeaf79Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete05fef752-7110-4671-8b7b-04ec94aeaf79">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videocf0c59bd-d3a2-427c-c003-7dfc9a388796 Videocf0c59bd-d3a2-427c-c003-7dfc9a388796Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videocf0c59bd-d3a2-427c-c003-7dfc9a388796">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=1062&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=1062" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=1062" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">17:42 - 18:01</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Here's
 an example of polynomial regression using scikit-learn. There's already
 a handy class called polynomial features in the sklearn.preprocessing 
module that will generate these polynomial features for us. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Here's an example of polynomial regression using scikit-learn. There's already a handy class called polynomial features in the sklearn.preprocessing module that will generate these polynomial features for us. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit6952e085-62af-4dd8-aa66-42b371bf00ff Edit6952e085-62af-4dd8-aa66-42b371bf00ffDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit6952e085-62af-4dd8-aa66-42b371bf00ff">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Here's an example of polynomial regression using scikit-learn. There's already a handy class called polynomial features in the sklearn.preprocessing module that will generate these polynomial features for us. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleteca579f99-9e1e-4072-db39-e69ca18293c5 Deleteca579f99-9e1e-4072-db39-e69ca18293c5Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deleteca579f99-9e1e-4072-db39-e69ca18293c5">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoa9b88dda-3d05-4198-eba7-d866b570deb0 Videoa9b88dda-3d05-4198-eba7-d866b570deb0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoa9b88dda-3d05-4198-eba7-d866b570deb0">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=762&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=762" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=762" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">12:42 - 13:03</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">With
 some data sets you may occasionally get a convergence warning, in which
 case you can set the max_iter attribute to a larger value. So typically
 at least 20,000, or possibly more. Increasing the max inter-parameter 
will increase the computation time accordingly. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: With some data sets you may occasionally get a convergence warning, in which case you can set the max_iter attribute to a larger value. So typically at least 20,000, or possibly more. Increasing the max inter-parameter will increase the computation time accordingly. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit36191e6b-0969-4538-8860-9d4b13dfc5c7 Edit36191e6b-0969-4538-8860-9d4b13dfc5c7Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit36191e6b-0969-4538-8860-9d4b13dfc5c7">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: With some data sets you may occasionally get a convergence warning, in which case you can set the max_iter attribute to a larger value. So typically at least 20,000, or possibly more. Increasing the max inter-parameter will increase the computation time accordingly. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete127d4b56-a894-4574-ad11-4a5a4797ac49 Delete127d4b56-a894-4574-ad11-4a5a4797ac49Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete127d4b56-a894-4574-ad11-4a5a4797ac49">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video186b88a2-b12c-4371-a4f6-abd5e5703f52 Video186b88a2-b12c-4371-a4f6-abd5e5703f52Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video186b88a2-b12c-4371-a4f6-abd5e5703f52">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=447&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=447" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=447" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">7:27 - 7:35</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">You may have noticed two things here. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: You may have noticed two things here. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit1d5911b7-9549-4656-cad6-aa04a28bc160 Edit1d5911b7-9549-4656-cad6-aa04a28bc160Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit1d5911b7-9549-4656-cad6-aa04a28bc160">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: You may have noticed two things here. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete4cce01af-4e81-43fa-f35c-23dd4e44d022 Delete4cce01af-4e81-43fa-f35c-23dd4e44d022Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete4cce01af-4e81-43fa-f35c-23dd4e44d022">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video9b727ec0-d9a9-4203-c885-fd328ff86374 Video9b727ec0-d9a9-4203-c885-fd328ff86374Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video9b727ec0-d9a9-4203-c885-fd328ff86374">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=882&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=882" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=882" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">14:42 - 15:16</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Let's
 suppose for a moment that we had a set of two-dimensional data points 
with features X0 and X1. Then we could transform each data point by 
adding additional features that were the three unique multiplicative 
combinations of X0 and X1. So, X0 squared, X0, X1 and X1 squared. So 
we've transformed our original two-dimensional points into a set of 
five-dimensional points that rely only on the information in the 
two-dimensional points. </div><div class="video-note-text-box video-note-text" aria-label="User Note">XXXXX</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Let's suppose for a moment that we had a set of two-dimensional data points with features X0 and X1. Then we could transform each data point by adding additional features that were the three unique multiplicative combinations of X0 and X1. So, X0 squared, X0, X1 and X1 squared. So we've transformed our original two-dimensional points into a set of five-dimensional points that rely only on the information in the two-dimensional points. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit2aeb8311-5101-43ab-8e23-343e847c459b Edit2aeb8311-5101-43ab-8e23-343e847c459bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit2aeb8311-5101-43ab-8e23-343e847c459b">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Let's suppose for a moment that we had a set of two-dimensional data points with features X0 and X1. Then we could transform each data point by adding additional features that were the three unique multiplicative combinations of X0 and X1. So, X0 squared, X0, X1 and X1 squared. So we've transformed our original two-dimensional points into a set of five-dimensional points that rely only on the information in the two-dimensional points. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete17933f94-5407-4e4a-e083-eef9f14d2505 Delete17933f94-5407-4e4a-e083-eef9f14d2505Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete17933f94-5407-4e4a-e083-eef9f14d2505">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoed92e8d7-1aad-424a-8a11-b365010ee19c Videoed92e8d7-1aad-424a-8a11-b365010ee19cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videoed92e8d7-1aad-424a-8a11-b365010ee19c">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=162&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=162" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=162" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">2:42 - 2:57</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">The
 amount of regularisation to apply is controlled by the alpha parameter.
 Larger alpha means more regularization and simpler linear models with 
weights closer to zero. The default setting for alpha is 1.0.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: The amount of regularisation to apply is controlled by the alpha parameter. Larger alpha means more regularization and simpler linear models with weights closer to zero. The default setting for alpha is 1.0." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edite63fae5f-7218-490d-c0ff-71c5e9f53014 Edite63fae5f-7218-490d-c0ff-71c5e9f53014Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edite63fae5f-7218-490d-c0ff-71c5e9f53014">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: The amount of regularisation to apply is controlled by the alpha parameter. Larger alpha means more regularization and simpler linear models with weights closer to zero. The default setting for alpha is 1.0." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete0c2f6133-9f7c-4969-8c69-e4f6f560d13f Delete0c2f6133-9f7c-4969-8c69-e4f6f560d13fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete0c2f6133-9f7c-4969-8c69-e4f6f560d13f">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video5885612f-f195-4f60-fe21-54bc0f2aa353 Video5885612f-f195-4f60-fe21-54bc0f2aa353Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video5885612f-f195-4f60-fe21-54bc0f2aa353">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=293&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=293" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=293" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">4:53 - 5:19</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">feature
 normalization is important to perform for a number of different 
learning algorithms, beyond just regularized regression. This includes 
K-nearest neighbors, support vector machines, neural networks and 
others. The type of feature preprocessing and normalization that's 
needed can also depend on the data. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: feature normalization is important to perform for a number of different learning algorithms, beyond just regularized regression. This includes K-nearest neighbors, support vector machines, neural networks and others. The type of feature preprocessing and normalization that's needed can also depend on the data. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit5ca78e89-c707-48c3-8cfa-1c0e6999b082 Edit5ca78e89-c707-48c3-8cfa-1c0e6999b082Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit5ca78e89-c707-48c3-8cfa-1c0e6999b082">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: feature normalization is important to perform for a number of different learning algorithms, beyond just regularized regression. This includes K-nearest neighbors, support vector machines, neural networks and others. The type of feature preprocessing and normalization that's needed can also depend on the data. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete70788f96-0c7a-43db-e7d7-7315b10fa05d Delete70788f96-0c7a-43db-e7d7-7315b10fa05dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete70788f96-0c7a-43db-e7d7-7315b10fa05d">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video6a90aac3-48fb-4a3b-a3eb-7de9254b9bd0 Video6a90aac3-48fb-4a3b-a3eb-7de9254b9bd0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video6a90aac3-48fb-4a3b-a3eb-7de9254b9bd0">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=685&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=685" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=685" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">11:25 - 11:37</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">This
 sparse solution where only a subset of the most important features are 
left with non-zero weights, also makes the model easier to interpret. In
 cases where there are more than a few input variables.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: This sparse solution where only a subset of the most important features are left with non-zero weights, also makes the model easier to interpret. In cases where there are more than a few input variables." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit689ce633-79a0-4b42-8f58-f252350ac0ca Edit689ce633-79a0-4b42-8f58-f252350ac0caDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit689ce633-79a0-4b42-8f58-f252350ac0ca">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: This sparse solution where only a subset of the most important features are left with non-zero weights, also makes the model easier to interpret. In cases where there are more than a few input variables." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete67156ea6-0bb7-475f-f8f1-a356bba097ca Delete67156ea6-0bb7-475f-f8f1-a356bba097caDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete67156ea6-0bb7-475f-f8f1-a356bba097ca">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoc9bfa626-f22f-4868-b1a3-b0599742c972 Videoc9bfa626-f22f-4868-b1a3-b0599742c972Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoc9bfa626-f22f-4868-b1a3-b0599742c972">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=620&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=620" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=620" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">10:20 - 10:44</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">
 Another kind of regularized regression that you could use instead of 
ridge regression is called Lasso Regression. Like ridge regression, 
lasso regression adds a regularisation penalty term to the ordinary 
least-squares objective, that causes the model W-coefficients to shrink 
towards zero.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text:  Another kind of regularized regression that you could use instead of ridge regression is called Lasso Regression. Like ridge regression, lasso regression adds a regularisation penalty term to the ordinary least-squares objective, that causes the model W-coefficients to shrink towards zero." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editf610aabc-86bb-4500-e6ca-395fd5e9557b Editf610aabc-86bb-4500-e6ca-395fd5e9557bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editf610aabc-86bb-4500-e6ca-395fd5e9557b">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text:  Another kind of regularized regression that you could use instead of ridge regression is called Lasso Regression. Like ridge regression, lasso regression adds a regularisation penalty term to the ordinary least-squares objective, that causes the model W-coefficients to shrink towards zero." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete3f78c9c9-6fd5-4c5f-ce12-cd4dee68b380 Delete3f78c9c9-6fd5-4c5f-ce12-cd4dee68b380Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete3f78c9c9-6fd5-4c5f-ce12-cd4dee68b380">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videofc1b41d3-05ad-4aa9-8c87-034d1118300f Videofc1b41d3-05ad-4aa9-8c87-034d1118300fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videofc1b41d3-05ad-4aa9-8c87-034d1118300f">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=474&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=474" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=474" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">7:54 - 8:24</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">If
 you prepare the scaler or other normalization method by showing it the 
test data instead of the training data, this leads to a phenomenon 
called Data Leakage, where the training phase has information that is 
leaked from the test set. For example, like the distribution of extreme 
values for each feature in the test data, which the learner should never
 have access to during training. This in turn can cause the learning 
method to give unrealistically good estimates on the same test set.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: If you prepare the scaler or other normalization method by showing it the test data instead of the training data, this leads to a phenomenon called Data Leakage, where the training phase has information that is leaked from the test set. For example, like the distribution of extreme values for each feature in the test data, which the learner should never have access to during training. This in turn can cause the learning method to give unrealistically good estimates on the same test set." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editc8c5868c-d8bd-4610-ec2c-46adee023474 Editc8c5868c-d8bd-4610-ec2c-46adee023474Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editc8c5868c-d8bd-4610-ec2c-46adee023474">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: If you prepare the scaler or other normalization method by showing it the test data instead of the training data, this leads to a phenomenon called Data Leakage, where the training phase has information that is leaked from the test set. For example, like the distribution of extreme values for each feature in the test data, which the learner should never have access to during training. This in turn can cause the learning method to give unrealistically good estimates on the same test set." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete15a1be04-a44f-4c5f-ba12-19a6aa1c394a Delete15a1be04-a44f-4c5f-ba12-19a6aa1c394aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete15a1be04-a44f-4c5f-ba12-19a6aa1c394a">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video2c260ee4-e7a5-4fff-97ef-bf27ba3d6a60 Video2c260ee4-e7a5-4fff-97ef-bf27ba3d6a60Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video2c260ee4-e7a5-4fff-97ef-bf27ba3d6a60">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=669&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=669" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=669" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">11:09 - 11:28</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">
 With lasso regression, a subset of the coefficients are forced to be 
precisely zero. Which is a kind of automatic feature selection, since 
with the weight of zero the features are essentially ignored completely 
in the model. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text:  With lasso regression, a subset of the coefficients are forced to be precisely zero. Which is a kind of automatic feature selection, since with the weight of zero the features are essentially ignored completely in the model. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editb8d1ecfb-00c2-45db-a220-b2c59d1d9e5b Editb8d1ecfb-00c2-45db-a220-b2c59d1d9e5bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editb8d1ecfb-00c2-45db-a220-b2c59d1d9e5b">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text:  With lasso regression, a subset of the coefficients are forced to be precisely zero. Which is a kind of automatic feature selection, since with the weight of zero the features are essentially ignored completely in the model. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletedb4c3d80-4d99-4c92-fb14-4c342ee3ec0d Deletedb4c3d80-4d99-4c92-fb14-4c342ee3ec0dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletedb4c3d80-4d99-4c92-fb14-4c342ee3ec0d">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video0c69ff3c-f454-41a3-dcde-026200f14b18 Video0c69ff3c-f454-41a3-dcde-026200f14b18Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video0c69ff3c-f454-41a3-dcde-026200f14b18">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=1040&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=1040" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=1040" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">17:20 - 17:42</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">one
 side effect of adding lots of new features especially when we're taking
 every possible combination of K variables, is that these more complex 
models have the potential for overfitting. So in practice, polynomial 
regression is often done with a regularized learning method like ridge 
regression.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: one side effect of adding lots of new features especially when we're taking every possible combination of K variables, is that these more complex models have the potential for overfitting. So in practice, polynomial regression is often done with a regularized learning method like ridge regression." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit4ba3c6fe-0d77-45ca-ad25-8220048a980c Edit4ba3c6fe-0d77-45ca-ad25-8220048a980cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit4ba3c6fe-0d77-45ca-ad25-8220048a980c">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: one side effect of adding lots of new features especially when we're taking every possible combination of K variables, is that these more complex models have the potential for overfitting. So in practice, polynomial regression is often done with a regularized learning method like ridge regression." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete263187d9-4471-4b86-c3c9-bfab2bf06114 Delete263187d9-4471-4b86-c3c9-bfab2bf06114Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete263187d9-4471-4b86-c3c9-bfab2bf06114">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoc2978163-c1e1-40c1-860b-d8aa94f08d73 Videoc2978163-c1e1-40c1-860b-d8aa94f08d73Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoc2978163-c1e1-40c1-860b-d8aa94f08d73">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=258&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=258" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=258" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">4:18 - 4:35</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">if
 the input variables, the features, have very different scales, then 
when this shrinkage happens of the coefficients, input variables with 
different scales will have different contributions to this L2 penalty, 
because the L2 penalty is a sum of squares of all the coefficients.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: if the input variables, the features, have very different scales, then when this shrinkage happens of the coefficients, input variables with different scales will have different contributions to this L2 penalty, because the L2 penalty is a sum of squares of all the coefficients." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editeef2e16a-f07b-46ad-c901-ba917c8eabf6 Editeef2e16a-f07b-46ad-c901-ba917c8eabf6Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editeef2e16a-f07b-46ad-c901-ba917c8eabf6">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: if the input variables, the features, have very different scales, then when this shrinkage happens of the coefficients, input variables with different scales will have different contributions to this L2 penalty, because the L2 penalty is a sum of squares of all the coefficients." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleteff39c8d4-e8e4-47ad-b533-1fdcd9d37851 Deleteff39c8d4-e8e4-47ad-b533-1fdcd9d37851Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deleteff39c8d4-e8e4-47ad-b533-1fdcd9d37851">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoedabf653-f7c8-4f30-8fa8-b32de755d528 Videoedabf653-f7c8-4f30-8fa8-b32de755d528Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoedabf653-f7c8-4f30-8fa8-b32de755d528">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/M7yUQ?t=37&quot;,&quot;itemId&quot;:&quot;M7yUQ&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/M7yUQ?t=37" href="https://www.coursera.org/learn/python-machine-learning/lecture/M7yUQ?t=37" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Regression: Ridge, Lasso, and Polynomial Regression</div></a><div class="video-details" aria-label="Duration">0:37 - 1:01</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Once
 ridge regression has estimated the WNB parameters for the linear model,
 the prediction of Y values for new instances is exactly the same as in 
least squares. You just plug in your input feature values, the XIs and 
compute the sum of the weighted feature values plus B with the usual in 
your formula. So why would something like ridge regression be useful?</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Once ridge regression has estimated the WNB parameters for the linear model, the prediction of Y values for new instances is exactly the same as in least squares. You just plug in your input feature values, the XIs and compute the sum of the weighted feature values plus B with the usual in your formula. So why would something like ridge regression be useful?" tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit46459255-2639-4116-d039-4038ef59bab1 Edit46459255-2639-4116-d039-4038ef59bab1Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit46459255-2639-4116-d039-4038ef59bab1">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Once ridge regression has estimated the WNB parameters for the linear model, the prediction of Y values for new instances is exactly the same as in least squares. You just plug in your input feature values, the XIs and compute the sum of the weighted feature values plus B with the usual in your formula. So why would something like ridge regression be useful?" tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete30b4dc53-5c0b-4c9d-ce44-cf7c89e1948f Delete30b4dc53-5c0b-4c9d-ce44-cf7c89e1948fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete30b4dc53-5c0b-4c9d-ce44-cf7c89e1948f">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoa7e85e1e-18c5-4b9c-fe54-1504dd1cdd8f Videoa7e85e1e-18c5-4b9c-fe54-1504dd1cdd8fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videoa7e85e1e-18c5-4b9c-fe54-1504dd1cdd8f">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/bEtYh?t=639&quot;,&quot;itemId&quot;:&quot;bEtYh&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/bEtYh?t=639" href="https://www.coursera.org/learn/python-machine-learning/lecture/bEtYh?t=639" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Logistic Regression</div></a><div class="video-details" aria-label="Duration">10:39 - 11:34</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Like
 ridge and lasso regression, a regularization penalty on the model 
coefficients can also be applied with logistic regression, and is 
controlled with the parameter C. In fact, the same L2 regularization 
penalty used for ridge regression is turned on by default for logistic 
regression with a default value C = 1. Note that for both Support Vector
 machines and Logistic Regression, higher values of C correspond to less
 regularization. With large values of C, logistic regression tries to 
fit the training data as well as possible. While with small values of C,
 the model tries harder to find model coefficients that are closer to 0,
 even if that model fits the training data a little bit worse. You can 
see the effect of changing the regularization parameter C for logistic 
regression in this visual.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Like ridge and lasso regression, a regularization penalty on the model coefficients can also be applied with logistic regression, and is controlled with the parameter C. In fact, the same L2 regularization penalty used for ridge regression is turned on by default for logistic regression with a default value C = 1. Note that for both Support Vector machines and Logistic Regression, higher values of C correspond to less regularization. With large values of C, logistic regression tries to fit the training data as well as possible. While with small values of C, the model tries harder to find model coefficients that are closer to 0, even if that model fits the training data a little bit worse. You can see the effect of changing the regularization parameter C for logistic regression in this visual." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editb963d680-eae1-42bf-9eae-361d79a3495d Editb963d680-eae1-42bf-9eae-361d79a3495dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editb963d680-eae1-42bf-9eae-361d79a3495d">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Like ridge and lasso regression, a regularization penalty on the model coefficients can also be applied with logistic regression, and is controlled with the parameter C. In fact, the same L2 regularization penalty used for ridge regression is turned on by default for logistic regression with a default value C = 1. Note that for both Support Vector machines and Logistic Regression, higher values of C correspond to less regularization. With large values of C, logistic regression tries to fit the training data as well as possible. While with small values of C, the model tries harder to find model coefficients that are closer to 0, even if that model fits the training data a little bit worse. You can see the effect of changing the regularization parameter C for logistic regression in this visual." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete99a768d5-12b7-4a74-c9f5-10cc06ae6721 Delete99a768d5-12b7-4a74-c9f5-10cc06ae6721Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete99a768d5-12b7-4a74-c9f5-10cc06ae6721">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoe8b5fc47-566a-415b-f208-fd5ad23625c4 Videoe8b5fc47-566a-415b-f208-fd5ad23625c4Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoe8b5fc47-566a-415b-f208-fd5ad23625c4">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/bEtYh?t=7&quot;,&quot;itemId&quot;:&quot;bEtYh&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/bEtYh?t=7" href="https://www.coursera.org/learn/python-machine-learning/lecture/bEtYh?t=7" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Logistic Regression</div></a><div class="video-details" aria-label="Duration">0:07 - 0:17</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">a
 second supervised learning method that in spite of being called a 
regression measure, is actually used for classification and its called 
logistic regression.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: a second supervised learning method that in spite of being called a regression measure, is actually used for classification and its called logistic regression." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit0391a807-cc3f-4308-d991-bdd70753ab54 Edit0391a807-cc3f-4308-d991-bdd70753ab54Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit0391a807-cc3f-4308-d991-bdd70753ab54">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: a second supervised learning method that in spite of being called a regression measure, is actually used for classification and its called logistic regression." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletedcf34e14-c7f6-4253-f55c-71753009e477 Deletedcf34e14-c7f6-4253-f55c-71753009e477Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletedcf34e14-c7f6-4253-f55c-71753009e477">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videod2cf31cb-dfec-4b44-cb64-7c6a8e6819b6 Videod2cf31cb-dfec-4b44-cb64-7c6a8e6819b6Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videod2cf31cb-dfec-4b44-cb64-7c6a8e6819b6">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/bEtYh?t=363&quot;,&quot;itemId&quot;:&quot;bEtYh&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/bEtYh?t=363" href="https://www.coursera.org/learn/python-machine-learning/lecture/bEtYh?t=363" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Logistic Regression</div></a><div class="video-details" aria-label="Duration">6:03 - 6:26</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Here
 the plots show a training set with two classes. Each data point has two
 features. Feature 1 corresponds to the x-axis, and Feature 2 
corresponds to the y-axis. The data points in the red class on the left,
 form a cluster with low Feature 1 value, and high Feature 2 value. And 
the points in the blue class have intermediate Feature 1 value, and low 
Feature 2 value.</div><div class="video-note-text-box video-note-text" aria-label="User Note">xxxx</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Here the plots show a training set with two classes. Each data point has two features. Feature 1 corresponds to the x-axis, and Feature 2 corresponds to the y-axis. The data points in the red class on the left, form a cluster with low Feature 1 value, and high Feature 2 value. And the points in the blue class have intermediate Feature 1 value, and low Feature 2 value." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editcd750494-1d0f-47ed-e0f2-9233999cbe37 Editcd750494-1d0f-47ed-e0f2-9233999cbe37Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editcd750494-1d0f-47ed-e0f2-9233999cbe37">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Here the plots show a training set with two classes. Each data point has two features. Feature 1 corresponds to the x-axis, and Feature 2 corresponds to the y-axis. The data points in the red class on the left, form a cluster with low Feature 1 value, and high Feature 2 value. And the points in the blue class have intermediate Feature 1 value, and low Feature 2 value." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete6833fa79-e047-4022-aa29-27daf109c278 Delete6833fa79-e047-4022-aa29-27daf109c278Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete6833fa79-e047-4022-aa29-27daf109c278">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video6ae83892-0e02-4bac-945e-edfa07dad8ab Video6ae83892-0e02-4bac-945e-edfa07dad8abDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video6ae83892-0e02-4bac-945e-edfa07dad8ab">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/bEtYh?t=485&quot;,&quot;itemId&quot;:&quot;bEtYh&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/bEtYh?t=485" href="https://www.coursera.org/learn/python-machine-learning/lecture/bEtYh?t=485" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Logistic Regression</div></a><div class="video-details" aria-label="Duration">8:05 - 8:11</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">In other words, using logistic regression gives a linear decision boundary between the classes as shown here.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: In other words, using logistic regression gives a linear decision boundary between the classes as shown here." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit1595a789-c1ef-4ac6-ebfa-71a5428d8023 Edit1595a789-c1ef-4ac6-ebfa-71a5428d8023Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit1595a789-c1ef-4ac6-ebfa-71a5428d8023">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: In other words, using logistic regression gives a linear decision boundary between the classes as shown here." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete53d8467e-c434-47e9-f185-38838366a182 Delete53d8467e-c434-47e9-f185-38838366a182Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete53d8467e-c434-47e9-f185-38838366a182">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video2ee0a41d-8533-4820-f650-d808b2ed9130 Video2ee0a41d-8533-4820-f650-d808b2ed9130Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video2ee0a41d-8533-4820-f650-d808b2ed9130">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/bEtYh?t=202&quot;,&quot;itemId&quot;:&quot;bEtYh&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/bEtYh?t=202" href="https://www.coursera.org/learn/python-machine-learning/lecture/bEtYh?t=202" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Logistic Regression</div></a><div class="video-details" aria-label="Duration">3:22 - 3:31</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">If
 we pick different values for b hat and the w hat coefficients, we'll 
get different variants of this s shaped logistic function, which again 
is always between 0 and 1.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: If we pick different values for b hat and the w hat coefficients, we'll get different variants of this s shaped logistic function, which again is always between 0 and 1." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit3594c9f5-ed28-49dc-a59b-1a4931e12e19 Edit3594c9f5-ed28-49dc-a59b-1a4931e12e19Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit3594c9f5-ed28-49dc-a59b-1a4931e12e19">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: If we pick different values for b hat and the w hat coefficients, we'll get different variants of this s shaped logistic function, which again is always between 0 and 1." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete3eccedf0-01dc-4504-d59a-7cd1cb5a2f9b Delete3eccedf0-01dc-4504-d59a-7cd1cb5a2f9bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete3eccedf0-01dc-4504-d59a-7cd1cb5a2f9b">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videod9fa503d-090c-49a6-8ef5-6ae7900a9539 Videod9fa503d-090c-49a6-8ef5-6ae7900a9539Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videod9fa503d-090c-49a6-8ef5-6ae7900a9539">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/bEtYh?t=133&quot;,&quot;itemId&quot;:&quot;bEtYh&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/bEtYh?t=133" href="https://www.coursera.org/learn/python-machine-learning/lecture/bEtYh?t=133" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Logistic Regression</div></a><div class="video-details" aria-label="Duration">2:13 - 2:34</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">
 The logistic regression model still computes a weighted sum of the 
input features xi and the intercept term b, but it runs this result 
through a special non-linear function f, the logistic function 
represented by this new box in the middle of the diagram to produce the 
output y.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text:  The logistic regression model still computes a weighted sum of the input features xi and the intercept term b, but it runs this result through a special non-linear function f, the logistic function represented by this new box in the middle of the diagram to produce the output y." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit0cd74058-675e-4a53-ad3b-4ccc6d5b7035 Edit0cd74058-675e-4a53-ad3b-4ccc6d5b7035Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit0cd74058-675e-4a53-ad3b-4ccc6d5b7035">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text:  The logistic regression model still computes a weighted sum of the input features xi and the intercept term b, but it runs this result through a special non-linear function f, the logistic function represented by this new box in the middle of the diagram to produce the output y." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete45e482d6-af2a-4eff-f627-fd0bae738509 Delete45e482d6-af2a-4eff-f627-fd0bae738509Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete45e482d6-af2a-4eff-f627-fd0bae738509">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video88305d0d-2a9a-43cc-ab8e-b18693794262 Video88305d0d-2a9a-43cc-ab8e-b18693794262Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video88305d0d-2a9a-43cc-ab8e-b18693794262">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/bEtYh?t=626&quot;,&quot;itemId&quot;:&quot;bEtYh&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/bEtYh?t=626" href="https://www.coursera.org/learn/python-machine-learning/lecture/bEtYh?t=626" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Logistic Regression</div></a><div class="video-details" aria-label="Duration">10:26 - 10:36</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">In
 fact, logistic regression results are often quite similar to those you 
might obtain from a linear support vector machine, another type of 
linear model we explore for classification.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: In fact, logistic regression results are often quite similar to those you might obtain from a linear support vector machine, another type of linear model we explore for classification." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editdaf6f80e-13b0-4e53-eddd-769f70f3be7f Editdaf6f80e-13b0-4e53-eddd-769f70f3be7fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editdaf6f80e-13b0-4e53-eddd-769f70f3be7f">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: In fact, logistic regression results are often quite similar to those you might obtain from a linear support vector machine, another type of linear model we explore for classification." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete224d2353-c2c8-4c19-ae69-c414457fbbf0 Delete224d2353-c2c8-4c19-ae69-c414457fbbf0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete224d2353-c2c8-4c19-ae69-c414457fbbf0">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video161019e2-50d8-4f22-f301-aaca1443a9ec Video161019e2-50d8-4f22-f301-aaca1443a9ecDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video161019e2-50d8-4f22-f301-aaca1443a9ec">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/bEtYh?t=18&quot;,&quot;itemId&quot;:&quot;bEtYh&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/bEtYh?t=18" href="https://www.coursera.org/learn/python-machine-learning/lecture/bEtYh?t=18" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Logistic Regression</div></a><div class="video-details" aria-label="Duration">0:18 - 0:22</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Logistic regression can be seen as a kind of generalized linear model.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Logistic regression can be seen as a kind of generalized linear model." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit4398c4a0-4a6d-4a93-b294-3969d9e81ef0 Edit4398c4a0-4a6d-4a93-b294-3969d9e81ef0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit4398c4a0-4a6d-4a93-b294-3969d9e81ef0">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Logistic regression can be seen as a kind of generalized linear model." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete13dcdd8f-9095-428b-9743-a23b998f5ff2 Delete13dcdd8f-9095-428b-9743-a23b998f5ff2Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete13dcdd8f-9095-428b-9743-a23b998f5ff2">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video2eade6e0-b4ee-47ad-bd6b-25c3f72c8e85 Video2eade6e0-b4ee-47ad-bd6b-25c3f72c8e85Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video2eade6e0-b4ee-47ad-bd6b-25c3f72c8e85">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/bEtYh?t=418&quot;,&quot;itemId&quot;:&quot;bEtYh&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/bEtYh?t=418" href="https://www.coursera.org/learn/python-machine-learning/lecture/bEtYh?t=418" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Logistic Regression</div></a><div class="video-details" aria-label="Duration">6:58 - 7:18</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Then
 just as we did in the exam studying example, we can estimate the w hat 
and b hat parameters of the logistic function that best fits this 
training data. The only difference is that the logistic function is now a
 function of two input features and not just one. So it forms something 
like a three dimensional S shaped sheet in this space.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Then just as we did in the exam studying example, we can estimate the w hat and b hat parameters of the logistic function that best fits this training data. The only difference is that the logistic function is now a function of two input features and not just one. So it forms something like a three dimensional S shaped sheet in this space." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit7a8aff54-5556-48b4-eac7-46e42ecf8d19 Edit7a8aff54-5556-48b4-eac7-46e42ecf8d19Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit7a8aff54-5556-48b4-eac7-46e42ecf8d19">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Then just as we did in the exam studying example, we can estimate the w hat and b hat parameters of the logistic function that best fits this training data. The only difference is that the logistic function is now a function of two input features and not just one. So it forms something like a three dimensional S shaped sheet in this space." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletec299c3e7-d01f-46ef-8ac4-27a273c89d09 Deletec299c3e7-d01f-46ef-8ac4-27a273c89d09Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletec299c3e7-d01f-46ef-8ac4-27a273c89d09">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video21892550-22d5-440f-b86f-a1ac4a969f90 Video21892550-22d5-440f-b86f-a1ac4a969f90Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video21892550-22d5-440f-b86f-a1ac4a969f90">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/bEtYh?t=159&quot;,&quot;itemId&quot;:&quot;bEtYh&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/bEtYh?t=159" href="https://www.coursera.org/learn/python-machine-learning/lecture/bEtYh?t=159" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Logistic Regression</div></a><div class="video-details" aria-label="Duration">2:39 - 3:20</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">t's
 an S shaped function that gets closer and closer to 1 as the input 
value increases above 0 and closer and closer to 0 as the input value 
decreases far below 0. The effect of applying the logistic function is 
to compress the output of the linear function so that it's limited to a 
range between 0 and 1. Below the diagram, you can see the formula for 
the predicted output y hat which first computes the same linear 
combination of the inputs xi, model coefficient weights wi hat and 
intercept b hat, but runs it through the additional step of applying the
 logistic function to produce y hat.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: t's an S shaped function that gets closer and closer to 1 as the input value increases above 0 and closer and closer to 0 as the input value decreases far below 0. The effect of applying the logistic function is to compress the output of the linear function so that it's limited to a range between 0 and 1. Below the diagram, you can see the formula for the predicted output y hat which first computes the same linear combination of the inputs xi, model coefficient weights wi hat and intercept b hat, but runs it through the additional step of applying the logistic function to produce y hat." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editebfae753-b380-4f66-bbd1-fcbed2fec282 Editebfae753-b380-4f66-bbd1-fcbed2fec282Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editebfae753-b380-4f66-bbd1-fcbed2fec282">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: t's an S shaped function that gets closer and closer to 1 as the input value increases above 0 and closer and closer to 0 as the input value decreases far below 0. The effect of applying the logistic function is to compress the output of the linear function so that it's limited to a range between 0 and 1. Below the diagram, you can see the formula for the predicted output y hat which first computes the same linear combination of the inputs xi, model coefficient weights wi hat and intercept b hat, but runs it through the additional step of applying the logistic function to produce y hat." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleted4bd9a6e-a878-4d74-bc97-b21c15617a6d Deleted4bd9a6e-a878-4d74-bc97-b21c15617a6dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deleted4bd9a6e-a878-4d74-bc97-b21c15617a6d">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video1129789a-1cc1-4681-f65a-08a9ddf79d7a Video1129789a-1cc1-4681-f65a-08a9ddf79d7aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video1129789a-1cc1-4681-f65a-08a9ddf79d7a">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/bEtYh?t=222&quot;,&quot;itemId&quot;:&quot;bEtYh&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/bEtYh?t=222" href="https://www.coursera.org/learn/python-machine-learning/lecture/bEtYh?t=222" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Logistic Regression</div></a><div class="video-details" aria-label="Duration">3:42 - 4:06</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">We
 could identify data instances with the target value of 0 as belonging 
to the negative class and data instances with a target value of 1 
belonging to the positive class. Then the value of y hat, that's the 
output from the logistic regression formula, can be interpreted as the 
probability that the input data instance belongs to the positive class, 
given its input features.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: We could identify data instances with the target value of 0 as belonging to the negative class and data instances with a target value of 1 belonging to the positive class. Then the value of y hat, that's the output from the logistic regression formula, can be interpreted as the probability that the input data instance belongs to the positive class, given its input features." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editf88a6a4e-e673-4716-e27e-de9860d20c36 Editf88a6a4e-e673-4716-e27e-de9860d20c36Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editf88a6a4e-e673-4716-e27e-de9860d20c36">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: We could identify data instances with the target value of 0 as belonging to the negative class and data instances with a target value of 1 belonging to the positive class. Then the value of y hat, that's the output from the logistic regression formula, can be interpreted as the probability that the input data instance belongs to the positive class, given its input features." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete21508447-fe9a-449f-ffc6-7d60f729a9e0 Delete21508447-fe9a-449f-ffc6-7d60f729a9e0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete21508447-fe9a-449f-ffc6-7d60f729a9e0">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video95c8a9a5-72c3-470f-96d9-c7abe305308e Video95c8a9a5-72c3-470f-96d9-c7abe305308eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video95c8a9a5-72c3-470f-96d9-c7abe305308e">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/bEtYh?t=528&quot;,&quot;itemId&quot;:&quot;bEtYh&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/bEtYh?t=528" href="https://www.coursera.org/learn/python-machine-learning/lecture/bEtYh?t=528" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Logistic Regression</div></a><div class="video-details" aria-label="Duration">8:48 - 9:03</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">To
 perform logistic, regression in Scikit-Learn, you import the logistic 
regression class from the sklearn.linear model module, then create the 
object and call the fit method using the training data just as you did 
for other class files like k nearest neighbors.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: To perform logistic, regression in Scikit-Learn, you import the logistic regression class from the sklearn.linear model module, then create the object and call the fit method using the training data just as you did for other class files like k nearest neighbors." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edita1918c2d-4ea5-4cc0-e61d-50cf1f427f8f Edita1918c2d-4ea5-4cc0-e61d-50cf1f427f8fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edita1918c2d-4ea5-4cc0-e61d-50cf1f427f8f">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: To perform logistic, regression in Scikit-Learn, you import the logistic regression class from the sklearn.linear model module, then create the object and call the fit method using the training data just as you did for other class files like k nearest neighbors." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete2abfebd2-413d-45d0-bc19-6cc937cda0a7 Delete2abfebd2-413d-45d0-bc19-6cc937cda0a7Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete2abfebd2-413d-45d0-bc19-6cc937cda0a7">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video965d31d5-79f0-4c3f-b374-ac06b7ba12d6 Video965d31d5-79f0-4c3f-b374-ac06b7ba12d6Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video965d31d5-79f0-4c3f-b374-ac06b7ba12d6">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/uClaN?t=713&quot;,&quot;itemId&quot;:&quot;uClaN&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/uClaN?t=713" href="https://www.coursera.org/learn/python-machine-learning/lecture/uClaN?t=713" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Classifiers: Support Vector Machines</div></a><div class="video-details" aria-label="Duration">11:53 - 12:20</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Larger
 values of C represent less regularization and will cause the model to 
fit the training set with these few errors as possible, even if it means
 using a small immersion decision boundary. Very small values of C on 
the other hand use more regularization that encourages the classifier to
 find a large marge on decision boundary, even if that decision boundary
 leads to more points being misclassified.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Larger values of C represent less regularization and will cause the model to fit the training set with these few errors as possible, even if it means using a small immersion decision boundary. Very small values of C on the other hand use more regularization that encourages the classifier to find a large marge on decision boundary, even if that decision boundary leads to more points being misclassified." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit6a098ff2-46b4-42b7-abbf-3e369f456cea Edit6a098ff2-46b4-42b7-abbf-3e369f456ceaDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit6a098ff2-46b4-42b7-abbf-3e369f456cea">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Larger values of C represent less regularization and will cause the model to fit the training set with these few errors as possible, even if it means using a small immersion decision boundary. Very small values of C on the other hand use more regularization that encourages the classifier to find a large marge on decision boundary, even if that decision boundary leads to more points being misclassified." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete8b428bba-b101-4ade-84be-828389261822 Delete8b428bba-b101-4ade-84be-828389261822Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete8b428bba-b101-4ade-84be-828389261822">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video70fc36b3-e957-4ded-db73-aeb70fac8e56 Video70fc36b3-e957-4ded-db73-aeb70fac8e56Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video70fc36b3-e957-4ded-db73-aeb70fac8e56">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/uClaN?t=33&quot;,&quot;itemId&quot;:&quot;uClaN&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/uClaN?t=33" href="https://www.coursera.org/learn/python-machine-learning/lecture/uClaN?t=33" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Classifiers: Support Vector Machines</div></a><div class="video-details" aria-label="Duration">0:33 - 0:43</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">If
 the target value is greater than zero, the function returns plus one 
and if it's less than zero, the function returns minus one. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: If the target value is greater than zero, the function returns plus one and if it's less than zero, the function returns minus one. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit85cdc300-8070-4049-c977-b4247776ca77 Edit85cdc300-8070-4049-c977-b4247776ca77Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit85cdc300-8070-4049-c977-b4247776ca77">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: If the target value is greater than zero, the function returns plus one and if it's less than zero, the function returns minus one. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleteb695898a-02b6-4edc-cfd7-a0c76b11df23 Deleteb695898a-02b6-4edc-cfd7-a0c76b11df23Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deleteb695898a-02b6-4edc-cfd7-a0c76b11df23">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video92fc970e-4f18-4173-c6b4-2d6ed703f3e2 Video92fc970e-4f18-4173-c6b4-2d6ed703f3e2Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video92fc970e-4f18-4173-c6b4-2d6ed703f3e2">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/uClaN?t=644&quot;,&quot;itemId&quot;:&quot;uClaN&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/uClaN?t=644" href="https://www.coursera.org/learn/python-machine-learning/lecture/uClaN?t=644" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Classifiers: Support Vector Machines</div></a><div class="video-details" aria-label="Duration">10:44 - 10:53</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">in
 the notebook on how to use the default linear support vector classifier
 in scikit-learn, which is defined in the sklearn SVM library.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: in the notebook on how to use the default linear support vector classifier in scikit-learn, which is defined in the sklearn SVM library." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editf18ca07c-6233-4cd9-ca98-472bcd4e3345 Editf18ca07c-6233-4cd9-ca98-472bcd4e3345Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editf18ca07c-6233-4cd9-ca98-472bcd4e3345">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: in the notebook on how to use the default linear support vector classifier in scikit-learn, which is defined in the sklearn SVM library." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletea90f596e-c4cb-47ee-dcef-198869729dab Deletea90f596e-c4cb-47ee-dcef-198869729dabDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletea90f596e-c4cb-47ee-dcef-198869729dab">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videode19bc96-c312-417c-c29e-d4199a00ea3d Videode19bc96-c312-417c-c29e-d4199a00ea3dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videode19bc96-c312-417c-c29e-d4199a00ea3d">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/uClaN?t=795&quot;,&quot;itemId&quot;:&quot;uClaN&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/uClaN?t=795" href="https://www.coursera.org/learn/python-machine-learning/lecture/uClaN?t=795" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Classifiers: Support Vector Machines</div></a><div class="video-details" aria-label="Duration">13:15 - 13:29</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Linear
 models including Linear Support Vector Machines also perform 
effectively on high dementional data set, especially, in cases where the
 data instances are sparse. Linear Models scale well to very large 
datasets as well.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Linear models including Linear Support Vector Machines also perform effectively on high dementional data set, especially, in cases where the data instances are sparse. Linear Models scale well to very large datasets as well." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit1fca179b-aa6e-43f7-a745-fee4970f5352 Edit1fca179b-aa6e-43f7-a745-fee4970f5352Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit1fca179b-aa6e-43f7-a745-fee4970f5352">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Linear models including Linear Support Vector Machines also perform effectively on high dementional data set, especially, in cases where the data instances are sparse. Linear Models scale well to very large datasets as well." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleteadc9dd94-a6ee-4c43-9d4c-4e6d34c63ccd Deleteadc9dd94-a6ee-4c43-9d4c-4e6d34c63ccdDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deleteadc9dd94-a6ee-4c43-9d4c-4e6d34c63ccd">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video04cbb21b-c2dc-4161-b91d-3f39922c1e5d Video04cbb21b-c2dc-4161-b91d-3f39922c1e5dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video04cbb21b-c2dc-4161-b91d-3f39922c1e5d">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/uClaN?t=485&quot;,&quot;itemId&quot;:&quot;uClaN&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/uClaN?t=485" href="https://www.coursera.org/learn/python-machine-learning/lecture/uClaN?t=485" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Classifiers: Support Vector Machines</div></a><div class="video-details" aria-label="Duration">8:05 - 8:37</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">So
 one way to define a good classifier is to reward classifiers for the 
amount of separation that can provide between the two classes. And to do
 this, we need define the concept of classifier margin. So informally, 
for our given classifier, The margin is the width that the decision 
boundary can be increased before hitting a data point. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: So one way to define a good classifier is to reward classifiers for the amount of separation that can provide between the two classes. And to do this, we need define the concept of classifier margin. So informally, for our given classifier, The margin is the width that the decision boundary can be increased before hitting a data point. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit38bcfb77-7eac-4e16-f35d-67d17225b662 Edit38bcfb77-7eac-4e16-f35d-67d17225b662Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit38bcfb77-7eac-4e16-f35d-67d17225b662">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: So one way to define a good classifier is to reward classifiers for the amount of separation that can provide between the two classes. And to do this, we need define the concept of classifier margin. So informally, for our given classifier, The margin is the width that the decision boundary can be increased before hitting a data point. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete37e9666a-b9a0-477e-d9e4-022216fa9944 Delete37e9666a-b9a0-477e-d9e4-022216fa9944Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete37e9666a-b9a0-477e-d9e4-022216fa9944">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video869644fa-1477-4fed-cb01-b9e94f0e60ea Video869644fa-1477-4fed-cb01-b9e94f0e60eaDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video869644fa-1477-4fed-cb01-b9e94f0e60ea">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/uClaN?t=819&quot;,&quot;itemId&quot;:&quot;uClaN&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/uClaN?t=819" href="https://www.coursera.org/learn/python-machine-learning/lecture/uClaN?t=819" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Classifiers: Support Vector Machines</div></a><div class="video-details" aria-label="Duration">13:39 - 13:42</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">So the algorithm can be implemented in a memory efficient way.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: So the algorithm can be implemented in a memory efficient way." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit097f84da-22ba-4681-8695-2a0ddf308caa Edit097f84da-22ba-4681-8695-2a0ddf308caaDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit097f84da-22ba-4681-8695-2a0ddf308caa">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: So the algorithm can be implemented in a memory efficient way." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete7acb79c5-457f-4751-af3c-9cd7a8d89d90 Delete7acb79c5-457f-4751-af3c-9cd7a8d89d90Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete7acb79c5-457f-4751-af3c-9cd7a8d89d90">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videof60c8796-61bf-4997-af05-ceae29281f67 Videof60c8796-61bf-4997-af05-ceae29281f67Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videof60c8796-61bf-4997-af05-ceae29281f67">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/uClaN?t=556&quot;,&quot;itemId&quot;:&quot;uClaN&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/uClaN?t=556" href="https://www.coursera.org/learn/python-machine-learning/lecture/uClaN?t=556" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Classifiers: Support Vector Machines</div></a><div class="video-details" aria-label="Duration">9:16 - 9:30</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">so
 among all possible classifiers that separate these two classes then, we
 can define the best classifier as the classifier that has the maximum 
amount of margin</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: so among all possible classifiers that separate these two classes then, we can define the best classifier as the classifier that has the maximum amount of margin" tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit67f6a1ec-9faf-4cfa-c562-53556ec67283 Edit67f6a1ec-9faf-4cfa-c562-53556ec67283Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit67f6a1ec-9faf-4cfa-c562-53556ec67283">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: so among all possible classifiers that separate these two classes then, we can define the best classifier as the classifier that has the maximum amount of margin" tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete1a678dc2-2afe-46b0-a6dc-0211648672f8 Delete1a678dc2-2afe-46b0-a6dc-0211648672f8Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete1a678dc2-2afe-46b0-a6dc-0211648672f8">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video9b89f354-f29f-4424-80fe-e73f7ee6d30b Video9b89f354-f29f-4424-80fe-e73f7ee6d30bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video9b89f354-f29f-4424-80fe-e73f7ee6d30b">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/uClaN?t=15&quot;,&quot;itemId&quot;:&quot;uClaN&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/uClaN?t=15" href="https://www.coursera.org/learn/python-machine-learning/lecture/uClaN?t=15" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Classifiers: Support Vector Machines</div></a><div class="video-details" aria-label="Duration">0:15 - 0:32</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">This
 approach to prediction uses the same linear functional form as we saw 
for regression. But instead of predicting a continuous target value, we 
take the output of the linear function and apply the sine function to 
produce a binary output with two possible values, corresponding to the 
two possible class labels.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: This approach to prediction uses the same linear functional form as we saw for regression. But instead of predicting a continuous target value, we take the output of the linear function and apply the sine function to produce a binary output with two possible values, corresponding to the two possible class labels." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit5143d40f-09d4-4e3a-d0d0-6bf4767b763c Edit5143d40f-09d4-4e3a-d0d0-6bf4767b763cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit5143d40f-09d4-4e3a-d0d0-6bf4767b763c">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: This approach to prediction uses the same linear functional form as we saw for regression. But instead of predicting a continuous target value, we take the output of the linear function and apply the sine function to produce a binary output with two possible values, corresponding to the two possible class labels." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete492462eb-6a8f-44d3-ce32-178d43eaf091 Delete492462eb-6a8f-44d3-ce32-178d43eaf091Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete492462eb-6a8f-44d3-ce32-178d43eaf091">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video40a266c6-a1bb-4a94-b01c-af740a30a920 Video40a266c6-a1bb-4a94-b01c-af740a30a920Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video40a266c6-a1bb-4a94-b01c-af740a30a920">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/uClaN?t=669&quot;,&quot;itemId&quot;:&quot;uClaN&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/uClaN?t=669" href="https://www.coursera.org/learn/python-machine-learning/lecture/uClaN?t=669" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Classifiers: Support Vector Machines</div></a><div class="video-details" aria-label="Duration">11:09 - 11:27</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">
 In practice though, we typically have noise or just more complexity in 
the data set that makes a perfect linear separation impossible, but 
where most points can be separated without errors by linear classifier.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text:  In practice though, we typically have noise or just more complexity in the data set that makes a perfect linear separation impossible, but where most points can be separated without errors by linear classifier." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit4e417fe5-5433-4886-cf6d-b5be6769ea40 Edit4e417fe5-5433-4886-cf6d-b5be6769ea40Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit4e417fe5-5433-4886-cf6d-b5be6769ea40">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text:  In practice though, we typically have noise or just more complexity in the data set that makes a perfect linear separation impossible, but where most points can be separated without errors by linear classifier." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete80315b7e-8fd8-4d46-84a4-d273f2ce7f1e Delete80315b7e-8fd8-4d46-84a4-d273f2ce7f1eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete80315b7e-8fd8-4d46-84a4-d273f2ce7f1e">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video95a5bc8a-049c-4668-c60e-5e76c47423e9 Video95a5bc8a-049c-4668-c60e-5e76c47423e9Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video95a5bc8a-049c-4668-c60e-5e76c47423e9">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/uClaN?t=180&quot;,&quot;itemId&quot;:&quot;uClaN&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/uClaN?t=180" href="https://www.coursera.org/learn/python-machine-learning/lecture/uClaN?t=180" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Classifiers: Support Vector Machines</div></a><div class="video-details" aria-label="Duration">3:00 - 3:13</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">We
 take the X values, and we have certain weights that are learned for the
 classifier. So we compute w1 x1 + w2 x2. Then we feed that, and then 
plus a bias term, if there is one.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: We take the X values, and we have certain weights that are learned for the classifier. So we compute w1 x1 + w2 x2. Then we feed that, and then plus a bias term, if there is one." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit0d526389-dbca-4002-a28f-6c0ee0aa3508 Edit0d526389-dbca-4002-a28f-6c0ee0aa3508Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit0d526389-dbca-4002-a28f-6c0ee0aa3508">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: We take the X values, and we have certain weights that are learned for the classifier. So we compute w1 x1 + w2 x2. Then we feed that, and then plus a bias term, if there is one." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleteda9b977d-bfba-49c2-a5c6-bb1ec43e24cf Deleteda9b977d-bfba-49c2-a5c6-bb1ec43e24cfDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deleteda9b977d-bfba-49c2-a5c6-bb1ec43e24cf">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoa7330f68-0a30-4f67-91ea-4ad11a7c1939 Videoa7330f68-0a30-4f67-91ea-4ad11a7c1939Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoa7330f68-0a30-4f67-91ea-4ad11a7c1939">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/uClaN?t=194&quot;,&quot;itemId&quot;:&quot;uClaN&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/uClaN?t=194" href="https://www.coursera.org/learn/python-machine-learning/lecture/uClaN?t=194" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Classifiers: Support Vector Machines</div></a><div class="video-details" aria-label="Duration">3:14 - 3:30</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">And
 we feed the output of that through the sign function that converts the 
value in here. If it's above 0, it'll convert to +1, and if it's below 
0, it'll convert it to -1 </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: And we feed the output of that through the sign function that converts the value in here. If it's above 0, it'll convert to +1, and if it's below 0, it'll convert it to -1 " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit8636860b-aab2-4430-db51-13a402205364 Edit8636860b-aab2-4430-db51-13a402205364Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit8636860b-aab2-4430-db51-13a402205364">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: And we feed the output of that through the sign function that converts the value in here. If it's above 0, it'll convert to +1, and if it's below 0, it'll convert it to -1 " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletec77efb2b-979c-4511-d2e8-d008414278f7 Deletec77efb2b-979c-4511-d2e8-d008414278f7Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletec77efb2b-979c-4511-d2e8-d008414278f7">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videof16dac90-6aa5-43a7-af97-8e3bfbe06cd9 Videof16dac90-6aa5-43a7-af97-8e3bfbe06cd9Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videof16dac90-6aa5-43a7-af97-8e3bfbe06cd9">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/uClaN?t=687&quot;,&quot;itemId&quot;:&quot;uClaN&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/uClaN?t=687" href="https://www.coursera.org/learn/python-machine-learning/lecture/uClaN?t=687" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Classifiers: Support Vector Machines</div></a><div class="video-details" aria-label="Duration">11:27 - 11:49</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">
 So how tolerant the support vector machine is of misclassifying 
training points, as compared to its objective of minimizing the margin 
between classes is controlled by a regularization parameter called C 
which by default is set to 1.0 as we have here.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text:  So how tolerant the support vector machine is of misclassifying training points, as compared to its objective of minimizing the margin between classes is controlled by a regularization parameter called C which by default is set to 1.0 as we have here." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit94d74949-7c38-4bad-d749-91c92bf1a930 Edit94d74949-7c38-4bad-d749-91c92bf1a930Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit94d74949-7c38-4bad-d749-91c92bf1a930">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text:  So how tolerant the support vector machine is of misclassifying training points, as compared to its objective of minimizing the margin between classes is controlled by a regularization parameter called C which by default is set to 1.0 as we have here." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete492eb5a4-50e3-455f-8c47-dd323451ec8e Delete492eb5a4-50e3-455f-8c47-dd323451ec8eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete492eb5a4-50e3-455f-8c47-dd323451ec8e">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video02cdbc72-7ceb-40d6-a007-9f38adc9dcdd Video02cdbc72-7ceb-40d6-a007-9f38adc9dcddDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video02cdbc72-7ceb-40d6-a007-9f38adc9dcdd">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/uClaN?t=782&quot;,&quot;itemId&quot;:&quot;uClaN&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/uClaN?t=782" href="https://www.coursera.org/learn/python-machine-learning/lecture/uClaN?t=782" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Classifiers: Support Vector Machines</div></a><div class="video-details" aria-label="Duration">13:02 - 13:14</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">On
 the positive side, linear models, in the case of linear and logistic 
regression, are simple and easy to train. And for all types of linear 
models, prediction's very fast because, of the linear nature of the 
prediction function.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: On the positive side, linear models, in the case of linear and logistic regression, are simple and easy to train. And for all types of linear models, prediction's very fast because, of the linear nature of the prediction function." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit478d838e-5e0a-4ee1-8c7d-8542c8dd19e7 Edit478d838e-5e0a-4ee1-8c7d-8542c8dd19e7Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit478d838e-5e0a-4ee1-8c7d-8542c8dd19e7">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: On the positive side, linear models, in the case of linear and logistic regression, are simple and easy to train. And for all types of linear models, prediction's very fast because, of the linear nature of the prediction function." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete0026ffdd-dd11-42a2-b1a7-32c6cbb2be40 Delete0026ffdd-dd11-42a2-b1a7-32c6cbb2be40Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete0026ffdd-dd11-42a2-b1a7-32c6cbb2be40">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video1818a762-e61c-4497-aadc-69840fcbf752 Video1818a762-e61c-4497-aadc-69840fcbf752Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video1818a762-e61c-4497-aadc-69840fcbf752">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/uClaN?t=810&quot;,&quot;itemId&quot;:&quot;uClaN&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/uClaN?t=810" href="https://www.coursera.org/learn/python-machine-learning/lecture/uClaN?t=810" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Classifiers: Support Vector Machines</div></a><div class="video-details" aria-label="Duration">13:30 - 13:38</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">In
 the case of Linear Support Vector Machines, they only use a subset of 
training points and decision function. These training points are called 
support vectors.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: In the case of Linear Support Vector Machines, they only use a subset of training points and decision function. These training points are called support vectors." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit38b66525-4426-4927-f9cc-cfada51f5864 Edit38b66525-4426-4927-f9cc-cfada51f5864Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit38b66525-4426-4927-f9cc-cfada51f5864">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: In the case of Linear Support Vector Machines, they only use a subset of training points and decision function. These training points are called support vectors." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete240cf30a-a952-4500-e2d9-3cf9836ea924 Delete240cf30a-a952-4500-e2d9-3cf9836ea924Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete240cf30a-a952-4500-e2d9-3cf9836ea924">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video4e1c3c03-863f-4b8c-d763-ff7023648783 Video4e1c3c03-863f-4b8c-d763-ff7023648783Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video4e1c3c03-863f-4b8c-d763-ff7023648783">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/uClaN?t=614&quot;,&quot;itemId&quot;:&quot;uClaN&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/uClaN?t=614" href="https://www.coursera.org/learn/python-machine-learning/lecture/uClaN?t=614" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Classifiers: Support Vector Machines</div></a><div class="video-details" aria-label="Duration">10:14 - 10:25</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">This
 maximum margin classifier is called the Linear Support Vector Machine, 
also known as an LSVM or a support vector machine with linear kernel.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: This maximum margin classifier is called the Linear Support Vector Machine, also known as an LSVM or a support vector machine with linear kernel." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editc246d602-f047-46b3-c8f9-e6ce5c30145d Editc246d602-f047-46b3-c8f9-e6ce5c30145dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editc246d602-f047-46b3-c8f9-e6ce5c30145d">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: This maximum margin classifier is called the Linear Support Vector Machine, also known as an LSVM or a support vector machine with linear kernel." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete5f0e2798-5fdf-410b-e2d8-27432cf19ef0 Delete5f0e2798-5fdf-410b-e2d8-27432cf19ef0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete5f0e2798-5fdf-410b-e2d8-27432cf19ef0">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video9b880045-c225-4e9f-850a-0a387eb3a2f9 Video9b880045-c225-4e9f-850a-0a387eb3a2f9Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video9b880045-c225-4e9f-850a-0a387eb3a2f9">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/uClaN?t=7&quot;,&quot;itemId&quot;:&quot;uClaN&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/uClaN?t=7" href="https://www.coursera.org/learn/python-machine-learning/lecture/uClaN?t=7" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Linear Classifiers: Support Vector Machines</div></a><div class="video-details" aria-label="Duration">0:07 - 0:13</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Let's look at how linear models are also used for classification, starting with binary classification.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Let's look at how linear models are also used for classification, starting with binary classification." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editd5c43fcf-1e2f-435b-f090-5b74d22eb42f Editd5c43fcf-1e2f-435b-f090-5b74d22eb42fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editd5c43fcf-1e2f-435b-f090-5b74d22eb42f">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Let's look at how linear models are also used for classification, starting with binary classification." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete5e1b9105-a0e6-4c4a-a8d2-49e770b69d55 Delete5e1b9105-a0e6-4c4a-a8d2-49e770b69d55Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete5e1b9105-a0e6-4c4a-a8d2-49e770b69d55">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoc6bf787c-4e61-495a-cc6b-a228badf3459 Videoc6bf787c-4e61-495a-cc6b-a228badf3459Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoc6bf787c-4e61-495a-cc6b-a228badf3459">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/V2gAg?t=50&quot;,&quot;itemId&quot;:&quot;V2gAg&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/V2gAg?t=50" href="https://www.coursera.org/learn/python-machine-learning/lecture/V2gAg?t=50" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Multi-Class Classification</div></a><div class="video-details" aria-label="Duration">0:50 - 0:59</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Essentially, it does this by converting a multiclass classification problem into a series of binary problems. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Essentially, it does this by converting a multiclass classification problem into a series of binary problems. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit54568bdb-837a-4c4e-f8d7-7d18ae191d48 Edit54568bdb-837a-4c4e-f8d7-7d18ae191d48Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit54568bdb-837a-4c4e-f8d7-7d18ae191d48">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Essentially, it does this by converting a multiclass classification problem into a series of binary problems. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete564c1d04-0a14-4e9d-b335-7390465dae1a Delete564c1d04-0a14-4e9d-b335-7390465dae1aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete564c1d04-0a14-4e9d-b335-7390465dae1a">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video7f682cd1-4c63-4c3c-8fa4-e17471ff9f3d Video7f682cd1-4c63-4c3c-8fa4-e17471ff9f3dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video7f682cd1-4c63-4c3c-8fa4-e17471ff9f3d">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/V2gAg?t=59&quot;,&quot;itemId&quot;:&quot;V2gAg&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/V2gAg?t=59" href="https://www.coursera.org/learn/python-machine-learning/lecture/V2gAg?t=59" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Multi-Class Classification</div></a><div class="video-details" aria-label="Duration">0:59 - 1:27</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">when
 you pass in a dataset that has a categorical variable for the target 
value, scikit-learn detects this automatically and then for each class 
to be predicted. Scikit-learn creates one binary classifier that 
predicts that class against all the other classes. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: when you pass in a dataset that has a categorical variable for the target value, scikit-learn detects this automatically and then for each class to be predicted. Scikit-learn creates one binary classifier that predicts that class against all the other classes. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editb2473ef7-74e4-402b-c092-8ef703b073a9 Editb2473ef7-74e4-402b-c092-8ef703b073a9Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editb2473ef7-74e4-402b-c092-8ef703b073a9">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: when you pass in a dataset that has a categorical variable for the target value, scikit-learn detects this automatically and then for each class to be predicted. Scikit-learn creates one binary classifier that predicts that class against all the other classes. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete9d5b522d-1515-4f3b-fced-743fc3d43c7b Delete9d5b522d-1515-4f3b-fced-743fc3d43c7bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete9d5b522d-1515-4f3b-fced-743fc3d43c7b">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video83fdca66-d8da-47b7-8330-7abdf6495ba1 Video83fdca66-d8da-47b7-8330-7abdf6495ba1Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video83fdca66-d8da-47b7-8330-7abdf6495ba1">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/V2gAg?t=35&quot;,&quot;itemId&quot;:&quot;V2gAg&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/V2gAg?t=35" href="https://www.coursera.org/learn/python-machine-learning/lecture/V2gAg?t=35" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Multi-Class Classification</div></a><div class="video-details" aria-label="Duration">0:35 - 0:41</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">how do we deal with this multiclass classification situation with scikit-learn?</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: how do we deal with this multiclass classification situation with scikit-learn?" tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editf41317c4-f90f-4369-f3be-0809c4986be4 Editf41317c4-f90f-4369-f3be-0809c4986be4Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editf41317c4-f90f-4369-f3be-0809c4986be4">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: how do we deal with this multiclass classification situation with scikit-learn?" tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete603671c7-2b6e-41b2-ee5f-36a5403f72b8 Delete603671c7-2b6e-41b2-ee5f-36a5403f72b8Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete603671c7-2b6e-41b2-ee5f-36a5403f72b8">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video28847496-b495-493d-d918-0581b741b5ed Video28847496-b495-493d-d918-0581b741b5edDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video28847496-b495-493d-d918-0581b741b5ed">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/V2gAg?t=141&quot;,&quot;itemId&quot;:&quot;V2gAg&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/V2gAg?t=141" href="https://www.coursera.org/learn/python-machine-learning/lecture/V2gAg?t=141" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Multi-Class Classification</div></a><div class="video-details" aria-label="Duration">2:21 - 2:36</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">And
 in general, if we're just, you know, fitting, and then predicting, all 
of this would be completely transparent. Scikit-learn would simply do 
the right thing and it would learn multiple classes, and it would 
predict multiple classes, and we wouldn't really have to do much else.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: And in general, if we're just, you know, fitting, and then predicting, all of this would be completely transparent. Scikit-learn would simply do the right thing and it would learn multiple classes, and it would predict multiple classes, and we wouldn't really have to do much else." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit99dad4cb-a387-40cf-b524-60e7d4ecfaf7 Edit99dad4cb-a387-40cf-b524-60e7d4ecfaf7Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit99dad4cb-a387-40cf-b524-60e7d4ecfaf7">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: And in general, if we're just, you know, fitting, and then predicting, all of this would be completely transparent. Scikit-learn would simply do the right thing and it would learn multiple classes, and it would predict multiple classes, and we wouldn't really have to do much else." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletefa2bcea5-0c44-4222-c703-de6a2fe4398f Deletefa2bcea5-0c44-4222-c703-de6a2fe4398fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletefa2bcea5-0c44-4222-c703-de6a2fe4398f">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video68824a15-e97b-4efc-f0ce-e473bb83104f Video68824a15-e97b-4efc-f0ce-e473bb83104fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video68824a15-e97b-4efc-f0ce-e473bb83104f">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=716&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=716" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=716" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">11:56 - 12:15</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">The
 polynomial kernel, using the kernel poly setting, essentially 
represents a future transformation similar to the earlier quadratic 
example. In the lecture, this future space represented in terms of 
futures that are polynomial combinations of the original input features,
 much as we saw also for linear regression.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: The polynomial kernel, using the kernel poly setting, essentially represents a future transformation similar to the earlier quadratic example. In the lecture, this future space represented in terms of futures that are polynomial combinations of the original input features, much as we saw also for linear regression." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edita9b0f67b-0896-498c-9c00-84d7a03ac283 Edita9b0f67b-0896-498c-9c00-84d7a03ac283Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edita9b0f67b-0896-498c-9c00-84d7a03ac283">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: The polynomial kernel, using the kernel poly setting, essentially represents a future transformation similar to the earlier quadratic example. In the lecture, this future space represented in terms of futures that are polynomial combinations of the original input features, much as we saw also for linear regression." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete9e7e5dbe-ad0c-4c4e-bbd9-95b1840c5f60 Delete9e7e5dbe-ad0c-4c4e-bbd9-95b1840c5f60Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete9e7e5dbe-ad0c-4c4e-bbd9-95b1840c5f60">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video7980075e-6577-4ca8-da49-ac02776a3c37 Video7980075e-6577-4ca8-da49-ac02776a3c37Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video7980075e-6577-4ca8-da49-ac02776a3c37">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=187&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=187" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=187" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">3:07 - 3:16</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">to
 a corresponding 2-dimensional ordered pair xi, xi squared, whose new 
second feature is the squared value of the first feature.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: to a corresponding 2-dimensional ordered pair xi, xi squared, whose new second feature is the squared value of the first feature." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit20528aeb-787b-44f8-9ee2-fcda0da47071 Edit20528aeb-787b-44f8-9ee2-fcda0da47071Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit20528aeb-787b-44f8-9ee2-fcda0da47071">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: to a corresponding 2-dimensional ordered pair xi, xi squared, whose new second feature is the squared value of the first feature." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete169393cc-ebce-489c-f3ef-5549ae6fd062 Delete169393cc-ebce-489c-f3ef-5549ae6fd062Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete169393cc-ebce-489c-f3ef-5549ae6fd062">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video93acb60f-2592-4b48-f326-5082b7bec6de Video93acb60f-2592-4b48-f326-5082b7bec6deDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video93acb60f-2592-4b48-f326-5082b7bec6de">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=494&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=494" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=494" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">8:14 - 8:29</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Using
 the radial basis function kernel in effect, transforms all the points 
inside a certain distance of the circle class to one area of the 
transformed feature space. And all the points in the square class 
outside a certain radius get moved to a different area of the feature 
space.</div><div class="video-note-text-box video-note-text" aria-label="User Note">xxxx</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Using the radial basis function kernel in effect, transforms all the points inside a certain distance of the circle class to one area of the transformed feature space. And all the points in the square class outside a certain radius get moved to a different area of the feature space." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editc6f077dc-9790-43f0-8238-565105a5d03c Editc6f077dc-9790-43f0-8238-565105a5d03cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editc6f077dc-9790-43f0-8238-565105a5d03c">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Using the radial basis function kernel in effect, transforms all the points inside a certain distance of the circle class to one area of the transformed feature space. And all the points in the square class outside a certain radius get moved to a different area of the feature space." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete759ee528-ac77-46c5-eb22-afe263671539 Delete759ee528-ac77-46c5-eb22-afe263671539Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete759ee528-ac77-46c5-eb22-afe263671539">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoa8389ca4-2768-4683-8a6a-35f9ffdf906b Videoa8389ca4-2768-4683-8a6a-35f9ffdf906bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videoa8389ca4-2768-4683-8a6a-35f9ffdf906b">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=7&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=7" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=7" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">0:07 - 0:17</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">We
 saw earlier how linear support vector machines served as effective 
classifiers for some datasets, by finding a decision boundary with 
maximum margin between the classes.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: We saw earlier how linear support vector machines served as effective classifiers for some datasets, by finding a decision boundary with maximum margin between the classes." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit2b58521d-6cbe-4bc1-ee33-1a1ff9ea6d35 Edit2b58521d-6cbe-4bc1-ee33-1a1ff9ea6d35Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit2b58521d-6cbe-4bc1-ee33-1a1ff9ea6d35">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: We saw earlier how linear support vector machines served as effective classifiers for some datasets, by finding a decision boundary with maximum margin between the classes." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete90c0132d-7e42-4409-9990-4e30019cf39a Delete90c0132d-7e42-4409-9990-4e30019cf39aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete90c0132d-7e42-4409-9990-4e30019cf39a">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videob371f41d-6ae4-4862-b2d7-af0b8d88c6c5 Videob371f41d-6ae4-4862-b2d7-af0b8d88c6c5Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videob371f41d-6ae4-4862-b2d7-af0b8d88c6c5">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=32&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=32" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=32" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">0:32 - 0:44</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">But
 with real data, many classification problems aren't this easy. With the
 different classes located in future space in a way that a line or 
hyperplane can't act as an effective classifier. Here's an example on 
the right.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: But with real data, many classification problems aren't this easy. With the different classes located in future space in a way that a line or hyperplane can't act as an effective classifier. Here's an example on the right." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editac607fcd-9261-4601-89d0-c42fe6c4b793 Editac607fcd-9261-4601-89d0-c42fe6c4b793Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editac607fcd-9261-4601-89d0-c42fe6c4b793">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: But with real data, many classification problems aren't this easy. With the different classes located in future space in a way that a line or hyperplane can't act as an effective classifier. Here's an example on the right." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete7de1030f-6162-4993-d5a6-c7f30fb095fe Delete7de1030f-6162-4993-d5a6-c7f30fb095feDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete7de1030f-6162-4993-d5a6-c7f30fb095fe">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoa2d49c5d-cb12-4d30-f20e-d4a912ecc03c Videoa2d49c5d-cb12-4d30-f20e-d4a912ecc03cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videoa2d49c5d-cb12-4d30-f20e-d4a912ecc03c">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=219&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=219" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=219" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">3:39 - 3:46</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">We can now learn a linear support vector machine in this new, 2-deminsional feature space, </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: We can now learn a linear support vector machine in this new, 2-deminsional feature space, " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edita9a8160d-e5b9-4f1f-b4cf-3c5dbebd8663 Edita9a8160d-e5b9-4f1f-b4cf-3c5dbebd8663Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edita9a8160d-e5b9-4f1f-b4cf-3c5dbebd8663">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: We can now learn a linear support vector machine in this new, 2-deminsional feature space, " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletef876a8fd-1fb0-45dc-e153-7c55635ae28a Deletef876a8fd-1fb0-45dc-e153-7c55635ae28aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletef876a8fd-1fb0-45dc-e153-7c55635ae28a">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video086be096-c146-45ed-b0f1-329e2b926e0c Video086be096-c146-45ed-b0f1-329e2b926e0cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video086be096-c146-45ed-b0f1-329e2b926e0c">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=173&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=173" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=173" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">2:53 - 3:00</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">One very powerful idea is to transform the input data from a 1-dimensional space to a 2-dimensional space.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: One very powerful idea is to transform the input data from a 1-dimensional space to a 2-dimensional space." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editeb10b96d-0c5f-479e-caa5-c465e6a694f0 Editeb10b96d-0c5f-479e-caa5-c465e6a694f0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editeb10b96d-0c5f-479e-caa5-c465e6a694f0">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: One very powerful idea is to transform the input data from a 1-dimensional space to a 2-dimensional space." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete3fa4cc70-b45a-4bd0-8f75-c0b30b19fcce Delete3fa4cc70-b45a-4bd0-8f75-c0b30b19fcceDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete3fa4cc70-b45a-4bd0-8f75-c0b30b19fcce">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videocf57ef54-2364-4a28-9c44-b240aa652065 Videocf57ef54-2364-4a28-9c44-b240aa652065Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videocf57ef54-2364-4a28-9c44-b240aa652065">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=1111&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=1111" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=1111" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">18:31 - 18:38</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">In
 the case of the RBF kernel, SVM performance is very sensitive to the 
setting of the gamma parameter that controls the kernel width.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: In the case of the RBF kernel, SVM performance is very sensitive to the setting of the gamma parameter that controls the kernel width." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editd5d8bfb7-24d7-4239-d777-00ac5afa1f4a Editd5d8bfb7-24d7-4239-d777-00ac5afa1f4aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editd5d8bfb7-24d7-4239-d777-00ac5afa1f4a">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: In the case of the RBF kernel, SVM performance is very sensitive to the setting of the gamma parameter that controls the kernel width." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete32cec0ec-9134-4ec9-a1ed-1ea9f13cf62b Delete32cec0ec-9134-4ec9-a1ed-1ea9f13cf62bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete32cec0ec-9134-4ec9-a1ed-1ea9f13cf62b">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video3e3f8f4b-1571-45c9-b44f-2e6a1e13267c Video3e3f8f4b-1571-45c9-b44f-2e6a1e13267cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video3e3f8f4b-1571-45c9-b44f-2e6a1e13267c">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=543&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=543" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=543" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">9:03 - 9:17</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">The
 linear decision boundary learn feature space by linear SVM corresponds 
to a non-linear decision boundary In the original input space. So in 
this example, an ellipse like closed region in the input space.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: The linear decision boundary learn feature space by linear SVM corresponds to a non-linear decision boundary In the original input space. So in this example, an ellipse like closed region in the input space." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit70d2b7ba-1a6e-4de6-a037-77e691657984 Edit70d2b7ba-1a6e-4de6-a037-77e691657984Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit70d2b7ba-1a6e-4de6-a037-77e691657984">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: The linear decision boundary learn feature space by linear SVM corresponds to a non-linear decision boundary In the original input space. So in this example, an ellipse like closed region in the input space." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete8d1ea61d-1c9b-47f5-eb93-5f7c175b346c Delete8d1ea61d-1c9b-47f5-eb93-5f7c175b346cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete8d1ea61d-1c9b-47f5-eb93-5f7c175b346c">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video5848b27d-ac4e-418e-c4c9-9c613c026711 Video5848b27d-ac4e-418e-c4c9-9c613c026711Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video5848b27d-ac4e-418e-c4c9-9c613c026711">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=680&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=680" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=680" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">11:20 - 11:33</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">To
 use SVMs, we simply import the SVC class from sklearn.svm and use it 
just as we would in the other classifier. For example, by calling the 
fit method with the training data to train the model.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: To use SVMs, we simply import the SVC class from sklearn.svm and use it just as we would in the other classifier. For example, by calling the fit method with the training data to train the model." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit9b0b0997-4765-4658-b72d-d556feb22c45 Edit9b0b0997-4765-4658-b72d-d556feb22c45Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit9b0b0997-4765-4658-b72d-d556feb22c45">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: To use SVMs, we simply import the SVC class from sklearn.svm and use it just as we would in the other classifier. For example, by calling the fit method with the training data to train the model." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleteffce8193-a763-42c3-b1f8-f35df51f6341 Deleteffce8193-a763-42c3-b1f8-f35df51f6341Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deleteffce8193-a763-42c3-b1f8-f35df51f6341">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video10afacdf-cb83-4a1a-993a-2bd61dc3948a Video10afacdf-cb83-4a1a-993a-2bd61dc3948aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video10afacdf-cb83-4a1a-993a-2bd61dc3948a">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=991&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=991" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=991" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">16:31 - 17:00</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Support
 vector machines also typically work well for both low and 
high-dimensional data. Including data with hundreds, thousands or even 
millions of sparse dimensions. This makes it well suited to test 
classification for example. On the negative side as the training set 
size increases, the run time, speed, and memory usage in the SVM 
training phase also increases. So for a large datasets with hundreds of 
thousands, or millions of instances, an SVM may become less practical.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Support vector machines also typically work well for both low and high-dimensional data. Including data with hundreds, thousands or even millions of sparse dimensions. This makes it well suited to test classification for example. On the negative side as the training set size increases, the run time, speed, and memory usage in the SVM training phase also increases. So for a large datasets with hundreds of thousands, or millions of instances, an SVM may become less practical." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editca6abb1d-8523-4996-c98a-cb11db07344d Editca6abb1d-8523-4996-c98a-cb11db07344dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editca6abb1d-8523-4996-c98a-cb11db07344d">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Support vector machines also typically work well for both low and high-dimensional data. Including data with hundreds, thousands or even millions of sparse dimensions. This makes it well suited to test classification for example. On the negative side as the training set size increases, the run time, speed, and memory usage in the SVM training phase also increases. So for a large datasets with hundreds of thousands, or millions of instances, an SVM may become less practical." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleteda88640a-fad4-4370-d241-92b52e7b4aae Deleteda88640a-fad4-4370-d241-92b52e7b4aaeDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deleteda88640a-fad4-4370-d241-92b52e7b4aae">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video0d7c34a4-350a-47ec-ed0a-41e3adc1bad3 Video0d7c34a4-350a-47ec-ed0a-41e3adc1bad3Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video0d7c34a4-350a-47ec-ed0a-41e3adc1bad3">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=618&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=618" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=618" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">10:18 - 10:24</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Even better, we could easily plug in a variety of different kernels choosing one to suit the properties of our data.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Even better, we could easily plug in a variety of different kernels choosing one to suit the properties of our data." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit14b57d79-6582-4750-cb44-02496fc23e82 Edit14b57d79-6582-4750-cb44-02496fc23e82Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit14b57d79-6582-4750-cb44-02496fc23e82">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Even better, we could easily plug in a variety of different kernels choosing one to suit the properties of our data." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletec5bef2f6-0297-44f5-daa7-1272503210cb Deletec5bef2f6-0297-44f5-daa7-1272503210cbDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletec5bef2f6-0297-44f5-daa7-1272503210cb">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoc7bc9a44-5872-4ebf-8039-e18bffa07dcf Videoc7bc9a44-5872-4ebf-8039-e18bffa07dcfDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videoc7bc9a44-5872-4ebf-8039-e18bffa07dcf">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=59&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=59" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=59" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">0:59 - 1:05</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">A very powerful extension of linear support vector machines called kernelized support vector machines.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: A very powerful extension of linear support vector machines called kernelized support vector machines." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editfe59b963-ad17-4e0c-ea60-bba9c6bc4ddc Editfe59b963-ad17-4e0c-ea60-bba9c6bc4ddcDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editfe59b963-ad17-4e0c-ea60-bba9c6bc4ddc">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: A very powerful extension of linear support vector machines called kernelized support vector machines." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete2347dce5-b025-4506-a81c-80921c38e7a6 Delete2347dce5-b025-4506-a81c-80921c38e7a6Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete2347dce5-b025-4506-a81c-80921c38e7a6">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoc5d2d01e-5eea-4244-942a-b4e458a93def Videoc5d2d01e-5eea-4244-942a-b4e458a93defDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videoc5d2d01e-5eea-4244-942a-b4e458a93def">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=232&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=232" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=232" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">3:52 - 4:12</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Any
 future 1-dimensional points for which we'd like to predict the class, 
we can just create the 2-deminsional transformed version and predict the
 class of the 2-deminsional point, using this 2-deminsional linear SVM. 
If we took the inverse of the transformation we just applied to bring 
the data points back to our original input space,</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Any future 1-dimensional points for which we'd like to predict the class, we can just create the 2-deminsional transformed version and predict the class of the 2-deminsional point, using this 2-deminsional linear SVM. If we took the inverse of the transformation we just applied to bring the data points back to our original input space," tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit803cb182-f04a-4e5e-ae3e-93a21eb7df9b Edit803cb182-f04a-4e5e-ae3e-93a21eb7df9bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit803cb182-f04a-4e5e-ae3e-93a21eb7df9b">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Any future 1-dimensional points for which we'd like to predict the class, we can just create the 2-deminsional transformed version and predict the class of the 2-deminsional point, using this 2-deminsional linear SVM. If we took the inverse of the transformation we just applied to bring the data points back to our original input space," tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete35db1c1b-10b1-4bde-fac0-ecb30d58f652 Delete35db1c1b-10b1-4bde-fac0-ecb30d58f652Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete35db1c1b-10b1-4bde-fac0-ecb30d58f652">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video4c6ec54a-8b48-46fd-a67b-19639614876a Video4c6ec54a-8b48-46fd-a67b-19639614876aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video4c6ec54a-8b48-46fd-a67b-19639614876a">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=66&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=66" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=66" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">1:06 - 1:15</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">kernelized
 support vector machines, which I'll just call SVMs, can provide more 
complex models that can go beyond linear decision boundaries.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: kernelized support vector machines, which I'll just call SVMs, can provide more complex models that can go beyond linear decision boundaries." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit9afa2b08-053e-4acb-d212-9b5036500ca5 Edit9afa2b08-053e-4acb-d212-9b5036500ca5Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit9afa2b08-053e-4acb-d212-9b5036500ca5">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: kernelized support vector machines, which I'll just call SVMs, can provide more complex models that can go beyond linear decision boundaries." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete4801f898-36eb-481f-f56a-53708c4267d1 Delete4801f898-36eb-481f-f56a-53708c4267d1Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete4801f898-36eb-481f-f56a-53708c4267d1">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video135efb2b-3330-4ffb-8d03-821c37661000 Video135efb2b-3330-4ffb-8d03-821c37661000Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video135efb2b-3330-4ffb-8d03-821c37661000">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=1022&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=1022" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=1022" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">17:02 - 17:11</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">As
 we saw when applying a support vector machine to a real world dataset, 
using an SVM requires careful normalization of the input data as well as
 parameter tuning.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: As we saw when applying a support vector machine to a real world dataset, using an SVM requires careful normalization of the input data as well as parameter tuning." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit556bd85c-0e49-40a3-969b-3927e6926268 Edit556bd85c-0e49-40a3-969b-3927e6926268Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit556bd85c-0e49-40a3-969b-3927e6926268">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: As we saw when applying a support vector machine to a real world dataset, using an SVM requires careful normalization of the input data as well as parameter tuning." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete51273e21-ca47-4e1e-e575-2d436bb4a893 Delete51273e21-ca47-4e1e-e575-2d436bb4a893Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete51273e21-ca47-4e1e-e575-2d436bb4a893">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video0e5f554c-e09f-443c-9308-5700e3d09e98 Video0e5f554c-e09f-443c-9308-5700e3d09e98Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video0e5f554c-e09f-443c-9308-5700e3d09e98">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=694&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=694" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=694" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">11:34 - 11:40</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">There is an SVC parameter called kernel, that allows us to set the kernel function used by the SVM.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: There is an SVC parameter called kernel, that allows us to set the kernel function used by the SVM." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editc8d96fdb-dccf-40ac-f8fc-f6430e443446 Editc8d96fdb-dccf-40ac-f8fc-f6430e443446Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editc8d96fdb-dccf-40ac-f8fc-f6430e443446">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: There is an SVC parameter called kernel, that allows us to set the kernel function used by the SVM." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete4c67561d-f420-4dde-9a7d-7b80c31313c8 Delete4c67561d-f420-4dde-9a7d-7b80c31313c8Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete4c67561d-f420-4dde-9a7d-7b80c31313c8">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videod41a8faa-f036-4c40-f834-0ed373fef90e Videod41a8faa-f036-4c40-f834-0ed373fef90eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videod41a8faa-f036-4c40-f834-0ed373fef90e">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=1120&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=1120" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=1120" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">18:40 - 18:52</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Finally,
 for any support vector machine, the C: regularization parameter 
operates as we've discussed before. And it's typically tuned with the 
kernel parameters such as gamma for optimal performance.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Finally, for any support vector machine, the C: regularization parameter operates as we've discussed before. And it's typically tuned with the kernel parameters such as gamma for optimal performance." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editf56c30ad-fea5-4231-fd83-3c53454208a0 Editf56c30ad-fea5-4231-fd83-3c53454208a0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editf56c30ad-fea5-4231-fd83-3c53454208a0">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Finally, for any support vector machine, the C: regularization parameter operates as we've discussed before. And it's typically tuned with the kernel parameters such as gamma for optimal performance." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete53891d63-2329-4663-b4f6-8b550db9d8fc Delete53891d63-2329-4663-b4f6-8b550db9d8fcDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete53891d63-2329-4663-b4f6-8b550db9d8fc">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video8c0c4087-f0aa-4663-be2b-e422e0367b2a Video8c0c4087-f0aa-4663-be2b-e422e0367b2aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video8c0c4087-f0aa-4663-be2b-e422e0367b2a">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=842&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=842" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=842" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">14:02 - 14:07</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">This example from the notebook shows the effect of varying C and gamma together.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: This example from the notebook shows the effect of varying C and gamma together." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editfe3f85dc-bd9d-4507-8d99-71ea59032c2c Editfe3f85dc-bd9d-4507-8d99-71ea59032c2cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editfe3f85dc-bd9d-4507-8d99-71ea59032c2c">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: This example from the notebook shows the effect of varying C and gamma together." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete29f87c41-a53d-4d21-84ea-5e88225d6eef Delete29f87c41-a53d-4d21-84ea-5e88225d6eefDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete29f87c41-a53d-4d21-84ea-5e88225d6eef">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video4d924bb0-954a-46ff-86e0-3ceed78cd27a Video4d924bb0-954a-46ff-86e0-3ceed78cd27aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video4d924bb0-954a-46ff-86e0-3ceed78cd27a">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=1103&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=1103" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=1103" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">18:23 - 18:30</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Second,
 each kernel has one or more kernel specific parameters that control 
aspects like the influence of training points according to their 
distance.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Second, each kernel has one or more kernel specific parameters that control aspects like the influence of training points according to their distance." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit50f43570-e7ba-4434-e59c-f0284669113f Edit50f43570-e7ba-4434-e59c-f0284669113fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit50f43570-e7ba-4434-e59c-f0284669113f">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Second, each kernel has one or more kernel specific parameters that control aspects like the influence of training points according to their distance." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete2bca1586-71aa-4b4d-9b8e-dfc657e50f4d Delete2bca1586-71aa-4b4d-9b8e-dfc657e50f4dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete2bca1586-71aa-4b4d-9b8e-dfc657e50f4d">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video43e345da-6b1c-4ac4-fd23-874de336c11d Video43e345da-6b1c-4ac4-fd23-874de336c11dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video43e345da-6b1c-4ac4-fd23-874de336c11d">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=861&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=861" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=861" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">14:21 - 14:40</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Typically,
 gamma and C are tuned together, with the optimal combination typically 
in an intermediate range of values. For example, gamma between 0.0001 
and 10 and see between 0.1 and 100. Though the specifical optimal values
 will depend on your application.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Typically, gamma and C are tuned together, with the optimal combination typically in an intermediate range of values. For example, gamma between 0.0001 and 10 and see between 0.1 and 100. Though the specifical optimal values will depend on your application." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editbad25b45-5817-429d-dfe9-e86de6b55a1b Editbad25b45-5817-429d-dfe9-e86de6b55a1bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editbad25b45-5817-429d-dfe9-e86de6b55a1b">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Typically, gamma and C are tuned together, with the optimal combination typically in an intermediate range of values. For example, gamma between 0.0001 and 10 and see between 0.1 and 100. Though the specifical optimal values will depend on your application." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete8f9b69fa-12b7-4283-c83d-903ede5b0338 Delete8f9b69fa-12b7-4283-c83d-903ede5b0338Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete8f9b69fa-12b7-4283-c83d-903ede5b0338">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video2a08d929-2df5-45bd-f298-39bf4811d0f3 Video2a08d929-2df5-45bd-f298-39bf4811d0f3Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video2a08d929-2df5-45bd-f298-39bf4811d0f3">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=817&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=817" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=817" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">13:37 - 14:00</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">You
 may recall from linear SVMs that SVMs also have a regularization 
parameter, C, that controls the tradeoff between satisfying the maximum 
margin criterion to find the simple decision boundary, and avoiding 
misclassification errors on the training set. The C parameter is also an
 important one for kernelized SVMs, and it interacts with the gamma 
parameter.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: You may recall from linear SVMs that SVMs also have a regularization parameter, C, that controls the tradeoff between satisfying the maximum margin criterion to find the simple decision boundary, and avoiding misclassification errors on the training set. The C parameter is also an important one for kernelized SVMs, and it interacts with the gamma parameter." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit117ac82d-f0d8-4480-a48b-1c8e8c01226a Edit117ac82d-f0d8-4480-a48b-1c8e8c01226aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit117ac82d-f0d8-4480-a48b-1c8e8c01226a">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: You may recall from linear SVMs that SVMs also have a regularization parameter, C, that controls the tradeoff between satisfying the maximum margin criterion to find the simple decision boundary, and avoiding misclassification errors on the training set. The C parameter is also an important one for kernelized SVMs, and it interacts with the gamma parameter." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete49303dcc-3306-4451-8339-47a0ce8166ba Delete49303dcc-3306-4451-8339-47a0ce8166baDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete49303dcc-3306-4451-8339-47a0ce8166ba">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videod63813d5-a4ed-474c-f25b-825720028fd3 Videod63813d5-a4ed-474c-f25b-825720028fd3Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videod63813d5-a4ed-474c-f25b-825720028fd3">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=557&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=557" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=557" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">9:17 - 9:33</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">one
 of the mathematically remarkable things about kernelized support vector
 machines, something referred to as the kernel trick, is that 
internally, the algorithm doesn't have to perform this actual 
transformation on the data points to the new high dimensional feature 
space.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: one of the mathematically remarkable things about kernelized support vector machines, something referred to as the kernel trick, is that internally, the algorithm doesn't have to perform this actual transformation on the data points to the new high dimensional feature space." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit706c0136-7f97-4b50-c8f7-2eef1059845a Edit706c0136-7f97-4b50-c8f7-2eef1059845aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit706c0136-7f97-4b50-c8f7-2eef1059845a">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: one of the mathematically remarkable things about kernelized support vector machines, something referred to as the kernel trick, is that internally, the algorithm doesn't have to perform this actual transformation on the data points to the new high dimensional feature space." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete6e5fc18f-f63b-4b7d-a2f1-a2d41ba32df9 Delete6e5fc18f-f63b-4b7d-a2f1-a2d41ba32df9Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete6e5fc18f-f63b-4b7d-a2f1-a2d41ba32df9">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video52d6dba3-2002-4fbf-85e0-fbe0f29eaae9 Video52d6dba3-2002-4fbf-85e0-fbe0f29eaae9Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video52d6dba3-2002-4fbf-85e0-fbe0f29eaae9">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=751&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=751" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=751" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">12:31 - 12:40</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Gamma
 controls how far the influence of a single trending example reaches, 
which in turn affects how tightly the decision boundaries end up 
surrounding points in the input space.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Gamma controls how far the influence of a single trending example reaches, which in turn affects how tightly the decision boundaries end up surrounding points in the input space." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit1e3f98af-de3b-4308-9365-94b20e45dbf9 Edit1e3f98af-de3b-4308-9365-94b20e45dbf9Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit1e3f98af-de3b-4308-9365-94b20e45dbf9">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Gamma controls how far the influence of a single trending example reaches, which in turn affects how tightly the decision boundaries end up surrounding points in the input space." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletee6e5ad83-3ad2-415b-8918-a0be853baf18 Deletee6e5ad83-3ad2-415b-8918-a0be853baf18Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletee6e5ad83-3ad2-415b-8918-a0be853baf18">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video74fa1b71-d629-457b-af5e-1773f3be802f Video74fa1b71-d629-457b-af5e-1773f3be802fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video74fa1b71-d629-457b-af5e-1773f3be802f">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=775&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=775" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=775" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">12:55 - 13:08</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">On
 the other hand for larger values of gamma, the kernel value to K is 
more quickly and points have to be very close to be considered similar. 
This results in more complex, tightly constrained decision boundaries.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: On the other hand for larger values of gamma, the kernel value to K is more quickly and points have to be very close to be considered similar. This results in more complex, tightly constrained decision boundaries." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit93aac00e-8de2-45f3-ff1c-be32cafcb472 Edit93aac00e-8de2-45f3-ff1c-be32cafcb472Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit93aac00e-8de2-45f3-ff1c-be32cafcb472">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: On the other hand for larger values of gamma, the kernel value to K is more quickly and points have to be very close to be considered similar. This results in more complex, tightly constrained decision boundaries." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletebae5e89a-a7c1-4395-abd7-ad54f36f3e3c Deletebae5e89a-a7c1-4395-abd7-ad54f36f3e3cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletebae5e89a-a7c1-4395-abd7-ad54f36f3e3c">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video1d312d84-62c3-4bc7-c13d-5bee3c2917a0 Video1d312d84-62c3-4bc7-c13d-5bee3c2917a0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video1d312d84-62c3-4bc7-c13d-5bee3c2917a0">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=980&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=980" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=980" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">16:20 - 16:30</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">The
 support vector machine's also potentially very versatile, due to its 
ability to specify different kernel functions, including possible custom
 kernel functions depending on the data.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: The support vector machine's also potentially very versatile, due to its ability to specify different kernel functions, including possible custom kernel functions depending on the data." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editfb00d839-5ebf-4d46-ba63-d3b2fad03a47 Editfb00d839-5ebf-4d46-ba63-d3b2fad03a47Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editfb00d839-5ebf-4d46-ba63-d3b2fad03a47">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: The support vector machine's also potentially very versatile, due to its ability to specify different kernel functions, including possible custom kernel functions depending on the data." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletec745367e-48a7-4b04-9dbc-f177dc2a11b1 Deletec745367e-48a7-4b04-9dbc-f177dc2a11b1Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletec745367e-48a7-4b04-9dbc-f177dc2a11b1">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoda63f19e-5a78-44a5-ccd9-d669ac37c4d0 Videoda63f19e-5a78-44a5-ccd9-d669ac37c4d0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoda63f19e-5a78-44a5-ccd9-d669ac37c4d0">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=399&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=399" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=399" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">6:39 - 6:57</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">There
 are lots of different possible transformations we could apply to data. 
And the different kernels available for the kernelized SVM correspond to
 different transformations. Here we're going to focus mainly on what's 
called the radial basis function kernel, which we'll abbreviate as RBF.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: There are lots of different possible transformations we could apply to data. And the different kernels available for the kernelized SVM correspond to different transformations. Here we're going to focus mainly on what's called the radial basis function kernel, which we'll abbreviate as RBF." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit4842384c-a2dc-4972-f328-9aec7066c9a6 Edit4842384c-a2dc-4972-f328-9aec7066c9a6Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit4842384c-a2dc-4972-f328-9aec7066c9a6">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: There are lots of different possible transformations we could apply to data. And the different kernels available for the kernelized SVM correspond to different transformations. Here we're going to focus mainly on what's called the radial basis function kernel, which we'll abbreviate as RBF." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletee5d913a9-e2f0-4215-dab4-28b93df59f28 Deletee5d913a9-e2f0-4215-dab4-28b93df59f28Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletee5d913a9-e2f0-4215-dab4-28b93df59f28">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video14477747-cf86-4665-fff9-d03037a6969d Video14477747-cf86-4665-fff9-d03037a6969dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video14477747-cf86-4665-fff9-d03037a6969d">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=154&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=154" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=154" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">2:34 - 2:42</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">suppose we gave the linear support vector machine a harder problem, where the classes are no longer linearly separable.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: suppose we gave the linear support vector machine a harder problem, where the classes are no longer linearly separable." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit7fb468c7-ee21-4977-9e71-bef78bcc606c Edit7fb468c7-ee21-4977-9e71-bef78bcc606cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit7fb468c7-ee21-4977-9e71-bef78bcc606c">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: suppose we gave the linear support vector machine a harder problem, where the classes are no longer linearly separable." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete3ee1e7d4-1180-458d-d455-86bcbe514a73 Delete3ee1e7d4-1180-458d-d455-86bcbe514a73Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete3ee1e7d4-1180-458d-d455-86bcbe514a73">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videodfd15b9e-866f-4d66-c9c4-b87ef2ceb14d Videodfd15b9e-866f-4d66-c9c4-b87ef2ceb14dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videodfd15b9e-866f-4d66-c9c4-b87ef2ceb14d">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=761&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=761" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=761" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">12:41 - 12:53</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Small
 gamma means a larger similarity radius. So that points farther apart 
are considered similar. Which results in more points being group 
together and smoother decision boundaries.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Small gamma means a larger similarity radius. So that points farther apart are considered similar. Which results in more points being group together and smoother decision boundaries." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit6fcd2a07-b517-408f-84b9-e146ca682161 Edit6fcd2a07-b517-408f-84b9-e146ca682161Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit6fcd2a07-b517-408f-84b9-e146ca682161">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Small gamma means a larger similarity radius. So that points farther apart are considered similar. Which results in more points being group together and smoother decision boundaries." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletef27d9195-4f81-4ea6-f5f9-bd64b995bb33 Deletef27d9195-4f81-4ea6-f5f9-bd64b995bb33Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletef27d9195-4f81-4ea6-f5f9-bd64b995bb33">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video35e9fa35-7eb2-4afa-f7a1-eb16d27388fe Video35e9fa35-7eb2-4afa-f7a1-eb16d27388feDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video35e9fa35-7eb2-4afa-f7a1-eb16d27388fe">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=198&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=198" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=198" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">3:18 - 3:28</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">We're
 not adding in any new information in the sense that all we need to 
obtain this new 2-dimensional version is already present in the original
 1-dimensional data poi</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: We're not adding in any new information in the sense that all we need to obtain this new 2-dimensional version is already present in the original 1-dimensional data poi" tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit67c9b83e-eb6d-4ab7-9979-306a08642949 Edit67c9b83e-eb6d-4ab7-9979-306a08642949Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit67c9b83e-eb6d-4ab7-9979-306a08642949">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: We're not adding in any new information in the sense that all we need to obtain this new 2-dimensional version is already present in the original 1-dimensional data poi" tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete22e41334-e36a-4a16-ccbc-29bc6c1c5faa Delete22e41334-e36a-4a16-ccbc-29bc6c1c5faaDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete22e41334-e36a-4a16-ccbc-29bc6c1c5faa">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video9e3f9c9f-30e1-47eb-de62-8f441388fe5c Video9e3f9c9f-30e1-47eb-de62-8f441388fe5cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video9e3f9c9f-30e1-47eb-de62-8f441388fe5c">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=797&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=797" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=797" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">13:17 - 13:26</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Small
 values of gamma give broader, smoother decision regions. While larger 
values of gamma give smaller, more complex decision regions.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Small values of gamma give broader, smoother decision regions. While larger values of gamma give smaller, more complex decision regions." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editcd4f7c18-f491-488b-8099-bea6cbfac128 Editcd4f7c18-f491-488b-8099-bea6cbfac128Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editcd4f7c18-f491-488b-8099-bea6cbfac128">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Small values of gamma give broader, smoother decision regions. While larger values of gamma give smaller, more complex decision regions." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete1fd92e61-11f1-42fc-eb59-becbbf831960 Delete1fd92e61-11f1-42fc-eb59-becbbf831960Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete1fd92e61-11f1-42fc-eb59-becbbf831960">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoe5598e2c-c498-4c2a-f9da-3afa7afc2bde Videoe5598e2c-c498-4c2a-f9da-3afa7afc2bdeDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videoe5598e2c-c498-4c2a-f9da-3afa7afc2bde">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=643&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=643" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=643" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">10:43 - 10:55</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">You
 can see that unlike a linear classifier, the SVM with RBF kernel finds a
 more complex and very effective set of decision boundaries that are 
very good at separating one class from the other.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: You can see that unlike a linear classifier, the SVM with RBF kernel finds a more complex and very effective set of decision boundaries that are very good at separating one class from the other." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit7d4248be-8dc5-48e3-dc55-4a56da50226c Edit7d4248be-8dc5-48e3-dc55-4a56da50226cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit7d4248be-8dc5-48e3-dc55-4a56da50226c">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: You can see that unlike a linear classifier, the SVM with RBF kernel finds a more complex and very effective set of decision boundaries that are very good at separating one class from the other." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete0f4b1512-fe7a-4578-b097-b3660ea1a773 Delete0f4b1512-fe7a-4578-b097-b3660ea1a773Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete0f4b1512-fe7a-4578-b097-b3660ea1a773">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videob5c67ae8-a97b-4113-a623-dee7c34ae8a2 Videob5c67ae8-a97b-4113-a623-dee7c34ae8a2Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videob5c67ae8-a97b-4113-a623-dee7c34ae8a2">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=181&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=181" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=181" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">3:01 - 3:06</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">We can do this, for example, by mapping each 1-dimensional input data instance xi</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: We can do this, for example, by mapping each 1-dimensional input data instance xi" tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edite6d148a4-336d-4e79-b5e2-0cefa9a608b2 Edite6d148a4-336d-4e79-b5e2-0cefa9a608b2Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edite6d148a4-336d-4e79-b5e2-0cefa9a608b2">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: We can do this, for example, by mapping each 1-dimensional input data instance xi" tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleteeeb6fdc4-e299-4692-b7f6-a2eae80c3a3b Deleteeeb6fdc4-e299-4692-b7f6-a2eae80c3a3bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deleteeeb6fdc4-e299-4692-b7f6-a2eae80c3a3b">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video76e422b6-6467-433e-e9e1-cf0fc15e1fbf Video76e422b6-6467-433e-e9e1-cf0fc15e1fbfDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video76e422b6-6467-433e-e9e1-cf0fc15e1fbf">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=1040&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=1040" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=1040" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">17:20 - 18:02</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Support
 vector machines also don't provide direct probability estimates for 
predictions, which are needed for some applications. Now, there are ways
 to estimate these probabilities using techniques such as plot scaling, 
which transforms the output of the classifier to a probability 
distribution over classes by fitting a logistic regression model to the 
classifiers course. Finally, it could be difficult to interpret the 
internal model parameters of a support vector machine. Which means the 
applicability of support vector machines in scenarios where 
interpretation is important for people may be limited when we want to 
understand why a particular prediction was made.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Support vector machines also don't provide direct probability estimates for predictions, which are needed for some applications. Now, there are ways to estimate these probabilities using techniques such as plot scaling, which transforms the output of the classifier to a probability distribution over classes by fitting a logistic regression model to the classifiers course. Finally, it could be difficult to interpret the internal model parameters of a support vector machine. Which means the applicability of support vector machines in scenarios where interpretation is important for people may be limited when we want to understand why a particular prediction was made." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editec33a952-1c2f-456f-e216-693fc54be4a0 Editec33a952-1c2f-456f-e216-693fc54be4a0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editec33a952-1c2f-456f-e216-693fc54be4a0">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Support vector machines also don't provide direct probability estimates for predictions, which are needed for some applications. Now, there are ways to estimate these probabilities using techniques such as plot scaling, which transforms the output of the classifier to a probability distribution over classes by fitting a logistic regression model to the classifiers course. Finally, it could be difficult to interpret the internal model parameters of a support vector machine. Which means the applicability of support vector machines in scenarios where interpretation is important for people may be limited when we want to understand why a particular prediction was made." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete77d952c7-6a75-4b8c-c3a2-b7258ab7b79c Delete77d952c7-6a75-4b8c-c3a2-b7258ab7b79cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete77d952c7-6a75-4b8c-c3a2-b7258ab7b79c">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video6529cd6a-c0d3-4659-987c-1f8b20af5174 Video6529cd6a-c0d3-4659-987c-1f8b20af5174Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video6529cd6a-c0d3-4659-987c-1f8b20af5174">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=1084&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=1084" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=1084" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">18:04 - 18:09</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">As a reminder, there are three main parameters that control model complexity for kernelized SVMs.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: As a reminder, there are three main parameters that control model complexity for kernelized SVMs." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editf64157ae-a240-4ef7-8233-7248b5fbb90e Editf64157ae-a240-4ef7-8233-7248b5fbb90eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editf64157ae-a240-4ef7-8233-7248b5fbb90e">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: As a reminder, there are three main parameters that control model complexity for kernelized SVMs." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete0d49f8e3-70b1-41f6-e2da-244fcce88c86 Delete0d49f8e3-70b1-41f6-e2da-244fcce88c86Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete0d49f8e3-70b1-41f6-e2da-244fcce88c86">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video9bbeaef4-f3ba-4488-a6d8-4eb2a6f20139 Video9bbeaef4-f3ba-4488-a6d8-4eb2a6f20139Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video9bbeaef4-f3ba-4488-a6d8-4eb2a6f20139">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=746&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=746" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=746" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">12:26 - 12:29</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">the RBF kernel has a parameter gamma.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: the RBF kernel has a parameter gamma." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit9c134135-b898-4667-e30f-25eeaf4d67b2 Edit9c134135-b898-4667-e30f-25eeaf4d67b2Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit9c134135-b898-4667-e30f-25eeaf4d67b2">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: the RBF kernel has a parameter gamma." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete026e48a9-7c2e-4c8f-b410-23aa239d06d5 Delete026e48a9-7c2e-4c8f-b410-23aa239d06d5Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete026e48a9-7c2e-4c8f-b410-23aa239d06d5">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videod402c6aa-e3cc-47bb-869d-14992656f3fd Videod402c6aa-e3cc-47bb-869d-14992656f3fdDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videod402c6aa-e3cc-47bb-869d-14992656f3fd">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=848&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=848" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=848" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">14:08 - 14:19</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">If
 gamma is large, then C will have little to no effect. Well, if gamma is
 small, the model is much more constrained and the effective C will be 
similar to how it would affect a linear classifier.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: If gamma is large, then C will have little to no effect. Well, if gamma is small, the model is much more constrained and the effective C will be similar to how it would affect a linear classifier." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit1ed41707-b974-4859-b3e9-35e7629178d6 Edit1ed41707-b974-4859-b3e9-35e7629178d6Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit1ed41707-b974-4859-b3e9-35e7629178d6">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: If gamma is large, then C will have little to no effect. Well, if gamma is small, the model is much more constrained and the effective C will be similar to how it would affect a linear classifier." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletef11b099e-8234-45dd-a832-687b7b8fb6b0 Deletef11b099e-8234-45dd-a832-687b7b8fb6b0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletef11b099e-8234-45dd-a832-687b7b8fb6b0">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoc06582da-380a-45e5-dc8a-f7ef7dddbebf Videoc06582da-380a-45e5-dc8a-f7ef7dddbebfDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videoc06582da-380a-45e5-dc8a-f7ef7dddbebf">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=99&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=99" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=99" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">1:39 - 1:55</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">one
 way to think about what kernelized SVMs do, is they take the original 
input data space and transform it to a new higher dimensional feature 
space, where it becomes much easier to classify the transform to data 
using a linear classifier.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: one way to think about what kernelized SVMs do, is they take the original input data space and transform it to a new higher dimensional feature space, where it becomes much easier to classify the transform to data using a linear classifier." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit39d011f3-da34-4edc-a8e1-4f7f7e1e9160 Edit39d011f3-da34-4edc-a8e1-4f7f7e1e9160Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit39d011f3-da34-4edc-a8e1-4f7f7e1e9160">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: one way to think about what kernelized SVMs do, is they take the original input data space and transform it to a new higher dimensional feature space, where it becomes much easier to classify the transform to data using a linear classifier." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleteddfa8045-6eb4-456b-a9fe-173198bd3e06 Deleteddfa8045-6eb4-456b-a9fe-173198bd3e06Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deleteddfa8045-6eb4-456b-a9fe-173198bd3e06">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video1eb6e1c0-0341-456f-fe16-c1012341c9d7 Video1eb6e1c0-0341-456f-fe16-c1012341c9d7Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video1eb6e1c0-0341-456f-fe16-c1012341c9d7">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=389&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=389" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=389" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">6:29 - 6:38</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">This
 idea of transforming the input data points to a new feature space where
 a linear classifier can be easily applied, is a very general and 
powerful one.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: This idea of transforming the input data points to a new feature space where a linear classifier can be easily applied, is a very general and powerful one." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editbbbab421-e827-413b-a5f4-5a193e734345 Editbbbab421-e827-413b-a5f4-5a193e734345Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editbbbab421-e827-413b-a5f4-5a193e734345">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: This idea of transforming the input data points to a new feature space where a linear classifier can be easily applied, is a very general and powerful one." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete396b1fe3-0c9f-4172-8270-c70bb55cdc03 Delete396b1fe3-0c9f-4172-8270-c70bb55cdc03Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete396b1fe3-0c9f-4172-8270-c70bb55cdc03">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video62ea2158-dd60-46ac-fe00-c7cf0b8bff4e Video62ea2158-dd60-46ac-fe00-c7cf0b8bff4eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video62ea2158-dd60-46ac-fe00-c7cf0b8bff4e">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=574&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=574" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=574" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">9:34 - 9:48</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Instead,
 the kernelized SVM can compute these more complex decision boundaries 
just in terms of similarity calculations between pairs of points in the 
high dimensional space where the transformed feature representation is 
implicit.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Instead, the kernelized SVM can compute these more complex decision boundaries just in terms of similarity calculations between pairs of points in the high dimensional space where the transformed feature representation is implicit." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit7eb06b0c-9fe5-4cb4-c4f3-020e48b3c4ab Edit7eb06b0c-9fe5-4cb4-c4f3-020e48b3c4abDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit7eb06b0c-9fe5-4cb4-c4f3-020e48b3c4ab">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Instead, the kernelized SVM can compute these more complex decision boundaries just in terms of similarity calculations between pairs of points in the high dimensional space where the transformed feature representation is implicit." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete6b2994f0-716c-4a9d-e6a8-55e84d8e8034 Delete6b2994f0-716c-4a9d-e6a8-55e84d8e8034Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete6b2994f0-716c-4a9d-e6a8-55e84d8e8034">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video71d47b54-097d-459b-dae8-a55abc008afc Video71d47b54-097d-459b-dae8-a55abc008afcDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video71d47b54-097d-459b-dae8-a55abc008afc">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=1091&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=1091" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=1091" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">18:11 - 18:21</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">First,
 there's the kernel type which defaults to RBF for radial basis 
function. But several other common types are available in scikit-learns 
SVC module.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: First, there's the kernel type which defaults to RBF for radial basis function. But several other common types are available in scikit-learns SVC module." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit900d2cd1-70b9-44c2-a909-6e2591ba4d06 Edit900d2cd1-70b9-44c2-a909-6e2591ba4d06Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit900d2cd1-70b9-44c2-a909-6e2591ba4d06">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: First, there's the kernel type which defaults to RBF for radial basis function. But several other common types are available in scikit-learns SVC module." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleteb2fc8d6e-485e-44ff-fd8a-246350841dc9 Deleteb2fc8d6e-485e-44ff-fd8a-246350841dc9Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deleteb2fc8d6e-485e-44ff-fd8a-246350841dc9">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videodfc9530b-fda0-48d7-dfdf-1191841c78f1 Videodfc9530b-fda0-48d7-dfdf-1191841c78f1Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videodfc9530b-fda0-48d7-dfdf-1191841c78f1">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=969&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=969" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=969" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">16:09 - 16:19</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">On
 the positive side, support vector machines perform well on a range of 
datasets, and have been successfully applied on data that ranges from 
text to images and many more types.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: On the positive side, support vector machines perform well on a range of datasets, and have been successfully applied on data that ranges from text to images and many more types." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editf056a0f0-f476-4c09-f415-5ca4f0b0a234 Editf056a0f0-f476-4c09-f415-5ca4f0b0a234Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editf056a0f0-f476-4c09-f415-5ca4f0b0a234">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: On the positive side, support vector machines perform well on a range of datasets, and have been successfully applied on data that ranges from text to images and many more types." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete2cc5d9ea-a94e-42f0-e996-c8ddb32b0668 Delete2cc5d9ea-a94e-42f0-e996-c8ddb32b0668Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete2cc5d9ea-a94e-42f0-e996-c8ddb32b0668">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoc4f129f5-260d-43cc-841b-d806f21f9f25 Videoc4f129f5-260d-43cc-841b-d806f21f9f25Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoc4f129f5-260d-43cc-841b-d806f21f9f25">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=19&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=19" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=19" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">0:19 - 0:30</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Linear
 support vector machines worked well for simpler kinds of classification
 problems, where the classes were linearly separable or close to 
linearly separable like this example on the left.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Linear support vector machines worked well for simpler kinds of classification problems, where the classes were linearly separable or close to linearly separable like this example on the left." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit9a75a2fc-a243-4a58-a466-3f33f32c33c4 Edit9a75a2fc-a243-4a58-a466-3f33f32c33c4Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit9a75a2fc-a243-4a58-a466-3f33f32c33c4">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Linear support vector machines worked well for simpler kinds of classification problems, where the classes were linearly separable or close to linearly separable like this example on the left." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete51405b3f-3c68-4c07-9691-666e19cc855a Delete51405b3f-3c68-4c07-9691-666e19cc855aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete51405b3f-3c68-4c07-9691-666e19cc855a">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video8e42d988-e007-4094-e7d5-de140992c68f Video8e42d988-e007-4094-e7d5-de140992c68fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video8e42d988-e007-4094-e7d5-de140992c68f">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=609&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=609" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=609" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">10:09 - 10:17</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">This
 makes it practical to apply support vector machines, when the 
underlying transformed feature space is complex or even infinite 
dimensional.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: This makes it practical to apply support vector machines, when the underlying transformed feature space is complex or even infinite dimensional." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit44ad78fe-bd78-46b8-a5b2-5eccd3435e73 Edit44ad78fe-bd78-46b8-a5b2-5eccd3435e73Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit44ad78fe-bd78-46b8-a5b2-5eccd3435e73">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: This makes it practical to apply support vector machines, when the underlying transformed feature space is complex or even infinite dimensional." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete56e66873-34ff-4713-8931-a7e4c63c04f1 Delete56e66873-34ff-4713-8931-a7e4c63c04f1Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete56e66873-34ff-4713-8931-a7e4c63c04f1">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videofe6c6deb-dd44-4745-db84-30c98a778546 Videofe6c6deb-dd44-4745-db84-30c98a778546Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videofe6c6deb-dd44-4745-db84-30c98a778546">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=1033&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=1033" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=1033" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">17:13 - 17:18</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">The input should be normalized that all features have comparable units and around similar scales if they aren't already.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: The input should be normalized that all features have comparable units and around similar scales if they aren't already." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit9c1fca10-c0c1-446a-8a47-c55bc781fc05 Edit9c1fca10-c0c1-446a-8a47-c55bc781fc05Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit9c1fca10-c0c1-446a-8a47-c55bc781fc05">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: The input should be normalized that all features have comparable units and around similar scales if they aren't already." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete0b4a57b3-59b2-409d-8277-b437446df1be Delete0b4a57b3-59b2-409d-8277-b437446df1beDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete0b4a57b3-59b2-409d-8277-b437446df1be">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videofa50156a-9a77-4d90-9b4a-d0e1e828e02c Videofa50156a-9a77-4d90-9b4a-d0e1e828e02cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videofa50156a-9a77-4d90-9b4a-d0e1e828e02c">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=163&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=163" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=163" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">2:43 - 2:48</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">A simple linear decision boundary just doesn't have enough expressive power to classify all these points correctly.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: A simple linear decision boundary just doesn't have enough expressive power to classify all these points correctly." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editeeab5ed0-9caa-492f-b7c5-7a95c6591190 Editeeab5ed0-9caa-492f-b7c5-7a95c6591190Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editeeab5ed0-9caa-492f-b7c5-7a95c6591190">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: A simple linear decision boundary just doesn't have enough expressive power to classify all these points correctly." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete72b5c8fe-03c1-44a9-c538-10b9a27dd71a Delete72b5c8fe-03c1-44a9-c538-10b9a27dd71aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete72b5c8fe-03c1-44a9-c538-10b9a27dd71a">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videob8ed1fad-8cf5-4de6-b54b-4693a919d71a Videob8ed1fad-8cf5-4de6-b54b-4693a919d71aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videob8ed1fad-8cf5-4de6-b54b-4693a919d71a">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=702&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=702" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=702" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">11:42 - 11:48</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">By default, the SVM will use the radial base's function, but a number of other choices are supported.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: By default, the SVM will use the radial base's function, but a number of other choices are supported." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editd3cd8701-dff0-4bf9-b333-edbf1ef7090e Editd3cd8701-dff0-4bf9-b333-edbf1ef7090eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editd3cd8701-dff0-4bf9-b333-edbf1ef7090e">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: By default, the SVM will use the radial base's function, but a number of other choices are supported." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletea7206945-d3e6-4eb9-bc73-efb6b91b7b69 Deletea7206945-d3e6-4eb9-bc73-efb6b91b7b69Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletea7206945-d3e6-4eb9-bc73-efb6b91b7b69">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videod4c4bdc1-d041-4df7-d033-86b52c706feb Videod4c4bdc1-d041-4df7-d033-86b52c706febDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videod4c4bdc1-d041-4df7-d033-86b52c706feb">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=76&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=76" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=76" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">1:16 - 1:22</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">SVMs can be used for both classification and regression.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: SVMs can be used for both classification and regression." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit80706b85-de15-4e00-f157-ddacc537672d Edit80706b85-de15-4e00-f157-ddacc537672dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit80706b85-de15-4e00-f157-ddacc537672d">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: SVMs can be used for both classification and regression." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletefce00b9b-8b97-4898-c790-9a0807222e96 Deletefce00b9b-8b97-4898-c790-9a0807222e96Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletefce00b9b-8b97-4898-c790-9a0807222e96">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video30626364-f999-4595-9f43-6afcb4680966 Video30626364-f999-4595-9f43-6afcb4680966Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video30626364-f999-4595-9f43-6afcb4680966">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=45&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=45" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=45" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">0:45 - 0:52</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">These dataset is difficult, or impossible for a linear model, a line or hyperplane, to classify well.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: These dataset is difficult, or impossible for a linear model, a line or hyperplane, to classify well." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edite6ba6ba2-addc-4a79-b7ee-b1860fbc33db Edite6ba6ba2-addc-4a79-b7ee-b1860fbc33dbDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edite6ba6ba2-addc-4a79-b7ee-b1860fbc33db">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: These dataset is difficult, or impossible for a linear model, a line or hyperplane, to classify well." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete12256d5b-9648-442f-af24-38aabfc5f21f Delete12256d5b-9648-442f-af24-38aabfc5f21fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete12256d5b-9648-442f-af24-38aabfc5f21f">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video27fe7612-8d0d-4116-e9a7-5c761e5c756b Video27fe7612-8d0d-4116-e9a7-5c761e5c756bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video27fe7612-8d0d-4116-e9a7-5c761e5c756b">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=881&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=881" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=881" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">14:41 - 14:57</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Kernelized
 SVMs are pretty sensitive to settings of gamma. The most important 
thing to remember when applying SVMs is that it's important to normalize
 the input data, so that all the features have comparable units that are
 on the same scale.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Kernelized SVMs are pretty sensitive to settings of gamma. The most important thing to remember when applying SVMs is that it's important to normalize the input data, so that all the features have comparable units that are on the same scale." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit3c5d74bc-1617-418c-a857-99f9c0da6978 Edit3c5d74bc-1617-418c-a857-99f9c0da6978Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit3c5d74bc-1617-418c-a857-99f9c0da6978">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Kernelized SVMs are pretty sensitive to settings of gamma. The most important thing to remember when applying SVMs is that it's important to normalize the input data, so that all the features have comparable units that are on the same scale." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleted02f8f5c-f54c-4304-aa0a-c78bd375c72e Deleted02f8f5c-f54c-4304-aa0a-c78bd375c72eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deleted02f8f5c-f54c-4304-aa0a-c78bd375c72e">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video9cc78ba0-54c4-4446-aa1c-f057ef339ca1 Video9cc78ba0-54c4-4446-aa1c-f057ef339ca1Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video9cc78ba0-54c4-4446-aa1c-f057ef339ca1">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=590&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=590" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=590" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">9:50 - 9:56</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">This similarity function which mathematically is a kind of dot product is the kernel in kernelized SVM.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: This similarity function which mathematically is a kind of dot product is the kernel in kernelized SVM." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit07c7e537-a059-4884-fb3b-44e963eced47 Edit07c7e537-a059-4884-fb3b-44e963eced47Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit07c7e537-a059-4884-fb3b-44e963eced47">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: This similarity function which mathematically is a kind of dot product is the kernel in kernelized SVM." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleteb9f3492c-8c57-41be-ccc5-aeae1e5b06f5 Deleteb9f3492c-8c57-41be-ccc5-aeae1e5b06f5Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deleteb9f3492c-8c57-41be-ccc5-aeae1e5b06f5">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video9b24dc29-7a74-474b-90df-de14437b8e23 Video9b24dc29-7a74-474b-90df-de14437b8e23Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video9b24dc29-7a74-474b-90df-de14437b8e23">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/lCUeA?t=437&quot;,&quot;itemId&quot;:&quot;lCUeA&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/lCUeA?t=437" href="https://www.coursera.org/learn/python-machine-learning/lecture/lCUeA?t=437" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Kernelized Support Vector Machines</div></a><div class="video-details" aria-label="Duration">7:17 - 7:30</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">For
 the radial basis function kernel, the similarity between two points and
 the transformed feature space is an exponentially decaying function of 
the distance between the vectors and the original input space as shown 
by the formula here.</div><div class="video-note-text-box video-note-text" aria-label="User Note">xxxx</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: For the radial basis function kernel, the similarity between two points and the transformed feature space is an exponentially decaying function of the distance between the vectors and the original input space as shown by the formula here." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit8ef62d19-8f4f-4b2a-99a1-54f80c2652f2 Edit8ef62d19-8f4f-4b2a-99a1-54f80c2652f2Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit8ef62d19-8f4f-4b2a-99a1-54f80c2652f2">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: For the radial basis function kernel, the similarity between two points and the transformed feature space is an exponentially decaying function of the distance between the vectors and the original input space as shown by the formula here." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete7b3cf395-7204-4f19-99db-43325d5e0bc6 Delete7b3cf395-7204-4f19-99db-43325d5e0bc6Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete7b3cf395-7204-4f19-99db-43325d5e0bc6">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video62e4dcb9-2217-4629-e675-5a0bfb4dba78 Video62e4dcb9-2217-4629-e675-5a0bfb4dba78Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video62e4dcb9-2217-4629-e675-5a0bfb4dba78">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Vm0Ie?t=63&quot;,&quot;itemId&quot;:&quot;Vm0Ie&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Vm0Ie?t=63" href="https://www.coursera.org/learn/python-machine-learning/lecture/Vm0Ie?t=63" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Cross-Validation</div></a><div class="video-details" aria-label="Duration">1:03 - 1:18</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Cross-validation
 is a method that goes beyond evaluating a single model using a single 
Train/Test split of the data by using multiple Train/Test splits, each 
of which is used to train and evaluate a separate model.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Cross-validation is a method that goes beyond evaluating a single model using a single Train/Test split of the data by using multiple Train/Test splits, each of which is used to train and evaluate a separate model." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit0a052fd9-7fdf-462a-ae54-f1d4162cab39 Edit0a052fd9-7fdf-462a-ae54-f1d4162cab39Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit0a052fd9-7fdf-462a-ae54-f1d4162cab39">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Cross-validation is a method that goes beyond evaluating a single model using a single Train/Test split of the data by using multiple Train/Test splits, each of which is used to train and evaluate a separate model." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete3285adb1-c084-450f-8fb3-3f40dfdb165f Delete3285adb1-c084-450f-8fb3-3f40dfdb165fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete3285adb1-c084-450f-8fb3-3f40dfdb165f">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video5c68a889-5701-4447-a2af-3d91c25a4581 Video5c68a889-5701-4447-a2af-3d91c25a4581Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video5c68a889-5701-4447-a2af-3d91c25a4581">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Vm0Ie?t=364&quot;,&quot;itemId&quot;:&quot;Vm0Ie&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Vm0Ie?t=364" href="https://www.coursera.org/learn/python-machine-learning/lecture/Vm0Ie?t=364" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Cross-Validation</div></a><div class="video-details" aria-label="Duration">6:04 - 6:18</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">For
 regression, scikit-learn uses regular k-fold cross-validation since the
 concept of preserving class proportions isn't something that's really 
relevant for everyday regression problems.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: For regression, scikit-learn uses regular k-fold cross-validation since the concept of preserving class proportions isn't something that's really relevant for everyday regression problems." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editc156d5b7-907c-48ef-dee5-e1c53a6b7824 Editc156d5b7-907c-48ef-dee5-e1c53a6b7824Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editc156d5b7-907c-48ef-dee5-e1c53a6b7824">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: For regression, scikit-learn uses regular k-fold cross-validation since the concept of preserving class proportions isn't something that's really relevant for everyday regression problems." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete0dfa3f01-79f2-4d56-ee1e-039a99e47b06 Delete0dfa3f01-79f2-4d56-ee1e-039a99e47b06Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete0dfa3f01-79f2-4d56-ee1e-039a99e47b06">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video34808761-6452-4d1f-fa71-592a5cab2f99 Video34808761-6452-4d1f-fa71-592a5cab2f99Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video34808761-6452-4d1f-fa71-592a5cab2f99">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Vm0Ie?t=340&quot;,&quot;itemId&quot;:&quot;Vm0Ie&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Vm0Ie?t=340" href="https://www.coursera.org/learn/python-machine-learning/lecture/Vm0Ie?t=340" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Cross-Validation</div></a><div class="video-details" aria-label="Duration">5:40 - 6:04</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">So
 when you ask scikit-learn to do cross-validation for a classification 
task, it actually does instead what's called "Stratified K-fold 
Cross-validation". The Stratified Cross-validation means that when 
splitting the data, the proportions of classes in each fold are made as 
close as possible to the actual proportions of the classes in the 
overall data set</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: So when you ask scikit-learn to do cross-validation for a classification task, it actually does instead what's called &quot;Stratified K-fold Cross-validation&quot;. The Stratified Cross-validation means that when splitting the data, the proportions of classes in each fold are made as close as possible to the actual proportions of the classes in the overall data set" tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit10343bab-7d98-461c-9b41-e240e1014f5e Edit10343bab-7d98-461c-9b41-e240e1014f5eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit10343bab-7d98-461c-9b41-e240e1014f5e">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: So when you ask scikit-learn to do cross-validation for a classification task, it actually does instead what's called &quot;Stratified K-fold Cross-validation&quot;. The Stratified Cross-validation means that when splitting the data, the proportions of classes in each fold are made as close as possible to the actual proportions of the classes in the overall data set" tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletedebb83fd-16aa-46a5-b637-b0858a2e180e Deletedebb83fd-16aa-46a5-b637-b0858a2e180eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletedebb83fd-16aa-46a5-b637-b0858a2e180e">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video0331c4be-7206-47cf-a743-c41d25fd45b8 Video0331c4be-7206-47cf-a743-c41d25fd45b8Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video0331c4be-7206-47cf-a743-c41d25fd45b8">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Vm0Ie?t=124&quot;,&quot;itemId&quot;:&quot;Vm0Ie&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Vm0Ie?t=124" href="https://www.coursera.org/learn/python-machine-learning/lecture/Vm0Ie?t=124" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Cross-Validation</div></a><div class="video-details" aria-label="Duration">2:04 - 2:12</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">The most common type of cross-validation is k-fold cross-validation most commonly with K set to 5 or 10.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: The most common type of cross-validation is k-fold cross-validation most commonly with K set to 5 or 10." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editaeca2cc9-eead-497f-9f64-b052136def24 Editaeca2cc9-eead-497f-9f64-b052136def24Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editaeca2cc9-eead-497f-9f64-b052136def24">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: The most common type of cross-validation is k-fold cross-validation most commonly with K set to 5 or 10." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete9ecc7f88-f3cf-44d2-f29e-983018a10605 Delete9ecc7f88-f3cf-44d2-f29e-983018a10605Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete9ecc7f88-f3cf-44d2-f29e-983018a10605">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video0a15722a-be10-41a4-f747-bf8e7d4581fd Video0a15722a-be10-41a4-f747-bf8e7d4581fdDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video0a15722a-be10-41a4-f747-bf8e7d4581fd">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Vm0Ie?t=194&quot;,&quot;itemId&quot;:&quot;Vm0Ie&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Vm0Ie?t=194" href="https://www.coursera.org/learn/python-machine-learning/lecture/Vm0Ie?t=194" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Cross-Validation</div></a><div class="video-details" aria-label="Duration">3:14 - 3:20</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">By default, cross_val_score does threefold cross-validation.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: By default, cross_val_score does threefold cross-validation." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit28faa1fb-43c9-44c2-9046-5a41e27e5afb Edit28faa1fb-43c9-44c2-9046-5a41e27e5afbDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit28faa1fb-43c9-44c2-9046-5a41e27e5afb">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: By default, cross_val_score does threefold cross-validation." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletedd776637-e90e-4827-c3b6-e4e2924e9791 Deletedd776637-e90e-4827-c3b6-e4e2924e9791Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletedd776637-e90e-4827-c3b6-e4e2924e9791">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videofb87764a-ea0f-46b0-e445-db482446747f Videofb87764a-ea0f-46b0-e445-db482446747fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videofb87764a-ea0f-46b0-e445-db482446747f">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Vm0Ie?t=226&quot;,&quot;itemId&quot;:&quot;Vm0Ie&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Vm0Ie?t=226" href="https://www.coursera.org/learn/python-machine-learning/lecture/Vm0Ie?t=226" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Cross-Validation</div></a><div class="video-details" aria-label="Duration">3:46 - 4:17</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">One
 benefit of computing the accuracy of a model on multiple splits instead
 of a single split, is that it gives us potentially useful information 
about how sensitive the model is to the nature of the specific training 
set. We can look at the distribution of these multiple scores across all
 the cross-validation folds to see how likely it is that by chance, the 
model will perform very badly or very well on any new data set, so we 
can do a sort of worst case or best case performance estimate from these
 multiple scores.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: One benefit of computing the accuracy of a model on multiple splits instead of a single split, is that it gives us potentially useful information about how sensitive the model is to the nature of the specific training set. We can look at the distribution of these multiple scores across all the cross-validation folds to see how likely it is that by chance, the model will perform very badly or very well on any new data set, so we can do a sort of worst case or best case performance estimate from these multiple scores." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit0fb04b57-4ad9-4c18-fef6-ba1b3e580d8f Edit0fb04b57-4ad9-4c18-fef6-ba1b3e580d8fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit0fb04b57-4ad9-4c18-fef6-ba1b3e580d8f">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: One benefit of computing the accuracy of a model on multiple splits instead of a single split, is that it gives us potentially useful information about how sensitive the model is to the nature of the specific training set. We can look at the distribution of these multiple scores across all the cross-validation folds to see how likely it is that by chance, the model will perform very badly or very well on any new data set, so we can do a sort of worst case or best case performance estimate from these multiple scores." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete3ff14b7e-2da0-461c-ecbb-15953316eb1d Delete3ff14b7e-2da0-461c-ecbb-15953316eb1dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete3ff14b7e-2da0-461c-ecbb-15953316eb1d">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoabadbea1-d06e-48bf-d24f-7a0a23b64e15 Videoabadbea1-d06e-48bf-d24f-7a0a23b64e15Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoabadbea1-d06e-48bf-d24f-7a0a23b64e15">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Vm0Ie?t=175&quot;,&quot;itemId&quot;:&quot;Vm0Ie&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Vm0Ie?t=175" href="https://www.coursera.org/learn/python-machine-learning/lecture/Vm0Ie?t=175" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Cross-Validation</div></a><div class="video-details" aria-label="Duration">2:55 - 3:14</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">In
 scikit-learn, you can use the cross_val_score function from the model 
selection module to do cross-validation. The parameters are: first, the 
model you want to evaluate, and then the data set, and then the 
corresponding ground truth target labels or values.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: In scikit-learn, you can use the cross_val_score function from the model selection module to do cross-validation. The parameters are: first, the model you want to evaluate, and then the data set, and then the corresponding ground truth target labels or values." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edite8fee32d-65ac-4528-d0d5-eb9c1c00f61d Edite8fee32d-65ac-4528-d0d5-eb9c1c00f61dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edite8fee32d-65ac-4528-d0d5-eb9c1c00f61d">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: In scikit-learn, you can use the cross_val_score function from the model selection module to do cross-validation. The parameters are: first, the model you want to evaluate, and then the data set, and then the corresponding ground truth target labels or values." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete87ee757e-25a4-4bfa-ef56-dd8732b830c9 Delete87ee757e-25a4-4bfa-ef56-dd8732b830c9Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete87ee757e-25a4-4bfa-ef56-dd8732b830c9">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video0cbc7992-bfe2-43de-b38b-52ebbe6aa5df Video0cbc7992-bfe2-43de-b38b-52ebbe6aa5dfDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video0cbc7992-bfe2-43de-b38b-52ebbe6aa5df">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Vm0Ie?t=415&quot;,&quot;itemId&quot;:&quot;Vm0Ie&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Vm0Ie?t=415" href="https://www.coursera.org/learn/python-machine-learning/lecture/Vm0Ie?t=415" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Cross-Validation</div></a><div class="video-details" aria-label="Duration">6:55 - 7:09</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Sometimes we want to evaluate the effect that an important parameter of a model has on the cross-validation scores. </div><div class="video-note-text-box video-note-text" aria-label="User Note">xxxx</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Sometimes we want to evaluate the effect that an important parameter of a model has on the cross-validation scores. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit40ef6f78-bea5-4501-81e1-b57f27efd8c4 Edit40ef6f78-bea5-4501-81e1-b57f27efd8c4Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit40ef6f78-bea5-4501-81e1-b57f27efd8c4">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Sometimes we want to evaluate the effect that an important parameter of a model has on the cross-validation scores. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletebe729061-35b7-46e6-8c29-32c35d80c0c9 Deletebe729061-35b7-46e6-8c29-32c35d80c0c9Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletebe729061-35b7-46e6-8c29-32c35d80c0c9">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video06ad131e-b880-41f2-e879-af0aea1e2085 Video06ad131e-b880-41f2-e879-af0aea1e2085Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video06ad131e-b880-41f2-e879-af0aea1e2085">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Vm0Ie?t=170&quot;,&quot;itemId&quot;:&quot;Vm0Ie&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Vm0Ie?t=170" href="https://www.coursera.org/learn/python-machine-learning/lecture/Vm0Ie?t=170" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Cross-Validation</div></a><div class="video-details" aria-label="Duration">2:50 - 2:55</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">When this process is done, we have five accuracy values, one per fold.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: When this process is done, we have five accuracy values, one per fold." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editfb12422c-d7af-4723-f779-b20c43e64260 Editfb12422c-d7af-4723-f779-b20c43e64260Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editfb12422c-d7af-4723-f779-b20c43e64260">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: When this process is done, we have five accuracy values, one per fold." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete30f8d2f9-20c2-4494-9e72-e6cc47d1a800 Delete30f8d2f9-20c2-4494-9e72-e6cc47d1a800Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete30f8d2f9-20c2-4494-9e72-e6cc47d1a800">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoc78800ec-10f4-4ec7-aad2-c0e331e1414e Videoc78800ec-10f4-4ec7-aad2-c0e331e1414eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videoc78800ec-10f4-4ec7-aad2-c0e331e1414e">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Vm0Ie?t=422&quot;,&quot;itemId&quot;:&quot;Vm0Ie&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Vm0Ie?t=422" href="https://www.coursera.org/learn/python-machine-learning/lecture/Vm0Ie?t=422" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Cross-Validation</div></a><div class="video-details" aria-label="Duration">7:02 - 7:30</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">The
 useful function validation curve makes it easy to run this type of 
experiment. Like cross-value score, validation curve will do threefold 
cross-validation by default but you can adjust this with the CV 
parameter as well. Unlike cross_val_score, you can also specify a 
classifier, parameter name, and set of parameter values, you want to 
sweep across. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: The useful function validation curve makes it easy to run this type of experiment. Like cross-value score, validation curve will do threefold cross-validation by default but you can adjust this with the CV parameter as well. Unlike cross_val_score, you can also specify a classifier, parameter name, and set of parameter values, you want to sweep across. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit9d48fdd6-981a-4b84-fa98-524f7aac602f Edit9d48fdd6-981a-4b84-fa98-524f7aac602fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit9d48fdd6-981a-4b84-fa98-524f7aac602f">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: The useful function validation curve makes it easy to run this type of experiment. Like cross-value score, validation curve will do threefold cross-validation by default but you can adjust this with the CV parameter as well. Unlike cross_val_score, you can also specify a classifier, parameter name, and set of parameter values, you want to sweep across. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete879bdae3-7138-4b00-f611-aeebddafd3ed Delete879bdae3-7138-4b00-f611-aeebddafd3edDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete879bdae3-7138-4b00-f611-aeebddafd3ed">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video4ec71ec3-c2f6-4c64-fe0a-2fd39ebd9218 Video4ec71ec3-c2f6-4c64-fe0a-2fd39ebd9218Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video4ec71ec3-c2f6-4c64-fe0a-2fd39ebd9218">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Vm0Ie?t=264&quot;,&quot;itemId&quot;:&quot;Vm0Ie&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Vm0Ie?t=264" href="https://www.coursera.org/learn/python-machine-learning/lecture/Vm0Ie?t=264" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Cross-Validation</div></a><div class="video-details" aria-label="Duration">4:24 - 4:38</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">So
 for example, if we perform k-fold cross-validation and we don't compute
 the fold results in parallel, it'll take about k times as long to get 
the accuracy scores as it would with just one Train/Test split.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: So for example, if we perform k-fold cross-validation and we don't compute the fold results in parallel, it'll take about k times as long to get the accuracy scores as it would with just one Train/Test split." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit75324339-b7b2-44f1-c0b9-8aabb8f09058 Edit75324339-b7b2-44f1-c0b9-8aabb8f09058Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit75324339-b7b2-44f1-c0b9-8aabb8f09058">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: So for example, if we perform k-fold cross-validation and we don't compute the fold results in parallel, it'll take about k times as long to get the accuracy scores as it would with just one Train/Test split." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete5abee02d-7c9b-4022-c0bd-6ab2207ba07e Delete5abee02d-7c9b-4022-c0bd-6ab2207ba07eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete5abee02d-7c9b-4022-c0bd-6ab2207ba07e">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video6163a6e4-1024-4e00-b03b-6ef3a62c191e Video6163a6e4-1024-4e00-b03b-6ef3a62c191eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video6163a6e4-1024-4e00-b03b-6ef3a62c191e">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Vm0Ie?t=104&quot;,&quot;itemId&quot;:&quot;Vm0Ie&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Vm0Ie?t=104" href="https://www.coursera.org/learn/python-machine-learning/lecture/Vm0Ie?t=104" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Cross-Validation</div></a><div class="video-details" aria-label="Duration">1:44 - 1:59</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Cross-validation
 basically gives more stable and reliable estimates of how the 
classifiers likely to perform on average by running multiple different 
training test splits and then averaging the results, instead of relying 
entirely on a single particular training set.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Cross-validation basically gives more stable and reliable estimates of how the classifiers likely to perform on average by running multiple different training test splits and then averaging the results, instead of relying entirely on a single particular training set." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit737eb2f6-8932-41f6-d37d-1a737a0b1933 Edit737eb2f6-8932-41f6-d37d-1a737a0b1933Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit737eb2f6-8932-41f6-d37d-1a737a0b1933">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Cross-validation basically gives more stable and reliable estimates of how the classifiers likely to perform on average by running multiple different training test splits and then averaging the results, instead of relying entirely on a single particular training set." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete545916b4-1787-448c-90cc-42e788422b3e Delete545916b4-1787-448c-90cc-42e788422b3eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete545916b4-1787-448c-90cc-42e788422b3e">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video56099954-e47b-4846-cf49-1ed68270b492 Video56099954-e47b-4846-cf49-1ed68270b492Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video56099954-e47b-4846-cf49-1ed68270b492">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Vm0Ie?t=132&quot;,&quot;itemId&quot;:&quot;Vm0Ie&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Vm0Ie?t=132" href="https://www.coursera.org/learn/python-machine-learning/lecture/Vm0Ie?t=132" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Cross-Validation</div></a><div class="video-details" aria-label="Duration">2:12 - 2:29</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">For
 example, to do five-fold cross-validation, the original dataset is 
partitioned into five parts of equal or close to equal size. Each of 
these parts is called a "fold". Then a series of five models is trained 
one per fold.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: For example, to do five-fold cross-validation, the original dataset is partitioned into five parts of equal or close to equal size. Each of these parts is called a &quot;fold&quot;. Then a series of five models is trained one per fold." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit26c8477f-5933-4610-eea4-bc17dea6dcda Edit26c8477f-5933-4610-eea4-bc17dea6dcdaDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit26c8477f-5933-4610-eea4-bc17dea6dcda">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: For example, to do five-fold cross-validation, the original dataset is partitioned into five parts of equal or close to equal size. Each of these parts is called a &quot;fold&quot;. Then a series of five models is trained one per fold." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleted052f4a9-e7bb-4bd4-a467-0a49881e5387 Deleted052f4a9-e7bb-4bd4-a467-0a49881e5387Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deleted052f4a9-e7bb-4bd4-a467-0a49881e5387">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videofa4569ae-a522-41c9-9afc-7e0f3298d1f3 Videofa4569ae-a522-41c9-9afc-7e0f3298d1f3Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videofa4569ae-a522-41c9-9afc-7e0f3298d1f3">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Vm0Ie?t=527&quot;,&quot;itemId&quot;:&quot;Vm0Ie&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Vm0Ie?t=527" href="https://www.coursera.org/learn/python-machine-learning/lecture/Vm0Ie?t=527" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Cross-Validation</div></a><div class="video-details" aria-label="Duration">8:47 - 9:06</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">
 Finally as a reminder, cross-validation is used to evaluate the model 
and not learn or tune a new model. To do model tuning, we'll look at how
 to tune the models parameters using something called "Grid Search" in a
 later lecture.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text:  Finally as a reminder, cross-validation is used to evaluate the model and not learn or tune a new model. To do model tuning, we'll look at how to tune the models parameters using something called &quot;Grid Search&quot; in a later lecture." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit3c11aba3-aa4c-429e-886c-9054b7c75911 Edit3c11aba3-aa4c-429e-886c-9054b7c75911Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit3c11aba3-aa4c-429e-886c-9054b7c75911">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text:  Finally as a reminder, cross-validation is used to evaluate the model and not learn or tune a new model. To do model tuning, we'll look at how to tune the models parameters using something called &quot;Grid Search&quot; in a later lecture." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete811b09e9-a2e7-4be1-ecb9-19eb526e6edc Delete811b09e9-a2e7-4be1-ecb9-19eb526e6edcDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete811b09e9-a2e7-4be1-ecb9-19eb526e6edc">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video47fd6a6f-c652-4d27-d85c-0d927ff14265 Video47fd6a6f-c652-4d27-d85c-0d927ff14265Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video47fd6a6f-c652-4d27-d85c-0d927ff14265">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Vm0Ie?t=448&quot;,&quot;itemId&quot;:&quot;Vm0Ie&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Vm0Ie?t=448" href="https://www.coursera.org/learn/python-machine-learning/lecture/Vm0Ie?t=448" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Cross-Validation</div></a><div class="video-details" aria-label="Duration">7:28 - 8:05</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">o
 you first pass in the estimator object, or that is the classifier or 
regression object to use, followed by the data set samples X and target 
values Y, the name of the parameter to sweep, and the array of parameter
 values that that parameter should take on in doing the sweep. 
Validation curve will return two two-dimensional arrays corresponding to
 evaluation on the training set and the test set. Each array has one row
 per parameter value in the sweep, and the number of columns is the 
number of cross-validation folds that are used.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: o you first pass in the estimator object, or that is the classifier or regression object to use, followed by the data set samples X and target values Y, the name of the parameter to sweep, and the array of parameter values that that parameter should take on in doing the sweep. Validation curve will return two two-dimensional arrays corresponding to evaluation on the training set and the test set. Each array has one row per parameter value in the sweep, and the number of columns is the number of cross-validation folds that are used." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editfd991893-8db7-4ed6-aa2c-fb09fb6f7581 Editfd991893-8db7-4ed6-aa2c-fb09fb6f7581Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editfd991893-8db7-4ed6-aa2c-fb09fb6f7581">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: o you first pass in the estimator object, or that is the classifier or regression object to use, followed by the data set samples X and target values Y, the name of the parameter to sweep, and the array of parameter values that that parameter should take on in doing the sweep. Validation curve will return two two-dimensional arrays corresponding to evaluation on the training set and the test set. Each array has one row per parameter value in the sweep, and the number of columns is the number of cross-validation folds that are used." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleteccb1ce18-b41c-4d49-ffa0-c9558bcac2f7 Deleteccb1ce18-b41c-4d49-ffa0-c9558bcac2f7Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deleteccb1ce18-b41c-4d49-ffa0-c9558bcac2f7">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video03f6b56e-4e1f-40a8-9ca5-c6bb52180dc9 Video03f6b56e-4e1f-40a8-9ca5-c6bb52180dc9Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video03f6b56e-4e1f-40a8-9ca5-c6bb52180dc9">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Vm0Ie?t=378&quot;,&quot;itemId&quot;:&quot;Vm0Ie&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Vm0Ie?t=378" href="https://www.coursera.org/learn/python-machine-learning/lecture/Vm0Ie?t=378" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Cross-Validation</div></a><div class="video-details" aria-label="Duration">6:18 - 6:55</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">At
 one extreme we can do something called "Leave-one-out 
cross-validation", which is just k-fold cross-validation, with K sets to
 the number of data samples in the data set. In other words, each fold 
consists of a single sample as the test set and the rest of the data as 
the training set. Of course this uses even more computation, but for 
small data sets in particular, it can provide improved proved estimates 
because it gives the maximum possible amount of training data to a 
model, and that may help the performance of the model when the training 
sets are small.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: At one extreme we can do something called &quot;Leave-one-out cross-validation&quot;, which is just k-fold cross-validation, with K sets to the number of data samples in the data set. In other words, each fold consists of a single sample as the test set and the rest of the data as the training set. Of course this uses even more computation, but for small data sets in particular, it can provide improved proved estimates because it gives the maximum possible amount of training data to a model, and that may help the performance of the model when the training sets are small." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit4b90276b-9c9f-4db5-8033-5c1c04a8a411 Edit4b90276b-9c9f-4db5-8033-5c1c04a8a411Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit4b90276b-9c9f-4db5-8033-5c1c04a8a411">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: At one extreme we can do something called &quot;Leave-one-out cross-validation&quot;, which is just k-fold cross-validation, with K sets to the number of data samples in the data set. In other words, each fold consists of a single sample as the test set and the rest of the data as the training set. Of course this uses even more computation, but for small data sets in particular, it can provide improved proved estimates because it gives the maximum possible amount of training data to a model, and that may help the performance of the model when the training sets are small." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete946189fc-2c44-4b6f-cb8f-d85c5b814f37 Delete946189fc-2c44-4b6f-cb8f-d85c5b814f37Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete946189fc-2c44-4b6f-cb8f-d85c5b814f37">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video2fd6bbc6-2bcd-4131-d6d3-df6a1d7f9dcb Video2fd6bbc6-2bcd-4131-d6d3-df6a1d7f9dcbDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video2fd6bbc6-2bcd-4131-d6d3-df6a1d7f9dcb">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Vm0Ie?t=298&quot;,&quot;itemId&quot;:&quot;Vm0Ie&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Vm0Ie?t=298" href="https://www.coursera.org/learn/python-machine-learning/lecture/Vm0Ie?t=298" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Cross-Validation</div></a><div class="video-details" aria-label="Duration">4:58 - 5:08</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">One
 problem with this is that the data might have been created in such a 
way that the records are sorted or at least show some bias in the 
ordering by class label.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: One problem with this is that the data might have been created in such a way that the records are sorted or at least show some bias in the ordering by class label." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit1ccf968f-42fc-47af-d8c4-6c1e44293811 Edit1ccf968f-42fc-47af-d8c4-6c1e44293811Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit1ccf968f-42fc-47af-d8c4-6c1e44293811">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: One problem with this is that the data might have been created in such a way that the records are sorted or at least show some bias in the ordering by class label." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete49324015-b7a0-4753-818d-62d26196a01c Delete49324015-b7a0-4753-818d-62d26196a01cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete49324015-b7a0-4753-818d-62d26196a01c">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video00159bb3-5d12-4b53-9aa1-f35739247600 Video00159bb3-5d12-4b53-9aa1-f35739247600Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video00159bb3-5d12-4b53-9aa1-f35739247600">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=375&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=375" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=375" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">6:15 - 6:26</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">So for the best split, the results should produce as homogeneous a set of classes as possible. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: So for the best split, the results should produce as homogeneous a set of classes as possible. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editd3a0994f-dc24-43be-9acc-fb351f178e91 Editd3a0994f-dc24-43be-9acc-fb351f178e91Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editd3a0994f-dc24-43be-9acc-fb351f178e91">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: So for the best split, the results should produce as homogeneous a set of classes as possible. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete213f94be-eb25-410c-e750-b17bf13aceb7 Delete213f94be-eb25-410c-e750-b17bf13aceb7Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete213f94be-eb25-410c-e750-b17bf13aceb7">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video94235ffa-f5e8-4c4b-e34a-77f6d27a9731 Video94235ffa-f5e8-4c4b-e34a-77f6d27a9731Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video94235ffa-f5e8-4c4b-e34a-77f6d27a9731">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=1097&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=1097" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=1097" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">18:17 - 18:38</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">One
 drawback of decision trees is that despite the use of pruning they can 
still overfit all or parts of the data and may not achieve the best 
generalization performance compared to other methods. One way to 
overcome that problem is to create what's called an ensemble of decision
 trees which combines multiple decision trees to make a prediction </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: One drawback of decision trees is that despite the use of pruning they can still overfit all or parts of the data and may not achieve the best generalization performance compared to other methods. One way to overcome that problem is to create what's called an ensemble of decision trees which combines multiple decision trees to make a prediction " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editb80f3ad6-385c-4c4d-b7f9-8dd3a921be74 Editb80f3ad6-385c-4c4d-b7f9-8dd3a921be74Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editb80f3ad6-385c-4c4d-b7f9-8dd3a921be74">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: One drawback of decision trees is that despite the use of pruning they can still overfit all or parts of the data and may not achieve the best generalization performance compared to other methods. One way to overcome that problem is to create what's called an ensemble of decision trees which combines multiple decision trees to make a prediction " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete8fa6decf-55ce-4c12-b2c2-072964734ba8 Delete8fa6decf-55ce-4c12-b2c2-072964734ba8Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete8fa6decf-55ce-4c12-b2c2-072964734ba8">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video49be2685-8d62-4e23-c53c-3aa167485c91 Video49be2685-8d62-4e23-c53c-3aa167485c91Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video49be2685-8d62-4e23-c53c-3aa167485c91">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=473&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=473" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=473" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">7:53 - 8:04</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Trees
 whose leaf nodes each have all the same target value are called pure, 
as opposed to mixed where the leaf nodes are allowed to contain at least
 some mixture of the classes.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Trees whose leaf nodes each have all the same target value are called pure, as opposed to mixed where the leaf nodes are allowed to contain at least some mixture of the classes." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editafdb69d7-2b74-48fe-efed-35d359c333bf Editafdb69d7-2b74-48fe-efed-35d359c333bfDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editafdb69d7-2b74-48fe-efed-35d359c333bf">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Trees whose leaf nodes each have all the same target value are called pure, as opposed to mixed where the leaf nodes are allowed to contain at least some mixture of the classes." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleteabb474e3-27d4-4b9a-83a9-a1133a6c4848 Deleteabb474e3-27d4-4b9a-83a9-a1133a6c4848Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deleteabb474e3-27d4-4b9a-83a9-a1133a6c4848">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video55291a34-a72c-41e9-8965-8d106d74e355 Video55291a34-a72c-41e9-8965-8d106d74e355Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video55291a34-a72c-41e9-8965-8d106d74e355">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=382&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=382" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=382" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">6:22 - 6:33</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">here
 are a number of mathematical ways to compute the best split. One 
criterion that's widely used for decision trees is called information 
game</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: here are a number of mathematical ways to compute the best split. One criterion that's widely used for decision trees is called information game" tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit184d3767-3d75-4101-ca37-09d997fe3d2b Edit184d3767-3d75-4101-ca37-09d997fe3d2bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit184d3767-3d75-4101-ca37-09d997fe3d2b">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: here are a number of mathematical ways to compute the best split. One criterion that's widely used for decision trees is called information game" tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletec774187a-d956-41b3-95c8-2bd5f7e6cf77 Deletec774187a-d956-41b3-95c8-2bd5f7e6cf77Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletec774187a-d956-41b3-95c8-2bd5f7e6cf77">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video4378e299-2e75-4292-9bd0-2d3d1b46131f Video4378e299-2e75-4292-9bd0-2d3d1b46131fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video4378e299-2e75-4292-9bd0-2d3d1b46131f">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=1068&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=1068" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=1068" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">17:48 - 18:06</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Another
 advantage of decision trees is that you can use them without having to 
do feature pre-processing or normalization. Since each feature is 
processed independently and the splitting of the data doesn't depend on 
the absolute scale of the feature. The decision algorithm can operate on
 the original training data pretty much as is.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Another advantage of decision trees is that you can use them without having to do feature pre-processing or normalization. Since each feature is processed independently and the splitting of the data doesn't depend on the absolute scale of the feature. The decision algorithm can operate on the original training data pretty much as is." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit5978c5e7-0d04-4ff6-830e-a0003a016441 Edit5978c5e7-0d04-4ff6-830e-a0003a016441Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit5978c5e7-0d04-4ff6-830e-a0003a016441">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Another advantage of decision trees is that you can use them without having to do feature pre-processing or normalization. Since each feature is processed independently and the splitting of the data doesn't depend on the absolute scale of the feature. The decision algorithm can operate on the original training data pretty much as is." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletefb7731ea-ed24-49a2-c938-73387102251a Deletefb7731ea-ed24-49a2-c938-73387102251aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletefb7731ea-ed24-49a2-c938-73387102251a">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video70a1fbb3-16d7-4939-974d-062e0390b2d3 Video70a1fbb3-16d7-4939-974d-062e0390b2d3Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video70a1fbb3-16d7-4939-974d-062e0390b2d3">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=522&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=522" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=522" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">8:42 - 8:53</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Decision
 trees can also be used for regression using the same process of testing
 the future values at each node and predicting the target value based on
 the contents of the leafnode.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Decision trees can also be used for regression using the same process of testing the future values at each node and predicting the target value based on the contents of the leafnode." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit007dab7c-1098-4dc1-9f4b-643204977325 Edit007dab7c-1098-4dc1-9f4b-643204977325Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit007dab7c-1098-4dc1-9f4b-643204977325">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Decision trees can also be used for regression using the same process of testing the future values at each node and predicting the target value based on the contents of the leafnode." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete4e975e60-3771-484e-bfc1-ba0e11851ab9 Delete4e975e60-3771-484e-bfc1-ba0e11851ab9Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete4e975e60-3771-484e-bfc1-ba0e11851ab9">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videod363dd43-9198-4a1c-d2fe-8c832f94444b Videod363dd43-9198-4a1c-d2fe-8c832f94444bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videod363dd43-9198-4a1c-d2fe-8c832f94444b">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=613&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=613" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=613" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">10:13 - 10:22</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">The decision tree implementation and scikit-learn only implements pre-pruning. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: The decision tree implementation and scikit-learn only implements pre-pruning. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit49849cbc-481e-4a5c-b7fd-ee3998c6eb85 Edit49849cbc-481e-4a5c-b7fd-ee3998c6eb85Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit49849cbc-481e-4a5c-b7fd-ee3998c6eb85">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: The decision tree implementation and scikit-learn only implements pre-pruning. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete65a00f75-239c-4cce-a985-54e69271d3f6 Delete65a00f75-239c-4cce-a985-54e69271d3f6Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete65a00f75-239c-4cce-a985-54e69271d3f6">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoa7c2383f-2492-4e69-f720-cf72cfdf28cc Videoa7c2383f-2492-4e69-f720-cf72cfdf28ccDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videoa7c2383f-2492-4e69-f720-cf72cfdf28cc">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=943&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=943" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=943" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">15:43 - 16:06</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Note
 that if a feature has a low feature importance value, that doesn't 
necessarily mean that the feature is not important for prediction. It 
simply means that the particular feature wasn't chosen at an early level
 of the tree and this could be because the future may be identical or 
highly correlated with another informative feature and so doesn't 
provide any new additional signal for prediction.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Note that if a feature has a low feature importance value, that doesn't necessarily mean that the feature is not important for prediction. It simply means that the particular feature wasn't chosen at an early level of the tree and this could be because the future may be identical or highly correlated with another informative feature and so doesn't provide any new additional signal for prediction." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edita8037d0e-b141-4771-e00b-8cd98e7e5eaf Edita8037d0e-b141-4771-e00b-8cd98e7e5eafDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edita8037d0e-b141-4771-e00b-8cd98e7e5eaf">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Note that if a feature has a low feature importance value, that doesn't necessarily mean that the feature is not important for prediction. It simply means that the particular feature wasn't chosen at an early level of the tree and this could be because the future may be identical or highly correlated with another informative feature and so doesn't provide any new additional signal for prediction." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete06cb71d2-1bbc-47e1-ada4-4523c9e2d06d Delete06cb71d2-1bbc-47e1-ada4-4523c9e2d06dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete06cb71d2-1bbc-47e1-ada4-4523c9e2d06d">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video9fb11686-963b-4350-883d-fceb8f8728a7 Video9fb11686-963b-4350-883d-fceb8f8728a7Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video9fb11686-963b-4350-883d-fceb8f8728a7">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=187&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=187" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=187" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">3:07 - 3:20</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">We
 can generalize this idea of finding a set of rules that can learn to 
categorize an object into the correct category to many other 
classification tasks. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: We can generalize this idea of finding a set of rules that can learn to categorize an object into the correct category to many other classification tasks. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edite9cfdc2f-9af8-42ce-82e2-d9c118cea59b Edite9cfdc2f-9af8-42ce-82e2-d9c118cea59bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edite9cfdc2f-9af8-42ce-82e2-d9c118cea59b">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: We can generalize this idea of finding a set of rules that can learn to categorize an object into the correct category to many other classification tasks. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete85b18672-c1b7-4474-cd66-939f44258710 Delete85b18672-c1b7-4474-cd66-939f44258710Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete85b18672-c1b7-4474-cd66-939f44258710">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videod021b723-07fa-4c33-aa35-ca9341a48a92 Videod021b723-07fa-4c33-aa35-ca9341a48a92Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videod021b723-07fa-4c33-aa35-ca9341a48a92">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=7&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=7" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=7" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">0:07 - 0:17</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Decision
 trees are a popular supervised learning method that like many other 
learning methods we've seen, can be used for both regression and 
classification.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Decision trees are a popular supervised learning method that like many other learning methods we've seen, can be used for both regression and classification." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editbff2cc06-a10b-4eb7-d5c6-fcfca25c9c09 Editbff2cc06-a10b-4eb7-d5c6-fcfca25c9c09Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editbff2cc06-a10b-4eb7-d5c6-fcfca25c9c09">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Decision trees are a popular supervised learning method that like many other learning methods we've seen, can be used for both regression and classification." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete1b4f335f-068b-476a-c589-bd42d7509a2a Delete1b4f335f-068b-476a-c589-bd42d7509a2aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete1b4f335f-068b-476a-c589-bd42d7509a2a">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video56201aef-bbbb-4ce5-d465-20f2c21968a2 Video56201aef-bbbb-4ce5-d465-20f2c21968a2Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video56201aef-bbbb-4ce5-d465-20f2c21968a2">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=324&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=324" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=324" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">5:24 - 5:48</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">An
 important concept is how informative a split of the data is. So 
intuitively an informative split of the data is one that does an 
excellent job at separating one class from the others. An example of an 
informative split might be to put all instances of the flowers with 
petal length less than 2.35 centimeters into one bin and the rest in the
 other bin.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: An important concept is how informative a split of the data is. So intuitively an informative split of the data is one that does an excellent job at separating one class from the others. An example of an informative split might be to put all instances of the flowers with petal length less than 2.35 centimeters into one bin and the rest in the other bin." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editb9d6554e-b213-44f0-a506-97dedc337cdb Editb9d6554e-b213-44f0-a506-97dedc337cdbDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editb9d6554e-b213-44f0-a506-97dedc337cdb">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: An important concept is how informative a split of the data is. So intuitively an informative split of the data is one that does an excellent job at separating one class from the others. An example of an informative split might be to put all instances of the flowers with petal length less than 2.35 centimeters into one bin and the rest in the other bin." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletedcb4e30d-3e39-4a24-efd9-25f360978c14 Deletedcb4e30d-3e39-4a24-efd9-25f360978c14Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletedcb4e30d-3e39-4a24-efd9-25f360978c14">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video706a276f-a60a-4656-e3e3-eadafa2c175c Video706a276f-a60a-4656-e3e3-eadafa2c175cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video706a276f-a60a-4656-e3e3-eadafa2c175c">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=540&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=540" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=540" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">9:00 - 9:15</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">In
 scikit-learn, to build the decision tree you import the decision tree 
classifier class from the Sklearn tree module and fit it just as you 
would any classifier by creating the object and calling the fit method 
on the training data.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: In scikit-learn, to build the decision tree you import the decision tree classifier class from the Sklearn tree module and fit it just as you would any classifier by creating the object and calling the fit method on the training data." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editd05ba2f7-6be5-4c18-9770-18a84358e15e Editd05ba2f7-6be5-4c18-9770-18a84358e15eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editd05ba2f7-6be5-4c18-9770-18a84358e15e">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: In scikit-learn, to build the decision tree you import the decision tree classifier class from the Sklearn tree module and fit it just as you would any classifier by creating the object and calling the fit method on the training data." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletee2f636ce-17dd-4580-d22b-e996d5e9037c Deletee2f636ce-17dd-4580-d22b-e996d5e9037cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletee2f636ce-17dd-4580-d22b-e996d5e9037c">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoc59dfd9d-2151-405f-c644-11452d0cdf9c Videoc59dfd9d-2151-405f-c644-11452d0cdf9cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videoc59dfd9d-2151-405f-c644-11452d0cdf9c">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=1047&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=1047" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=1047" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">17:27 - 17:48</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">One
 of the major advantages of decision trees as a supervised learning 
method, is that the decision rules are easily visualized and interpreted
 by people including users without machine learning expertise. This 
makes decision trees a useful choice for getting an initial 
understanding of what some of the more important features are likely to 
be for a particular prediction task.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: One of the major advantages of decision trees as a supervised learning method, is that the decision rules are easily visualized and interpreted by people including users without machine learning expertise. This makes decision trees a useful choice for getting an initial understanding of what some of the more important features are likely to be for a particular prediction task." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit3a9b20a2-74b9-420e-ab77-7fae308774e4 Edit3a9b20a2-74b9-420e-ab77-7fae308774e4Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit3a9b20a2-74b9-420e-ab77-7fae308774e4">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: One of the major advantages of decision trees as a supervised learning method, is that the decision rules are easily visualized and interpreted by people including users without machine learning expertise. This makes decision trees a useful choice for getting an initial understanding of what some of the more important features are likely to be for a particular prediction task." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete98264721-c7cc-4401-a11f-29c3463c6923 Delete98264721-c7cc-4401-a11f-29c3463c6923Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete98264721-c7cc-4401-a11f-29c3463c6923">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videof55d48f7-f926-458c-f161-dadc1dbdcf06 Videof55d48f7-f926-458c-f161-dadc1dbdcf06Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videof55d48f7-f926-458c-f161-dadc1dbdcf06">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=308&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=308" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=308" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">5:08 - 5:24</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">
 For example, whether the petal width is greater than one point two 
centimeters might be an example of a splitting rule that threshold is 
called a split point.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text:  For example, whether the petal width is greater than one point two centimeters might be an example of a splitting rule that threshold is called a split point." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editfcc9b7a5-2a28-4b8f-efd1-a3314f031302 Editfcc9b7a5-2a28-4b8f-efd1-a3314f031302Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editfcc9b7a5-2a28-4b8f-efd1-a3314f031302">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text:  For example, whether the petal width is greater than one point two centimeters might be an example of a splitting rule that threshold is called a split point." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete7a8d08fa-f7ba-4d02-d824-947391820c61 Delete7a8d08fa-f7ba-4d02-d824-947391820c61Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete7a8d08fa-f7ba-4d02-d824-947391820c61">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoaec82873-07b1-4ff7-c58e-834974dacfc4 Videoaec82873-07b1-4ff7-c58e-834974dacfc4Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoaec82873-07b1-4ff7-c58e-834974dacfc4">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=874&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=874" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=874" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">14:34 - 15:12</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">In
 scikit-learn, feature importance values are stored as a list in an 
estimated property called feature_importances_. And note the underscore 
at the end of the name which indicates it's a property of the object 
that's set as a result of fitting the model and not say as a user 
defined property. The shared utilities python file contains a function 
called plot feature importances, that you can import and use to 
visualize future importance. It plots a horizontal bar chart with the 
features listed along the y axis by name and feature importance along 
the x axis.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: In scikit-learn, feature importance values are stored as a list in an estimated property called feature_importances_. And note the underscore at the end of the name which indicates it's a property of the object that's set as a result of fitting the model and not say as a user defined property. The shared utilities python file contains a function called plot feature importances, that you can import and use to visualize future importance. It plots a horizontal bar chart with the features listed along the y axis by name and feature importance along the x axis." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit5df32c74-be1d-4896-abd0-550d163de5ed Edit5df32c74-be1d-4896-abd0-550d163de5edDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit5df32c74-be1d-4896-abd0-550d163de5ed">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: In scikit-learn, feature importance values are stored as a list in an estimated property called feature_importances_. And note the underscore at the end of the name which indicates it's a property of the object that's set as a result of fitting the model and not say as a user defined property. The shared utilities python file contains a function called plot feature importances, that you can import and use to visualize future importance. It plots a horizontal bar chart with the features listed along the y axis by name and feature importance along the x axis." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete1e37fc02-e474-46ed-995e-daef8bf959f4 Delete1e37fc02-e474-46ed-995e-daef8bf959f4Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete1e37fc02-e474-46ed-995e-daef8bf959f4">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video2384d8cf-f611-45dd-e919-0277f3f65bd2 Video2384d8cf-f611-45dd-e919-0277f3f65bd2Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video2384d8cf-f611-45dd-e919-0277f3f65bd2">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=654&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=654" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=654" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">10:54 - 11:20</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">One
 great advantage of decision trees at least for the not too big, is that
 they're easy to interpret. Visualizing the entire tree can show you 
exactly how did the decision tree is making its predictions. So let's 
take a look at an example. In the shared utilities Python code for this 
course, we've provided a function call named Plot decision tree, that 
takes the classifier object, the feature names, and the class names as 
input.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: One great advantage of decision trees at least for the not too big, is that they're easy to interpret. Visualizing the entire tree can show you exactly how did the decision tree is making its predictions. So let's take a look at an example. In the shared utilities Python code for this course, we've provided a function call named Plot decision tree, that takes the classifier object, the feature names, and the class names as input." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editc25907bb-ec28-4699-dcae-f7af96abcf7b Editc25907bb-ec28-4699-dcae-f7af96abcf7bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editc25907bb-ec28-4699-dcae-f7af96abcf7b">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: One great advantage of decision trees at least for the not too big, is that they're easy to interpret. Visualizing the entire tree can show you exactly how did the decision tree is making its predictions. So let's take a look at an example. In the shared utilities Python code for this course, we've provided a function call named Plot decision tree, that takes the classifier object, the feature names, and the class names as input." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete122d3d0d-f5c2-4f3f-d6bf-d16ce0f66e30 Delete122d3d0d-f5c2-4f3f-d6bf-d16ce0f66e30Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete122d3d0d-f5c2-4f3f-d6bf-d16ce0f66e30">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videob19c369c-a56c-4590-afda-80d85b442f4c Videob19c369c-a56c-4590-afda-80d85b442f4cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videob19c369c-a56c-4590-afda-80d85b442f4c">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=460&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=460" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=460" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">7:40 - 7:53</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">We
 can continue this process recursively until we're left with leaves in 
the decision tree that all have the same or at least a predominant 
majority of a target value.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: We can continue this process recursively until we're left with leaves in the decision tree that all have the same or at least a predominant majority of a target value." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit5d6ed299-5d8d-409a-f28d-258175ebbaeb Edit5d6ed299-5d8d-409a-f28d-258175ebbaebDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit5d6ed299-5d8d-409a-f28d-258175ebbaeb">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: We can continue this process recursively until we're left with leaves in the decision tree that all have the same or at least a predominant majority of a target value." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleteba0e06d4-90a1-4ad4-ac13-6f76326560f2 Deleteba0e06d4-90a1-4ad4-ac13-6f76326560f2Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deleteba0e06d4-90a1-4ad4-ac13-6f76326560f2">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoeac28bb9-98bd-46fe-f750-ebaeafdad750 Videoeac28bb9-98bd-46fe-f750-ebaeafdad750Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoeac28bb9-98bd-46fe-f750-ebaeafdad750">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=800&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=800" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=800" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">13:20 - 13:36</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">or
 larger trees that have say a depth of more than 5 or 10. Instead of 
trying to analyze all the paths in the tree it can be useful to see 
which paths most of the data takes. This can be done by looking for the 
largest samples values in the nodes.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: or larger trees that have say a depth of more than 5 or 10. Instead of trying to analyze all the paths in the tree it can be useful to see which paths most of the data takes. This can be done by looking for the largest samples values in the nodes." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit67aef858-9cf1-4965-bfe3-cf9f3415246b Edit67aef858-9cf1-4965-bfe3-cf9f3415246bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit67aef858-9cf1-4965-bfe3-cf9f3415246b">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: or larger trees that have say a depth of more than 5 or 10. Instead of trying to analyze all the paths in the tree it can be useful to see which paths most of the data takes. This can be done by looking for the largest samples values in the nodes." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletec26e1850-82fa-4e1c-c1c8-8f1cf16efa8e Deletec26e1850-82fa-4e1c-c1c8-8f1cf16efa8eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletec26e1850-82fa-4e1c-c1c8-8f1cf16efa8e">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoa2b11e10-88db-4869-f139-b5b65fa3b00b Videoa2b11e10-88db-4869-f139-b5b65fa3b00bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videoa2b11e10-88db-4869-f139-b5b65fa3b00b">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=1122&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=1122" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=1122" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">18:42 - 19:40</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">So
 to recap, scikit-learn enables you to control the model complexity of 
your decision trees with three key parameters. First, max depth controls
 the maximum depth or the number of split points the decision can have 
and it's probably the most common parameter used to reduce tree 
complexity and thus reduce overfitting. The min samples leaf parameter 
is the threshold that controls what the minimum number of data instances
 has to be in a leaf to avoid splitting it further. This setting also 
reduces tree complexity. Finally, max leaf nodes limits the total number
 of nodes that are leaves of the tree. In effect, setting this parameter
 will indirectly influence the other two parameters and vice versa. So 
in practice, adjusting only one of these trees is typically enough to 
control most overfitting. Although even with the most optimized 
parameter settings, individual decision trees will still tend to 
overfit.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: So to recap, scikit-learn enables you to control the model complexity of your decision trees with three key parameters. First, max depth controls the maximum depth or the number of split points the decision can have and it's probably the most common parameter used to reduce tree complexity and thus reduce overfitting. The min samples leaf parameter is the threshold that controls what the minimum number of data instances has to be in a leaf to avoid splitting it further. This setting also reduces tree complexity. Finally, max leaf nodes limits the total number of nodes that are leaves of the tree. In effect, setting this parameter will indirectly influence the other two parameters and vice versa. So in practice, adjusting only one of these trees is typically enough to control most overfitting. Although even with the most optimized parameter settings, individual decision trees will still tend to overfit." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editf1a32fe3-980d-4bb8-ed8b-8514eb5603d9 Editf1a32fe3-980d-4bb8-ed8b-8514eb5603d9Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editf1a32fe3-980d-4bb8-ed8b-8514eb5603d9">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: So to recap, scikit-learn enables you to control the model complexity of your decision trees with three key parameters. First, max depth controls the maximum depth or the number of split points the decision can have and it's probably the most common parameter used to reduce tree complexity and thus reduce overfitting. The min samples leaf parameter is the threshold that controls what the minimum number of data instances has to be in a leaf to avoid splitting it further. This setting also reduces tree complexity. Finally, max leaf nodes limits the total number of nodes that are leaves of the tree. In effect, setting this parameter will indirectly influence the other two parameters and vice versa. So in practice, adjusting only one of these trees is typically enough to control most overfitting. Although even with the most optimized parameter settings, individual decision trees will still tend to overfit." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletef659d68a-1f2b-448a-9583-f996c9c957cf Deletef659d68a-1f2b-448a-9583-f996c9c957cfDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deletef659d68a-1f2b-448a-9583-f996c9c957cf">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video4d1f3e22-ec9d-49bd-bc0a-f69aace7365f Video4d1f3e22-ec9d-49bd-bc0a-f69aace7365fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video4d1f3e22-ec9d-49bd-bc0a-f69aace7365f">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=619&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=619" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=619" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">10:19 - 10:49</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">We
 can control tree complexity via pruning by limiting either the maximum 
depth of the tree using the max depth parameter or the maximum number of
 leafnodes using the max leafnodes parameter. We could also set a 
threshold on the minimum number of instances that must be in a node to 
consider splitting it. And this would be using the min samples leaf 
parameter we can see the effect of pre-pruning by setting max depth to 
three on the iris dataset. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: We can control tree complexity via pruning by limiting either the maximum depth of the tree using the max depth parameter or the maximum number of leafnodes using the max leafnodes parameter. We could also set a threshold on the minimum number of instances that must be in a node to consider splitting it. And this would be using the min samples leaf parameter we can see the effect of pre-pruning by setting max depth to three on the iris dataset. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit87fbdf28-70b9-4b3a-9a72-9de41c1d1427 Edit87fbdf28-70b9-4b3a-9a72-9de41c1d1427Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit87fbdf28-70b9-4b3a-9a72-9de41c1d1427">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: We can control tree complexity via pruning by limiting either the maximum depth of the tree using the max depth parameter or the maximum number of leafnodes using the max leafnodes parameter. We could also set a threshold on the minimum number of instances that must be in a node to consider splitting it. And this would be using the min samples leaf parameter we can see the effect of pre-pruning by setting max depth to three on the iris dataset. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete77995366-54b6-44fe-9ba0-0d46bcc5b2ba Delete77995366-54b6-44fe-9ba0-0d46bcc5b2baDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete77995366-54b6-44fe-9ba0-0d46bcc5b2ba">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video5bd9ae1e-8837-483a-934d-52dc7b6a0b4c Video5bd9ae1e-8837-483a-934d-52dc7b6a0b4cDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video5bd9ae1e-8837-483a-934d-52dc7b6a0b4c">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=563&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=563" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=563" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">9:23 - 9:51</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Notice
 that the training data here is predicted perfectly with an accuracy of 
1.0. While the test data is a little bit worse. This is an indication 
that the tree is likely overfitting and in fact this is a problem with 
building decision trees in general that keep adding rules until the 
leafnodes are pure. Typically such trees are overly complex and 
essentially memorized the training data. So when building decision 
trees, we need to use some additional strategy to prevent this 
overfitting.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Notice that the training data here is predicted perfectly with an accuracy of 1.0. While the test data is a little bit worse. This is an indication that the tree is likely overfitting and in fact this is a problem with building decision trees in general that keep adding rules until the leafnodes are pure. Typically such trees are overly complex and essentially memorized the training data. So when building decision trees, we need to use some additional strategy to prevent this overfitting." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit3ff23872-928d-4439-eec4-cc8021521145 Edit3ff23872-928d-4439-eec4-cc8021521145Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit3ff23872-928d-4439-eec4-cc8021521145">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Notice that the training data here is predicted perfectly with an accuracy of 1.0. While the test data is a little bit worse. This is an indication that the tree is likely overfitting and in fact this is a problem with building decision trees in general that keep adding rules until the leafnodes are pure. Typically such trees are overly complex and essentially memorized the training data. So when building decision trees, we need to use some additional strategy to prevent this overfitting." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete4416c7b2-428d-471f-ebbc-6fb892ad05fd Delete4416c7b2-428d-471f-ebbc-6fb892ad05fdDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete4416c7b2-428d-471f-ebbc-6fb892ad05fd">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video5cdfc30f-3773-45b6-a1da-499cb3371f22 Video5cdfc30f-3773-45b6-a1da-499cb3371f22Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video5cdfc30f-3773-45b6-a1da-499cb3371f22">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=966&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=966" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=966" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">16:06 - 16:18</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Feature
 importance values don't tell us which specific classes a feature might 
be especially predictive for, and they also don't indicate more complex 
relationships between features that may influence prediction.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Feature importance values don't tell us which specific classes a feature might be especially predictive for, and they also don't indicate more complex relationships between features that may influence prediction." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit0f48b5a9-de85-4ab0-b08e-258374386395 Edit0f48b5a9-de85-4ab0-b08e-258374386395Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit0f48b5a9-de85-4ab0-b08e-258374386395">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Feature importance values don't tell us which specific classes a feature might be especially predictive for, and they also don't indicate more complex relationships between features that may influence prediction." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete6f44fe8b-9556-489f-8890-40960506ae7e Delete6f44fe8b-9556-489f-8890-40960506ae7eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete6f44fe8b-9556-489f-8890-40960506ae7e">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videobb50ec1d-a513-466e-f9fc-192f737e6b82 Videobb50ec1d-a513-466e-f9fc-192f737e6b82Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videobb50ec1d-a513-466e-f9fc-192f737e6b82">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=982&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=982" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=982" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">16:22 - 16:47</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">hat
 can give useful insight about individual features in the learning 
model. Because feature importance can vary depending on the specific 
model learned for a particular train/test split for example. It's common
 when computing feature importance to use an average over multiple 
train/test splits. For example when performing cross-validation. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: hat can give useful insight about individual features in the learning model. Because feature importance can vary depending on the specific model learned for a particular train/test split for example. It's common when computing feature importance to use an average over multiple train/test splits. For example when performing cross-validation. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editb1e31807-2d0b-4e74-e3a8-64c7ec3ac33f Editb1e31807-2d0b-4e74-e3a8-64c7ec3ac33fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editb1e31807-2d0b-4e74-e3a8-64c7ec3ac33f">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: hat can give useful insight about individual features in the learning model. Because feature importance can vary depending on the specific model learned for a particular train/test split for example. It's common when computing feature importance to use an average over multiple train/test splits. For example when performing cross-validation. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete51898158-f434-4a86-f5dd-6fc3d79928ed Delete51898158-f434-4a86-f5dd-6fc3d79928edDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete51898158-f434-4a86-f5dd-6fc3d79928ed">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video032b070d-24aa-435b-a4d8-3f7502f03a39 Video032b070d-24aa-435b-a4d8-3f7502f03a39Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video032b070d-24aa-435b-a4d8-3f7502f03a39">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=196&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=196" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=196" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">3:16 - 3:31</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">For
 example, we're going to look at a classification task next that 
involves finding rules that can predict what species a particular flower
 is, based on measurements of certain parts of the flower. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: For example, we're going to look at a classification task next that involves finding rules that can predict what species a particular flower is, based on measurements of certain parts of the flower. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editaa9ef1c5-5553-4bbf-f9f1-6f75d38795c2 Editaa9ef1c5-5553-4bbf-f9f1-6f75d38795c2Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editaa9ef1c5-5553-4bbf-f9f1-6f75d38795c2">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: For example, we're going to look at a classification task next that involves finding rules that can predict what species a particular flower is, based on measurements of certain parts of the flower. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete1345f80e-c4fe-4ab9-cb5c-c16e83fdbde0 Delete1345f80e-c4fe-4ab9-cb5c-c16e83fdbde0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete1345f80e-c4fe-4ab9-cb5c-c16e83fdbde0">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videof37d049a-f050-4205-cf60-f2c2ee2a88f6 Videof37d049a-f050-4205-cf60-f2c2ee2a88f6Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videof37d049a-f050-4205-cf60-f2c2ee2a88f6">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=591&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=591" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=591" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">9:51 - 10:05</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">One
 strategy to prevent overfitting is to prevent the tree from becoming 
really detailed and complex by stopping its growth early. This is called
 pre-pruning. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: One strategy to prevent overfitting is to prevent the tree from becoming really detailed and complex by stopping its growth early. This is called pre-pruning. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editfc0e7019-b6bb-49f8-b928-9ab81a58e2a5 Editfc0e7019-b6bb-49f8-b928-9ab81a58e2a5Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editfc0e7019-b6bb-49f8-b928-9ab81a58e2a5">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: One strategy to prevent overfitting is to prevent the tree from becoming really detailed and complex by stopping its growth early. This is called pre-pruning. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete32bc8171-8eed-44f0-d229-36fea2c4b37e Delete32bc8171-8eed-44f0-d229-36fea2c4b37eDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete32bc8171-8eed-44f0-d229-36fea2c4b37e">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video4514a123-1177-419b-a8d0-e91af0ac5961 Video4514a123-1177-419b-a8d0-e91af0ac5961Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video4514a123-1177-419b-a8d0-e91af0ac5961">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=530&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=530" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=530" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">8:50 - 9:00</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">he
 target value based on the contents of the leafnode. For regression, the
 leafnode prediction would be the mean value of the target values for 
the training points in that leaf.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: he target value based on the contents of the leafnode. For regression, the leafnode prediction would be the mean value of the target values for the training points in that leaf." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editefb81a0b-ac6c-4a1d-e0e2-191f4c20f2ed Editefb81a0b-ac6c-4a1d-e0e2-191f4c20f2edDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editefb81a0b-ac6c-4a1d-e0e2-191f4c20f2ed">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: he target value based on the contents of the leafnode. For regression, the leafnode prediction would be the mean value of the target values for the training points in that leaf." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete8e5d367f-2100-4a43-9d96-b30b058562c1 Delete8e5d367f-2100-4a43-9d96-b30b058562c1Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete8e5d367f-2100-4a43-9d96-b30b058562c1">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video27a63868-8cc5-4ad9-9964-c27ba8684bd8 Video27a63868-8cc5-4ad9-9964-c27ba8684bd8Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video27a63868-8cc5-4ad9-9964-c27ba8684bd8">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=1086&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=1086" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=1086" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">18:06 - 18:22</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">So
 decision trees tend to work well with data sets that have a mixture of 
feature types-- binary, categorical or continuous and with features that
 are on very different scales. </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: So decision trees tend to work well with data sets that have a mixture of feature types-- binary, categorical or continuous and with features that are on very different scales. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit756741e1-a5eb-4eb2-a031-155636216cd0 Edit756741e1-a5eb-4eb2-a031-155636216cd0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit756741e1-a5eb-4eb2-a031-155636216cd0">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: So decision trees tend to work well with data sets that have a mixture of feature types-- binary, categorical or continuous and with features that are on very different scales. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete51696b5b-6454-46f1-85c6-e4ada21aea0d Delete51696b5b-6454-46f1-85c6-e4ada21aea0dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Delete51696b5b-6454-46f1-85c6-e4ada21aea0d">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video9ec65e07-9326-43d2-d023-a31c0f1f1143 Video9ec65e07-9326-43d2-d023-a31c0f1f1143Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video9ec65e07-9326-43d2-d023-a31c0f1f1143">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=27&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=27" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=27" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">0:27 - 0:36</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Basically,
 decision trees learn a series of explicit if then rules on feature 
values that result in a decision that predicts the target value.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Basically, decision trees learn a series of explicit if then rules on feature values that result in a decision that predicts the target value." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edita084e172-9ce6-4908-9cf7-78911e5796fa Edita084e172-9ce6-4908-9cf7-78911e5796faDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edita084e172-9ce6-4908-9cf7-78911e5796fa">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Basically, decision trees learn a series of explicit if then rules on feature values that result in a decision that predicts the target value." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete3fe5c31b-53fc-468d-f6e4-2cd217242ce0 Delete3fe5c31b-53fc-468d-f6e4-2cd217242ce0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete3fe5c31b-53fc-468d-f6e4-2cd217242ce0">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videof15fded8-c8ab-4de7-bf04-dcd6d036e206 Videof15fded8-c8ab-4de7-bf04-dcd6d036e206Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videof15fded8-c8ab-4de7-bf04-dcd6d036e206">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=348&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=348" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=348" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">5:48 - 6:03</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">This
 is an informative split because at least for this training set, using 
that rule separates the setosa class completely from the others and 
allows us to predict the setosa class perfectly just based on this one 
measurement.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: This is an informative split because at least for this training set, using that rule separates the setosa class completely from the others and allows us to predict the setosa class perfectly just based on this one measurement." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editb1d912cf-4243-44f1-b88b-d79af2e67c3b Editb1d912cf-4243-44f1-b88b-d79af2e67c3bDesc" xmlns="http://www.w3.org/2000/svg"><title id="Editb1d912cf-4243-44f1-b88b-d79af2e67c3b">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: This is an informative split because at least for this training set, using that rule separates the setosa class completely from the others and allows us to predict the setosa class perfectly just based on this one measurement." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete4f97fe50-6361-4ddb-9344-ba96b3add9c5 Delete4f97fe50-6361-4ddb-9344-ba96b3add9c5Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete4f97fe50-6361-4ddb-9344-ba96b3add9c5">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video54e4e60f-19a8-4fca-f6c8-ab27e6807714 Video54e4e60f-19a8-4fca-f6c8-ab27e6807714Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video54e4e60f-19a8-4fca-f6c8-ab27e6807714">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=824&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=824" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=824" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">13:44 - 14:34</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">
 Another way of analyzing the tree instead of looking at the whole tree 
at once is to do what's called a feature important calculation. And this
 is one of the most useful and widely used types of summary analysis you
 can perform on a supervised learning model. Feature importance is 
typically a number between 0 and 1 that's assigned to an individual 
feature. It indicates how important that feature is to the overall 
prediction accuracy. A feature importance of zero means that the feature
 is not used at all in the prediction. A feature importance of one, 
means the feature perfectly predicts the target. Typically, feature 
importance numbers are always positive and they're normalized so they 
sum to one.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text:  Another way of analyzing the tree instead of looking at the whole tree at once is to do what's called a feature important calculation. And this is one of the most useful and widely used types of summary analysis you can perform on a supervised learning model. Feature importance is typically a number between 0 and 1 that's assigned to an individual feature. It indicates how important that feature is to the overall prediction accuracy. A feature importance of zero means that the feature is not used at all in the prediction. A feature importance of one, means the feature perfectly predicts the target. Typically, feature importance numbers are always positive and they're normalized so they sum to one." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editf82d2a5a-4e03-4968-c974-bc10a11d9782 Editf82d2a5a-4e03-4968-c974-bc10a11d9782Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editf82d2a5a-4e03-4968-c974-bc10a11d9782">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text:  Another way of analyzing the tree instead of looking at the whole tree at once is to do what's called a feature important calculation. And this is one of the most useful and widely used types of summary analysis you can perform on a supervised learning model. Feature importance is typically a number between 0 and 1 that's assigned to an individual feature. It indicates how important that feature is to the overall prediction accuracy. A feature importance of zero means that the feature is not used at all in the prediction. A feature importance of one, means the feature perfectly predicts the target. Typically, feature importance numbers are always positive and they're normalized so they sum to one." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deletefba68591-e292-4757-ff69-6ff3d10b8c56 Deletefba68591-e292-4757-ff69-6ff3d10b8c56Desc" xmlns="http://www.w3.org/2000/svg"><title id="Deletefba68591-e292-4757-ff69-6ff3d10b8c56">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoea6fe6e3-1a81-46d8-990d-23cd2ae4b7b0 Videoea6fe6e3-1a81-46d8-990d-23cd2ae4b7b0Desc" xmlns="http://www.w3.org/2000/svg"><title id="Videoea6fe6e3-1a81-46d8-990d-23cd2ae4b7b0">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=603&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=603" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=603" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">10:03 - 10:13</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Another
 strategy is to build a complete tree with pure leaves but then to prune
 back the tree into a simpler form. This is called post-pruning or 
sometimes just pruning.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Another strategy is to build a complete tree with pure leaves but then to prune back the tree into a simpler form. This is called post-pruning or sometimes just pruning." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit7e9ef096-574a-413c-99ed-f553a016b252 Edit7e9ef096-574a-413c-99ed-f553a016b252Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit7e9ef096-574a-413c-99ed-f553a016b252">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Another strategy is to build a complete tree with pure leaves but then to prune back the tree into a simpler form. This is called post-pruning or sometimes just pruning." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete2a73e444-4cd5-4f4a-d4b9-44590d300e05 Delete2a73e444-4cd5-4f4a-d4b9-44590d300e05Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete2a73e444-4cd5-4f4a-d4b9-44590d300e05">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video5c8a3aeb-da83-4680-c8e2-38fe7539340a Video5c8a3aeb-da83-4680-c8e2-38fe7539340aDesc" xmlns="http://www.w3.org/2000/svg"><title id="Video5c8a3aeb-da83-4680-c8e2-38fe7539340a">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=978&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=978" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=978" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">16:18 - 16:27</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">Even
 so the feature importance values provide an easy to understand summary 
that can give useful insight about individual features in the learning 
model.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: Even so the feature importance values provide an easy to understand summary that can give useful insight about individual features in the learning model." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit6ef44962-ff9f-4b78-85f9-66f5977620e1 Edit6ef44962-ff9f-4b78-85f9-66f5977620e1Desc" xmlns="http://www.w3.org/2000/svg"><title id="Edit6ef44962-ff9f-4b78-85f9-66f5977620e1">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: Even so the feature importance values provide an easy to understand summary that can give useful insight about individual features in the learning model." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete8c06cf6e-c14b-4c38-ed73-6d48fc516570 Delete8c06cf6e-c14b-4c38-ed73-6d48fc516570Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete8c06cf6e-c14b-4c38-ed73-6d48fc516570">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Video2bffc16b-1aef-49bf-9cd3-10a25bef1928 Video2bffc16b-1aef-49bf-9cd3-10a25bef1928Desc" xmlns="http://www.w3.org/2000/svg"><title id="Video2bffc16b-1aef-49bf-9cd3-10a25bef1928">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=278&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=278" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=278" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">4:38 - 4:53</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">he
 iris data sets features are continuous values. So the rules to be 
learned will be of the form for example, "Is Petal length greater than 
2.3 centimeters?". </div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: he iris data sets features are continuous values. So the rules to be learned will be of the form for example, &quot;Is Petal length greater than 2.3 centimeters?&quot;. " tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Edit6b79045b-2f8a-4ae9-f837-bebcc8a6399f Edit6b79045b-2f8a-4ae9-f837-bebcc8a6399fDesc" xmlns="http://www.w3.org/2000/svg"><title id="Edit6b79045b-2f8a-4ae9-f837-bebcc8a6399f">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: he iris data sets features are continuous values. So the rules to be learned will be of the form for example, &quot;Is Petal length greater than 2.3 centimeters?&quot;. " tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Delete6f7a8bfa-a462-4763-aa2e-691486573a73 Delete6f7a8bfa-a462-4763-aa2e-691486573a73Desc" xmlns="http://www.w3.org/2000/svg"><title id="Delete6f7a8bfa-a462-4763-aa2e-691486573a73">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li><li class=""><div tabindex="0" class="_17khti1q rc-NoteCard"><div class="_nwu9p7t rc-NoteCardItemInfo highlight"><svg class="_ufjrdd" style="fill: rgb(31, 31, 31); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Videoefafc9f3-0d24-40cc-fdfd-583359553fcc Videoefafc9f3-0d24-40cc-fdfd-583359553fccDesc" xmlns="http://www.w3.org/2000/svg"><title id="Videoefafc9f3-0d24-40cc-fdfd-583359553fcc">Video</title><path d="M19 33.94V15l15 9.47-15 9.47zM24 47C11.3 47 1 36.7 1 24S11.3 1 24 1s23 10.3 23 23-10.3 23-23 23zm0-1.84c11.7 0 21.16-9.47 21.16-21.16C45.16 12.3 35.7 2.84 24 2.84 12.3 2.84 2.84 12.3 2.84 24c0 11.7 9.47 21.16 21.16 21.16z" role="presentation"></path></svg><div class="_v8ca7hp video-info-box"><a data-click-key="open_course_home.notes_review.click.highlight_link" data-click-value="{&quot;courseId&quot;:&quot;di4l_R0lEeaP7xL2JHHq4w&quot;,&quot;href&quot;:&quot;/learn/python-machine-learning/lecture/Zj96A?t=393&quot;,&quot;itemId&quot;:&quot;Zj96A&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;highlight_link&quot;,&quot;page&quot;:&quot;notes_review&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="click" data-track-component="highlight_link" data-track-href="/learn/python-machine-learning/lecture/Zj96A?t=393" href="https://www.coursera.org/learn/python-machine-learning/lecture/Zj96A?t=393" class="nostyle" target="_blank" rel="noopener noreferrer"><div class="video-title" aria-label="Item Name">Decision Trees</div></a><div class="video-details" aria-label="Duration">6:33 - 6:42</div></div></div><div class="_8f0ciyt note-text-and-actions"><div class="_8f0ciyt rc-NoteCardNote"><div class="video-section-text" aria-label="Transcript">So
 to build the decision tree, the decision tree building algorithm starts
 by finding the feature that leads to the most informative split.</div></div><div class="_1p9c6ep0 action-buttons-row"><button aria-label="Edit note for text: So to build the decision tree, the decision tree building algorithm starts by finding the feature that leads to the most informative split." tabindex="0" class="_x19y45g note-card-button edit-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_edit_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Editd5d35801-d178-4d6b-f147-dda1e0b05501 Editd5d35801-d178-4d6b-f147-dda1e0b05501Desc" xmlns="http://www.w3.org/2000/svg"><title id="Editd5d35801-d178-4d6b-f147-dda1e0b05501">Edit</title><path d="M30.3149,6.801 L36.6619,13.148 L40.1479,9.662 C40.9959,8.814 41.4629,7.687 41.4629,6.488 C41.4629,5.289 40.9959,4.162 40.1479,3.314 C39.3009,2.467 38.1739,2 36.9749,2 C35.7759,2 34.6489,2.467 33.8009,3.314 L30.3149,6.801 Z M7.9739,29.142 L14.3209,35.489 L35.2479,14.562 L28.9009,8.215 L7.9739,29.142 Z M6.9419,30.939 L3.4729,39.99 L12.5239,36.521 L6.9419,30.939 Z M-0.0001,43.463 L5.7019,28.586 L32.3869,1.9 C33.6129,0.675 35.2419,0 36.9749,0 C38.7079,0 40.3369,0.675 41.5629,1.9 C42.7879,3.126 43.4629,4.755 43.4629,6.488 C43.4629,8.221 42.7879,9.851 41.5629,11.076 L14.8769,37.761 L-0.0001,43.463 Z" role="presentation"></path></svg></span></span></button><button aria-label="Delete note for text: So to build the decision tree, the decision tree building algorithm starts by finding the feature that leads to the most informative split." tabindex="0" class="_x19y45g note-card-button delete-button" data-track="true" data-track-app="open_course_home" data-track-page="notes_review" data-track-action="[object Object]" data-track-component="note_delete_button"><span class="_1lutnh9y"><span class="_41qsc cui-iconWrapper"><svg class="_ufjrdd" style="fill: rgb(150, 150, 150); height: 24px; width: 24px;" viewBox="0 0 48 48" role="img" aria-labelledby="Deleted641601a-768d-428f-ce46-1af879e6ab3d Deleted641601a-768d-428f-ce46-1af879e6ab3dDesc" xmlns="http://www.w3.org/2000/svg"><title id="Deleted641601a-768d-428f-ce46-1af879e6ab3d">Delete</title><polygon points="14.501 37.0454 13.501 15.0454 15.499 14.9544 16.499 36.9544" role="presentation"></polygon><polygon points="25.499 37.0454 23.501 36.9544 24.501 14.9544 26.499 15.0454" role="presentation"></polygon><path d="M13.3877,6 L26.6127,6 L25.9627,4.051 C25.5537,2.824 24.4097,2 23.1167,2 L16.8827,2 C15.5897,2 14.4467,2.824 14.0367,4.051 L13.3877,6 Z M6.9507,46 L33.0487,46 L34.9487,8 L5.0517,8 L6.9507,46 Z M34.9507,48 L5.0487,48 L3.0487,8 L-0.0003,8 L-0.0003,6 L11.2797,6 L12.1397,3.419 C12.8217,1.374 14.7277,0 16.8827,0 L23.1167,0 C25.2727,0 27.1787,1.374 27.8607,3.419 L28.7207,6 L39.9997,6 L39.9997,8 L36.9507,8 L34.9507,48 Z" role="presentation"></path></svg></span></span></button></div></div></div></li></ul></div></div></div></main><div><a data-click-key="open_course_home.help.click.icon" data-click-value="{&quot;href&quot;:&quot;https://accounts.coursera.org/i/zendesk/courserahelp?return_to=https://learner.coursera.help/hc&quot;,&quot;namespace&quot;:{&quot;action&quot;:&quot;click&quot;,&quot;app&quot;:&quot;open_course_home&quot;,&quot;component&quot;:&quot;icon&quot;,&quot;page&quot;:&quot;help&quot;},&quot;open_course_slug&quot;:&quot;python-machine-learning&quot;,&quot;schema_type&quot;:&quot;FRONTEND&quot;}" data-track="true" data-track-app="open_course_home" data-track-page="help" data-track-action="click" data-track-component="icon" data-track-href="https://accounts.coursera.org/i/zendesk/courserahelp?return_to=https://learner.coursera.help/hc" href="https://accounts.coursera.org/i/zendesk/courserahelp?return_to=https://learner.coursera.help/hc" to="https://accounts.coursera.org/i/zendesk/courserahelp?return_to=https://learner.coursera.help/hc" class="rc-Help link-button nostyle" target="_blank" rel="noopener noreferrer" aria-label="Help Center" style="min-width: 0px; bottom: 20px; right: 20px;"><div class="help-widget horizontal-box align-items-absolute-center" role="tooltip"><i class="cif-question-circle-o" aria-hidden="true"></i></div></a></div></div></div></div></div><script>
    window.appName="ondemand";
    window.__APOLLO_STATE__ = {};
    window.renderedClassNames = ["_473mf9o","_e296pg","keyframe_1mfzdnn","_1hwtb43"];
    window.detectedTimezone = "Europe/Rome";
  
</script><script>var loadScript = function(url, success, async) {
  var newScript = document.createElement('script');
  var scripts = document.getElementsByTagName('script');

  newScript.type = 'text/javascript';
  newScript.async = async || false;
  newScript.crossOrigin = 'anonymous';

  if (success) {
    if (newScript.addEventListener) {
      newScript.addEventListener('load', function() {
       success();
      }, false);
    } else if(newScript.readyState) {
      newScript.onreadystatechange = function() {
        if (this.readyState == 'complete') {
          newScript.onreadystatechange = null;
          success();
        }
      };
    }
  }

  if (scripts && scripts.length) {
    var lastScript = scripts[scripts.length - 1];
    lastScript.parentNode.insertBefore(newScript, lastScript.nextSibling);
  } else if (window.document && window.document.body) {
    window.document.body.appendChild(newScript);
  }

  // IE9 will execute the proper order if src is set AFTER injection
  newScript.src = url;
}

window.coursera = {};
window.appName = "ondemand";
window.locale = "en";
</script><script>coursera.config = (function() {
 if (config) {
   // requesters country of origin, injected by edge
   // in the following format https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2
   config.requestCountryCode = 'IT';
   return config;
 } else {
   return {};
 }
})();/* global coursera */
// Provide a string that will be replaced by edge.
// Make sure to use double quotes because edge only escapes double quotes.
// Then check that edge actually did the replacement.
// Otherwise return an empty object.
// You must use double quotes for the injected string
coursera.epicOverrides = (function() {

  if (injectedString.search('EPIC_SITE_HOME_PLACEHOLDER') >= 0) {
    return {};
  }

  var epicResponse = injectedString && injectedString !== undefined ? JSON.parse(injectedString) : {};
  return epicResponse.elements || {};
})();
/* globals coursera */
/* eslint-disable quotes */
})();
/* globals coursera*/
// Defines a named AMD module containing the course ID
coursera.courseId = (function() {
})();
</script><!--[if lte IE 9]><script>var queueScript = function(scripts, callback) {
  return function() {
    if (scripts.length > 1) {
      loadScript(scripts.shift(), queueScript(scripts, callback));
    } else {
      loadScript(scripts.shift(), callback);
    }
  }
};

var queue = function(scripts, callback) {
  queueScript(scripts, callback)();
}

var scripts = [
  'https://d3njjcbhbojbot.cloudfront.net/web/bundles/vendor/Intl.js.v0-1-4/Intl.en-US.js',
  'https://d3njjcbhbojbot.cloudfront.net/webapps/r2-builds/ondemand/polyfill.7261bd210e8c516552b6.js','https://d3njjcbhbojbot.cloudfront.net/webapps/r2-builds/ondemand/preloader.229eca4229b4d365a2aa.js','https://d3njjcbhbojbot.cloudfront.net/webapps/r2-builds/ondemand/loader.a280ae1c041f5923e4b3.js',
  ''
];
scripts.pop(); // remove the last element, since it is empty due to template oddities...
queue(scripts, function() {});</script><![endif]-->
<!--[if !IE]> --><script>if (!window.JSON) {
  loadScript('https://d3njjcbhbojbot.cloudfront.net/web/js/vendor/json2.js');
}
</script><!-- <![endif]--><div class="hide confirm-navigation modal"><div class="modal-header"><h3>Confirm Navigation</h3></div><div class="modal-body"><div class="confirm-navigation-message"></div><div>Are you sure you want to leave this page?</div></div><div class="modal-footer"><button data-modal-close="data-modal-close" class="passive confirm-navigation-stay">Stay on this Page</button>&nbsp;&nbsp;<button data-modal-close="data-modal-close" data-modal-action="leave" class="primary confirm-navigation-leave">Leave this Page</button></div></div><div class="hide confirm-navigation modal"><div class="modal-header"><h3>Confirm Navigation</h3></div><div class="modal-body"><div class="confirm-navigation-message"></div><div>Are you sure you want to leave this page?</div></div><div class="modal-footer"><button data-modal-close="data-modal-close" class="passive confirm-navigation-stay">Stay on this Page</button>&nbsp;&nbsp;<button data-modal-close="data-modal-close" data-modal-action="leave" class="primary confirm-navigation-leave">Leave this Page</button></div></div></body></html>